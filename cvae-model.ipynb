{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notebook for building and testing the model     \n",
    "\n",
    "In this notebook, I will build and run an initial test over the first 2,048 rows of the data to ensure proper functionality before deploying on midway2 to train on GPUs. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda setup\n",
    "device = torch.device(\"cuda\")\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 64\n",
    "latent_size = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "dat = np.genfromtxt('traindata/trip-2021-07-28.csv', delimiter=',')[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to subset this in a conditional fashion (i.e., each gamma value, here class c, has 1000 data points)\n",
    "gamma = np.unique(dat[:,1])\n",
    "idx = [np.where(dat[:,1] == gamma[i]) for i in np.arange(len(gamma))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an 80/20 split in each data set\n",
    "temp = [train_test_split(dat[idx[i][0],0], dat[idx[i][0],2], test_size=0.2, random_state=42) for i in np.arange(len(gamma))]\n",
    "\n",
    "# for each gamma value...\n",
    "Xltrain = []\n",
    "Xltest = []\n",
    "altrain = []\n",
    "altest = []\n",
    "for t in np.arange(len(temp)):\n",
    "    Xltrain.append(temp[t][0])\n",
    "    Xltest.append(temp[t][1])\n",
    "    altrain.append(temp[t][2])\n",
    "    altest.append(temp[t][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa92450b8e0>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(Xltrain[0]), torch.from_numpy(altrain[0])), batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 487,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, hidden1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(1, hidden1),\n",
    "            nn.Linear(hidden1, 5),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "        self.fc2 = nn.Sequential(\n",
    "            nn.Linear(1, 2),\n",
    "            nn.Tanh(),\n",
    "        )\n",
    "\n",
    "        self.predict = nn.Sequential(\n",
    "            nn.Linear(5 + 2, 1), \n",
    "            nn.ReLU(),\n",
    "        )\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x, g):\n",
    "        #x = self.fc1(x.view(-1, x.size(0)))\n",
    "        x = self.fc1(x)\n",
    "        g = self.fc2(g)\n",
    "        # print(x)\n",
    "        # print(g)\n",
    "        a = self.predict(torch.cat((x,g), 1))\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 505,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnet = BaselineNet(20)\n",
    "bnet.eval()\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = optim.SGD(bnet.parameters(), lr=2e-3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 506,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch [0], Loss: 292808.07\n",
      "epoch [100], Loss: 74485.30\n",
      "epoch [200], Loss: 74146.65\n",
      "epoch [300], Loss: 74140.43\n",
      "epoch [400], Loss: 74170.19\n",
      "epoch [500], Loss: 74146.29\n",
      "epoch [600], Loss: 74146.26\n",
      "epoch [700], Loss: 74146.26\n",
      "epoch [800], Loss: 74146.26\n",
      "epoch [900], Loss: 74146.26\n"
     ]
    }
   ],
   "source": [
    "for e in range(1000):\n",
    "    #pred = bnet(torch.from_numpy(Xltrain[0]).float(), torch.from_numpy(np.repeat(gamma[0], len(Xltrain[0]))).float())\n",
    "    pred = bnet(torch.unsqueeze(torch.tensor(Xltrain[0]),1), torch.unsqueeze(torch.tensor(np.repeat(gamma[0], len(Xltrain[0]))),1))\n",
    "    step_loss = mse_loss(pred, torch.unsqueeze(torch.tensor(altrain[0]),1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    step_loss.backward()\n",
    "    # update with current step regression parameters \n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        print ('epoch [{}], Loss: {:.2f}'.format(e, step_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 507,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "tensor([[468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862],\n",
       "        [468.1862]], dtype=torch.float64, grad_fn=<SliceBackward>)"
      ]
     },
     "metadata": {},
     "execution_count": 507
    }
   ],
   "source": [
    "r2_score(y_true=altrain[0], y_pred=pred.detach().numpy())\n",
    "pred[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "metadata": {},
     "execution_count": 481
    }
   ],
   "source": [
    "#torch.unsqueeze(torch.tensor(Xltrain[0]),1)\n",
    "#bnet.forward(torch.tensor(Xltrain[0]), torch.tensor(np.repeat(gamma[0], len(Xltrain[0]))))\n",
    "torch.tensor(Xltrain[0]).view(-1, torch.tensor(Xltrain[0]).size(0)).shape\n",
    "torch.unsqueeze(torch.tensor(Xltrain[0]),1)\n",
    "#print(torch.unsqueeze(torch.linspace(-1,1,10),-1).shape)\n",
    "#bnet.forward(torch.tensor(Xltrain[0][1]),torch.tensor(gamma[0]))\n",
    "#torch.unsqueeze(torch.tensor(Xltrain[0]),0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 491,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 2.4035],\n",
       "        [-1.1682],\n",
       "        [ 1.2436],\n",
       "        [-3.9618],\n",
       "        [-4.1732],\n",
       "        [-0.2449],\n",
       "        [ 0.1441],\n",
       "        [-0.3814],\n",
       "        [-0.0617],\n",
       "        [-1.2677],\n",
       "        [ 2.8297],\n",
       "        [-1.2981],\n",
       "        [-4.5600],\n",
       "        [-3.7503],\n",
       "        [-2.9979],\n",
       "        [-0.9083],\n",
       "        [ 0.4969],\n",
       "        [ 0.0278],\n",
       "        [-0.7822],\n",
       "        [-4.4803]], dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 491
    }
   ],
   "source": [
    "bnet.fc1[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}