{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3",
   "language": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Notebook for building and testing the model     \n",
    "\n",
    "In this notebook, I will build and run an initial test over the first 2,048 rows of the data to ensure proper functionality before deploying on midway2 to train on GPUs. "
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable\n",
    "from torch.nn import functional as F\n",
    "from torch.utils.data import Dataset, TensorDataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import datasets, transforms\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cuda setup\n",
    "device = torch.device(\"cuda\")\n",
    "kwargs = {'num_workers': 2, 'pin_memory': True} "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hyper params\n",
    "batch_size = 64\n",
    "latent_size = 10\n",
    "epochs = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading in the data\n",
    "dat = np.genfromtxt('traindata/trip-2021-07-28.csv', delimiter=',')[1:,]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need to subset this in a conditional fashion (i.e., each gamma value, here class c, has 1000 data points)\n",
    "gamma = np.unique(dat[:,1])\n",
    "idx = [np.where(dat[:,1] == gamma[i]) for i in np.arange(len(gamma))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# create an 80/20 split in each data set\n",
    "temp = [train_test_split(dat[idx[i][0],0], dat[idx[i][0],2], test_size=0.2, random_state=42) for i in np.arange(len(gamma))]\n",
    "\n",
    "# for each gamma value...\n",
    "Xltrain = []\n",
    "Xltest = []\n",
    "altrain = []\n",
    "altest = []\n",
    "for t in np.arange(len(temp)):\n",
    "    Xltrain.append(temp[t][0])\n",
    "    Xltest.append(temp[t][1])\n",
    "    altrain.append(temp[t][2])\n",
    "    altest.append(temp[t][3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7fa92450b8e0>"
      ]
     },
     "metadata": {},
     "execution_count": 91
    }
   ],
   "source": [
    "torch.utils.data.DataLoader(TensorDataset(torch.from_numpy(Xltrain[0]), torch.from_numpy(altrain[0])), batch_size=batch_size, shuffle=True, **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 683,
   "metadata": {},
   "outputs": [],
   "source": [
    "class BaselineNet(nn.Module):\n",
    "    def __init__(self, hidden1):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Sequential(\n",
    "            nn.Linear(2, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1, hidden1),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(hidden1, 50), \n",
    "            nn.ReLU(),\n",
    "            nn.Linear(50, 1),\n",
    "        )\n",
    "        # self.fc2 = nn.Sequential(\n",
    "        #     nn.Linear(1, 2),\n",
    "        #     nn.Tanh(),\n",
    "        # )\n",
    "\n",
    "        # self.predict = nn.Sequential(\n",
    "        #     nn.Linear(10 + 2, 1), \n",
    "        # )\n",
    "        self.double()\n",
    "\n",
    "    def forward(self, x, g):\n",
    "        #x = self.fc1(x)\n",
    "        #g = self.fc2(g)\n",
    "        a = self.fc1(torch.cat((x,g), 1))\n",
    "        return a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 684,
   "metadata": {},
   "outputs": [],
   "source": [
    "bnet = BaselineNet(500)\n",
    "bnet.eval()\n",
    "mse_loss = nn.MSELoss()\n",
    "optimizer = optim.SGD(bnet.parameters(), lr=2e-4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 685,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "epoch [0], Loss: 2418022.70\n",
      "epoch [100], Loss: nan\n",
      "epoch [200], Loss: nan\n"
     ]
    },
    {
     "output_type": "error",
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-685-7bfec7418dc4>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m     \u001b[0mstep_loss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m     \u001b[0;31m# update with current step regression parameters\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m     \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cvae/lib/python3.9/site-packages/torch/tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph)\u001b[0m\n\u001b[1;32m    219\u001b[0m                 \u001b[0mretain_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    220\u001b[0m                 create_graph=create_graph)\n\u001b[0;32m--> 221\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    222\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    223\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/anaconda3/envs/cvae/lib/python3.9/site-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables)\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mretain_graph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 130\u001b[0;31m     Variable._execution_engine.run_backward(\n\u001b[0m\u001b[1;32m    131\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    132\u001b[0m         allow_unreachable=True)  # allow_unreachable flag\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "for e in range(800):\n",
    "    #pred = bnet(torch.from_numpy(Xltrain[0]).float(), torch.from_numpy(np.repeat(gamma[0], len(Xltrain[0]))).float())\n",
    "    #pred = bnet(torch.unsqueeze(torch.tensor(Xltrain[5]),1), torch.unsqueeze(torch.tensor(np.repeat(gamma[5], len(Xltrain[5]))),1))\n",
    "    pred = bnet(torch.unsqueeze(torch.tensor(np.hstack((Xltrain[0:5]))),1), torch.unsqueeze(torch.tensor(np.repeat(gamma[0:5],len(Xltrain[0]))),1))\n",
    "    step_loss = mse_loss(pred, torch.unsqueeze(torch.tensor(np.hstack((altrain[0:5]))),1))\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    step_loss.backward()\n",
    "    # update with current step regression parameters \n",
    "    optimizer.step()\n",
    "\n",
    "    if e % 100 == 0:\n",
    "        print ('epoch [{}], Loss: {:.2f}'.format(e, step_loss.item()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 682,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[-0.0239, -0.0065,  0.0233,  ...,  0.0497,  0.0425,  0.0248],\n",
       "        [ 0.0484, -0.0090,  0.0171,  ..., -0.0282, -0.0513,  0.0207],\n",
       "        [-0.0232,  0.0248, -0.0247,  ..., -0.0252, -0.0024, -0.0178],\n",
       "        ...,\n",
       "        [ 0.0487,  0.0155,  0.0068,  ..., -0.0589, -0.0140, -0.0423],\n",
       "        [-0.0306, -0.0460, -0.0129,  ..., -0.0064,  0.0208,  0.0207],\n",
       "        [ 0.0654, -0.0045, -0.0395,  ..., -0.0121, -0.0151,  0.0022]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 682
    }
   ],
   "source": [
    "(bnet.fc1[4].weight)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 649,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "torch.Size([7200, 1])"
      ]
     },
     "metadata": {},
     "execution_count": 649
    }
   ],
   "source": [
    "r2_score(y_true=altrain[5], y_pred=pred.detach().numpy())\n",
    "#bnet(torch.unsqueeze(torch.tensor(Xltrain[5][0:1]),1), torch.unsqueeze(torch.tensor(np.repeat(gamma[5],1)),1))\n",
    "#torch.unsqueeze(torch.cat((torch.tensor(Xltrain[5]),torch.tensor(Xltrain[0])),0),1)\n",
    "torch.unsqueeze(torch.tensor(np.repeat(gamma[0:9],len(Xltrain[0]))),1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 481,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "800"
      ]
     },
     "metadata": {},
     "execution_count": 481
    }
   ],
   "source": [
    "#torch.unsqueeze(torch.tensor(Xltrain[0]),1)\n",
    "#bnet.forward(torch.tensor(Xltrain[0]), torch.tensor(np.repeat(gamma[0], len(Xltrain[0]))))\n",
    "torch.tensor(Xltrain[0]).view(-1, torch.tensor(Xltrain[0]).size(0)).shape\n",
    "torch.unsqueeze(torch.tensor(Xltrain[0]),1)\n",
    "#print(torch.unsqueeze(torch.linspace(-1,1,10),-1).shape)\n",
    "#bnet.forward(torch.tensor(Xltrain[0][1]),torch.tensor(gamma[0]))\n",
    "#torch.unsqueeze(torch.tensor(Xltrain[0]),0).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 514,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "Parameter containing:\n",
       "tensor([[ 71.3519, -73.1773, -42.9027,  71.6761,  72.8176, -74.0732, -73.8141]],\n",
       "       dtype=torch.float64, requires_grad=True)"
      ]
     },
     "metadata": {},
     "execution_count": 514
    }
   ],
   "source": [
    "bnet.predict[0].weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}