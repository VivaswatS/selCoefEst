{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Notebook to code up method of moments framework \n",
    "\n",
    "Here, I will use the method of moments framework used to track the trajectory of the site frequency spectrum through time given drift and selection from [Jouganous et. al. 2017](https://www.genetics.org/content/206/3/1549). Mostly, I will just use equations to start from a certain generation $t$ back in time and then iterate until generation 0. Then I will store this SFS as a data entry for allele age $t$ and certain selection coefficient $s$. This process will be repeated for each value of $\\{1,\\ldots,gen,\\ldots,12000\\}$ generations. \n",
    "\n",
    "These vectors need to be summed to marginalize over *all* generations $a$, to give $P(X, a | s)$.\n",
    "\n",
    "First, need to get a handle on what $\\Phi_n^k(i)$ really is - can just be represented as *np.array*\n",
    "\n",
    "$\\phi_n^k(i)$ is the expected number of sites where the alternate allele is observed exactly $i$ times in a sample of size $n$ at generation $k$. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "# numerics + rv stuff\n",
    "from numba import jit\n",
    "import numpy as np\n",
    "import scipy as sp\n",
    "from scipy.stats.distributions import chi2\n",
    "from scipy.sparse import coo_matrix\n",
    "from scipy.sparse import linalg\n",
    "from numpy.random import default_rng\n",
    "import moments\n",
    "# import dadi \n",
    "# import Selection\n",
    "# plotting + misc tools\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.patches as mpatches\n",
    "import itertools as it\n",
    "from copy import deepcopy\n",
    "import matplotlib.colors as colors\n",
    "import seaborn\n",
    "from matplotlib import cm \n",
    "from mom_functions import *\n",
    "\n",
    "# rng setup\n",
    "rng = default_rng(100496)\n",
    "\n",
    "# change matplotlib fonts\n",
    "plt.rcParams[\"font.family\"] = \"Arial\"\n",
    "plt.rcParams[\"font.sans-serif\"] = \"Arial\"\n",
    "plt.rcParams[\"figure.figsize\"] = [5, 3.5]\n",
    "plt.rcParams[\"figure.dpi\"] = 110\n",
    "plt.rcParams[\"axes.axisbelow\"] = True\n",
    "plt.rcParams.update({\"figure.facecolor\": \"white\"})\n",
    "\n",
    "# set numpy print option to a more readable format for floats\n",
    "np.set_printoptions(formatter={'float': lambda x: \"{0:0.3f}\".format(x)})\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "N = 10000\n",
    "s = -10/N # 25/N -> gamma2 = 50 - strong selection\n",
    "mu = 1.25e-8 # human mutation rate\n",
    "n = 2000 # 2 * # of inds sampled, diploid\n",
    "\n",
    "# start in generation 10 so generation 11 has all zeros (going back in time)\n",
    "tot_gen = 10000\n",
    "time_steps = np.linspace(0, tot_gen-1, 100, dtype=int)\n",
    "\n",
    "mom = np.zeros((tot_gen+1,n+1))\n",
    "momnp1 = np.zeros(n+1)\n",
    "momkp1 = np.zeros((tot_gen+1,n+1))\n",
    "\n",
    "# double precaution - creating a mask\n",
    "mk = [False] + [True]*(n-1) + [False]\n",
    "\n",
    "iter = np.arange(1,n)\n",
    "iterm1p1 = np.arange(2,n-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "## borrowed directly from https://bitbucket.org/simongravel/moments/src/main/moments/Jackknife.pyx\n",
    "def python2round(f):\n",
    "    if round(f + 1) - round(f) != 1:\n",
    "        return f + abs(f) / f * 0.5\n",
    "    return round(f)\n",
    "\n",
    "# The choice i' in n samples that best approximates the frequency of i/(n + 1) is i*n / (n + 1)\n",
    "def index_bis(i, n):\n",
    "    return int(min(max(python2round(i * n / float(n+1)), 2), n-2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# code borrowed from https://bitbucket.org/simongravel/moments/src/main/moments/Jackknife.pyx  \n",
    "def calcJK13(n):\n",
    "    J = np.zeros((n,n-1))\n",
    "    for i in range(n):\n",
    "        ibis = index_bis(i + 1, n) - 1\n",
    "        J[i, ibis] = -(1.+n) * ((2.+i)*(2.+n)*(-6.-n+(i+1.)*(3.+n))-2.*(4.+n)*(-1.+(i+1.)*(2.+n))*(ibis+1.)+(12.+7.*n+n**2)*(ibis+1.)**2) / (2.+n) / (3.+n) / (4.+n)\n",
    "        J[i, ibis - 1] = (1.+n) * (4.+(1.+i)**2*(6.+5.*n+n**2)-(i+1.)*(14.+9.*n+n**2)-(4.+n)*(-5.-n+2.*(i+1.)*(2.+n))*(ibis+1.)+(12.+7.*n+n**2)*(ibis+1.)**2) / (2.+n) / (3.+n) / (4.+n) / 2.\n",
    "        J[i, ibis + 1] = (1.+n) * ((2.+i)*(2.+n)*(-2.+(i+1.)*(3.+n))-(4.+n)*(1.+n+2.*(i+1.)*(2.+n))*(ibis+1.)+(12.+7.*n+n**2)*(ibis+1.)**2) / (2.+n) / (3.+n) / (4.+n) / 2.\n",
    "    return J"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testbed for a single realization of gen = t\n",
    "mom[tot_gen,1] = n*mu # singleton input\n",
    "\n",
    "J = calcJK13(n)\n",
    "\n",
    "# going from generation 9 to 0\n",
    "for gen in np.arange(tot_gen)[::-1]:\n",
    "    momkp1[gen,iterm1p1] = 0.25/N * (mom[gen+1,iterm1p1-1] * (iterm1p1-1)*(n-iterm1p1+1) + mom[gen+1,iterm1p1+1] * (iterm1p1+1)*(n-iterm1p1-1) - mom[gen+1,iterm1p1] * 2*iterm1p1*(n-iterm1p1))\n",
    "\n",
    "    momkp1[gen,1] = 0.25/N * ((n-2) * 2 * mom[gen+1,2] - 2 * (n-1) * mom[gen+1,1])\n",
    "    momkp1[gen,n-1] = 0.25/N * ((n-2) * 2 * mom[gen+1,n-2] - 2 * (n-1) * mom[gen+1,n-1])\n",
    "\n",
    "    # notice the difference in indexing for LHS\n",
    "    # momnp1[np.arange(1,n+1)] = (jk13[:,0] * mom[gen+1,np.array(ibis)-1] - jk13[:,1] * mom[gen+1,np.array(ibis)] + jk13[:,2] * mom[gen+1,np.array(ibis)+1])\n",
    "    momnp1[np.arange(1,n+1)] = (J @ mom[gen+1,iter])\n",
    "\n",
    "    momkp1[gen,iter] += mom[gen+1,iter] + 0.5 * s/(n+1) * (iter * (n+1-iter) * momnp1[iter] - (n-iter) * (iter+1) * momnp1[iter+1])\n",
    "\n",
    "    mom[gen,] = deepcopy(momkp1[gen,])\n",
    "\n",
    "mom2 = deepcopy(mom)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## code to run APR's moments and compare with output from above\n",
    "# initialize the spectrum, with 1 in singleton bin\n",
    "fs = moments.Spectrum(np.zeros(2*n + 1))\n",
    "fs[1] = n*1\n",
    "# simulate a generations\n",
    "T = tot_gen / 2 / N\n",
    "# set relative size to 1, theta to 0 to forbid new mutations\n",
    "fs.integrate([1], T, gamma=s*2*N, h=0.5, theta=0, adapt_dt=True, dt_fac=0.005)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## testbed for a single realization of gen = t & the Crank-Nicolson method\n",
    "mom[100,1] = n*1 # singleton input\n",
    "\n",
    "dt = 1\n",
    "\n",
    "D = 0.25/N * calcD(n+1)\n",
    "J = calcJK13(n+1)\n",
    "S = 0.5 * s * calcS(n+1, J)\n",
    "\n",
    "# if N is same across all gens then only have to do this once\n",
    "slv = linalg.factorized(sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") - dt / 2.0 * (D + S))\n",
    "Q = sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") + dt / 2.0 * (D + S)\n",
    "\n",
    "# going from generation 9 to 0\n",
    "for gen in np.arange(100)[::-1]:\n",
    "\n",
    "    # momkp1[gen,iter] = mom[gen+1,iter] + ((D[iter,] + S[iter,]) @ mom[gen+1,])\n",
    "    momkp1[gen,iter] = mom[gen+1,iter] + slv(Q.dot(mom[gen+1,iter]))\n",
    "    momkp1[gen,0] = momkp1[gen,n] = 0.0\n",
    "\n",
    "    mom[gen,] = deepcopy(momkp1[gen,])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcD(d):\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "    # loop over the fs elements:\n",
    "    for i in range(d):\n",
    "        if i > 1:\n",
    "            data.append((i-1) * (d-i))\n",
    "            row.append(i)\n",
    "            col.append(i - 1)\n",
    "        if i < d - 2:\n",
    "            data.append((i+1) * (d-i-2))\n",
    "            col.append(i + 1)\n",
    "            row.append(i)\n",
    "        if i > 0 and i < d - 1:\n",
    "            data.append(-2 * i * (d-i-1))\n",
    "            row.append(i)\n",
    "            col.append(i)\n",
    "\n",
    "    return coo_matrix((data, (row, col)), shape=(d, d), dtype='float').tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calcS(d, ljk):\n",
    "    # Computes the jackknife-transformed selection matrix 1\n",
    "    # for the addition of a single sample\n",
    "    # arrays for the creation of the sparse (coo) matrix\n",
    "    # data will have matrix entry, row + column have coordinates\n",
    "    data = []\n",
    "    row = []\n",
    "    col = []\n",
    "    # loop over the fs elements:\n",
    "    for i in range(d):\n",
    "        i_bis = index_bis(i, d - 1) # This picks the second jackknife index \n",
    "        i_ter = index_bis(i + 1, d - 1) # This picks the third jackknife index\n",
    "        # coefficients of the selection matrix\n",
    "        g1 = i * (d-i) / np.float64(d)\n",
    "        g2 = -(i+1) * (d-1-i) / np.float64(d)\n",
    "\n",
    "        if i < d - 1 and i > 0: # First deal with non-fixed variants\n",
    "            data += [g1 * ljk[i - 1, i_bis - 1], g1 * ljk[i - 1, i_bis - 2],\n",
    "                    g1 * ljk[i - 1, i_bis], g2 * ljk[i, i_ter - 1],\n",
    "                    g2 * ljk[i, i_ter - 2], g2 * ljk[i, i_ter]]\n",
    "            row += 6 * [i]\n",
    "            col += [i_bis, i_bis - 1, i_bis + 1,\n",
    "                    i_ter, i_ter - 1, i_ter + 1]\n",
    "        \n",
    "        elif i == 0: # g1=0\n",
    "            data += [g2 * ljk[i, i_ter - 1],\n",
    "                     g2 * ljk[i, i_ter - 2], g2 * ljk[i, i_ter]]\n",
    "            row += 3 * [i]\n",
    "            col += [i_ter, i_ter - 1, i_ter + 1]\n",
    "        \n",
    "        elif i == d - 1: # g2=0\n",
    "            data += [g1 * ljk[i - 1, i_bis - 1], g1 * ljk[i - 1, i_bis - 2],\n",
    "                     g1 * ljk[i - 1, i_bis]]\n",
    "            row += 3 * [i]\n",
    "            col += [i_bis, i_bis - 1, i_bis + 1]\n",
    "\n",
    "    return coo_matrix((data, (row, col)), shape=(d, d), dtype='float').tocsc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## packaging into a function for easy manipulation - iteration implementation \n",
    "# input: a (number of gens), n (number of samples), s, N (pop size)\n",
    "# output: mom (number of sites)\n",
    "def run_mom_iterate(a, n, s, N, mu, misc):\n",
    "    mom = np.zeros((a+1,n+1))\n",
    "    # momnp1 = np.zeros(n+1)\n",
    "    momkp1 = np.zeros(n+1)\n",
    "\n",
    "    D = 0.25/N * calcD(n+1)\n",
    "    J = calcJK13(n)\n",
    "    S = 0.5 * s * calcS(n+1, J)\n",
    "\n",
    "    # if N is same across all gens then only have to do this once\n",
    "    slv = linalg.factorized(sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") - 0.5 * (D + S))\n",
    "    Q = sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") + 0.5 * (D + S)\n",
    "\n",
    "    mom[a,1] = 1 # singleton input\n",
    "\n",
    "    # going from generation 9 to 0\n",
    "    for gen in np.arange(a)[::-1]:\n",
    "        momkp1 = slv(Q.dot(mom[gen+1,]))\n",
    "        momkp1[0] = momkp1[n] = 0.0\n",
    "\n",
    "        mom[gen,] = deepcopy(momkp1)\n",
    "\n",
    "    return mom[:-1,:]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@jit(nopython=True)\n",
    "def run_mom_iterate_changing(n, s, Nc, mu, misc):\n",
    "    mom = np.zeros((len(Nc)+1,n+1))\n",
    "    # momnp1 = np.zeros(n+1)\n",
    "    momkp1 = np.zeros(n+1)\n",
    "\n",
    "    changepoints = len(Nc) - np.concatenate((np.array([0]),np.where(Nc[:-1] != Nc[1:])[0]+1),axis=0)\n",
    "    changepoints = np.append(changepoints, 0)\n",
    "\n",
    "    mom[len(Nc),1] = 1 # singleton input\n",
    "    \n",
    "    # only need to do this once - no dependence on N\n",
    "    J = calcJK13(n)\n",
    "    S = 0.5 * s * calcS(n+1, J)\n",
    "\n",
    "    for i in range(len(changepoints)-1):\n",
    "        D = 0.25/Nc[len(Nc)-changepoints[i]] * calcD(n+1)\n",
    "\n",
    "        slv = linalg.factorized(sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") - 0.5 * (D + S))\n",
    "        Q = sp.sparse.identity(S.shape[0], dtype=\"float\", format=\"csc\") + 0.5 * (D + S)\n",
    "\n",
    "        for gen in np.arange(changepoints[i+1],changepoints[i])[::-1]:\n",
    "            momkp1 = slv(Q.dot(mom[gen+1,]))\n",
    "            momkp1[0] = momkp1[n] = 0.0\n",
    "\n",
    "            mom[gen,] = deepcopy(momkp1)\n",
    "\n",
    "    return mom[:-1,:]           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## starting from the past to the present (Nc[-1] is current generation)\n",
    "# Nc = np.concatenate((np.repeat(20000,1000),np.repeat(2000,2000)))\n",
    "# changepoints = len(Nc) - np.concatenate((np.array([0]),np.where(Nc[:-1] != Nc[1:])[0]+1),axis=0)\n",
    "# changepoints = np.append(changepoints, 0)\n",
    "# mom_outc = run_mom_iterate_changing(1000, -0.000125, Nc/2, 1.25e-8, None)\n",
    "# plt.imshow(mom_outc[000:2100,:]/np.sum(mom_outc[000:2100]),aspect='auto',norm=colors.LogNorm()); plt.colorbar(); plt.show()\n",
    "# plt.imshow(up_xa_s[gamma2[-20]],aspect='auto',norm=colors.LogNorm(vmax=1e-3,vmin=1e-10)); plt.colorbar(); plt.show()\n",
    "plt.imshow(up_xa_s[-100.],aspect='auto',norm=colors.LogNorm(vmax=1e-3,vmin=1e-10)); plt.colorbar(); plt.show()\n",
    "# plt.plot(mom_outc[-100,:]); plt.plot(mom_outc[-2000,:]); plt.loglog(); plt.ylim((1e-10,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gamma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs = run_mom_integrate(4000, 1000, 0.5*gamma[0]/N, N, mu, misc = {'dt_fac':0.02, 'adapt_dt':False})\n",
    "# plt.imshow(fs[:,:],aspect='auto',norm=colors.LogNorm(vmax=10e-7,vmin=10e-30)); plt.colorbar(); plt.show()\n",
    "# fs2 = run_mom_integrate2(4000, 200, 0.5*gamma[0]/N, N, mu, misc = {'dt_fac':0.02, 'adapt_dt':False})\n",
    "# plt.imshow(fs2[:,:],aspect='auto',norm=colors.LogNorm(vmax=10e-7,vmin=10e-30)); plt.colorbar(); plt.show()\n",
    "# mom = run_mom_iterate(8000, 2000, 0.5*gamma[10]/N, N, mu, np.nan)\n",
    "# plt.imshow(mom[:,:],aspect='auto',norm=colors.LogNorm(vmax=10e-7,vmin=10e-30)); plt.colorbar(); plt.show()\n",
    "# fs.shape, mom.shape\n",
    "# plt.scatter(np.ravel(mom[:,1:-1]), np.ravel(fs[:,1:-1]), color='grey', alpha=0.75, s=5); plt.loglog()\n",
    "# plt.axline((0,0),(1,1),color='coral',ls='--', linewidth=0.6); plt.xlabel('iterative framework'); plt.ylabel('integrative framework'); plt.title('γ = {}'.format(-100.))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function where each generation was integrated to separately\n",
    "def run_mom_integrate(a, n, s, N, mu, misc):\n",
    "    fsmat = np.zeros((a,n+1))\n",
    "    for idt, dt in enumerate(np.linspace(0.5/N,0.5*a/N,a)[::-1]):\n",
    "        fs = moments.Spectrum(np.zeros(n + 1))\n",
    "        fs[1] = 1\n",
    "        fs.integrate([1], dt, gamma=2*s*N, h=0.5, theta=0, dt_fac=misc['dt_fac'], adapt_dt=misc['adapt_dt'])\n",
    "        fsmat[idt,:] = n*mu*fs\n",
    "    return fsmat\n",
    "\n",
    "## function where each generation is only integrated from previous generation\n",
    "def run_mom_integrate2(a, n, s, N, mu, misc):\n",
    "    fsmat = np.zeros((a,n+1))\n",
    "    dt = 0.5/N\n",
    "    fs = moments.Spectrum(fsmat[-1,:])\n",
    "    fs[1] = 1\n",
    "    fs.integrate([1], dt, gamma=2*s*N, h=0.5, theta=0)\n",
    "    fsmat[-1,:] = fs\n",
    "    for idt in np.arange(0,a-1)[::-1]:\n",
    "        # fs = moments.Spectrum(fsmat[idt+1,:])\n",
    "        fs.integrate([1], dt, gamma=2*s*N, h=0.5, theta=0, dt_fac=misc['dt_fac'], adapt_dt=misc['adapt_dt'])\n",
    "        fsmat[idt,:] = fs\n",
    "    return n*mu*fsmat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fs.integrate([1],2,gamma=-10,theta=1)\n",
    "# fs1 = moments.Spectrum(np.zeros(n+1))\n",
    "# fs1[1]=1\n",
    "# fs1.integrate([1],2,gamma=-1,theta=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gamma2 = np.hstack((np.logspace(1,-2,10),0.0,-np.logspace(-2,1,10)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## creating a database of P(X, a | s) with dicts for different s values\n",
    "# import io\n",
    "# up_xa_s = h5py.File(io.BytesIO(), 'w')\n",
    "# del up_xa_s\n",
    "gamma2 = -np.logspace(-.5,2.5,25,) \n",
    "# up_xa_s = dict.fromkeys(gamma2)\n",
    "## use different lengths of time for each gamma (high gamma - small limits)\n",
    "## go up to 5 orders of magnitude below start (i.e., E[# seg sites] < 1e-11)\n",
    "# limal = np.concatenate((np.linspace(7500,85000,20,dtype=int),np.repeat(85000,30)))\n",
    "# limal = np.linspace(140000,10000,25,dtype='int')\n",
    "# for ig, g in enumerate(gamma2):\n",
    "    # unscaled probability - almost likelihood\n",
    "    # up_xa_s[g] = run_mom_iterate(limal[ig], 2000, 0.5*g/N, N, 1.25e-8, misc = {'dt_fac':0.02, 'adapt_dt':True})\n",
    "    # can project down to any sample size using moments.Spectrum(p_xa_s[g][-1,:]).project([20])*120/20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# up_xa_s_neut = run_mom_iterate(100000, 2000, 0, N, 1.25e-8, misc = {'dt_fac':0.02, 'adapt_dt':True})\n",
    "cutoff = 2\n",
    "up_xa_s_neut[:,np.arange(cutoff,n-cutoff+1)] = up_xa_s_neut[:,np.arange(cutoff,n-cutoff+1)]/np.sum(up_xa_s_neut[:,np.arange(cutoff,n-cutoff+1)])\n",
    "p_xa_s_neut = np.sum(up_xa_s_neut, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "testup_xa_s = {}\n",
    "testup_xa_s[gamma[6]] = run_mom_integrate(80000, 2000, 0.5*g/N, N, mu, misc = {'dt_fac':0.02, 'adapt_dt':True})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testup_xa_s[gamma[6]][:,np.arange(cutoff,n-cutoff+1)] = testup_xa_s[gamma[6]][:,np.arange(cutoff,n-cutoff+1)]/np.sum(testup_xa_s[gamma[6]][:,np.arange(cutoff,n-cutoff+1)])\n",
    "fs = moments.Spectrum(np.zeros(2000 + 1))\n",
    "fs[1] = 1\n",
    "fs.integrate([1], 120000/2/N, gamma=gamma[-1], theta=0, adapt_dt=True, dt_fac=0.0001)\n",
    "testp_xa_s = fs\n",
    "testp_xa_s[cutoff:(2000-cutoff+1)] = fs[cutoff:(2000-cutoff+1)]/np.sum(fs[cutoff:(2000-cutoff+1)])\n",
    "plt.plot(np.arange(2,1001),testp_xa_s[2:1001],marker='o'); plt.loglog()\n",
    "# testp_xa_s = np.sum(testup_xa_s[gamma[6]], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# use these plots to figure out when to stop (for gamma<1, ok could stop at 10k for high gamma)\n",
    "plt.scatter(np.arange(100000)[::-1],(np.sum(up_xa_s[-1.],axis=1)),alpha=0.7,color='k')\n",
    "plt.scatter(np.arange(100000)[::-1],(np.sum(up_xa_s[-.1],axis=1)),alpha=0.7,color='grey')\n",
    "plt.loglog(); plt.xlabel('gens'); plt.ylabel('exp # of seg sites')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## scaling the matrix from above to get pdf (all rows sum to 1)\n",
    "cutoff = 2 # 2 x # of inds\n",
    "for g in gamma2:\n",
    "    # normalizing by rows (summing across gens)\n",
    "    # p_xa_s[g] = up_xa_s[g]/up_xa_s[g].sum(axis=0,keepdims=1)\n",
    "    # up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)] = up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)]/up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)].sum(axis=1,keepdims=True)\n",
    "    # normalizing by rows and cols (summing across gens and # of derived alleles)\n",
    "    # p_xa_s[g] = up_xa_s[g]/np.sum(up_xa_s[g])\n",
    "    # normalizing by rows and cols and number of derived alleles (based on if detectable in sample or not)\n",
    "    up_xa_s[g][:,np.arange(cutoff,2000-cutoff+1)] = up_xa_s[g][:,np.arange(cutoff,2000-cutoff+1)]/np.sum(up_xa_s[g][:,np.arange(cutoff,2000-cutoff+1)]) \n",
    "    # normalizing by rows (summing across allele freqs)\n",
    "    # up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)] = up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)]/up_xa_s[g][:,np.arange(cutoff,n-cutoff+1)].sum(axis=1,keepdims=True)\n",
    "\n",
    "# import pickle as pkl\n",
    "# with open('testdata/fsintegrate.pkl', 'wb') as f:\n",
    "#     pkl.dump(up_xa_s, f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## summing across rows and then normalizing to get P(X|\\gamma) \n",
    "# del p_xa_s\n",
    "p_xa_s = {}\n",
    "for g in gamma2:\n",
    "    fs = moments.Spectrum(np.zeros(2000+1))\n",
    "    fs[1] = 1\n",
    "    fs.integrate([0.5], 10, gamma=g)\n",
    "    p_xa_s[g] = fs/np.sum(fs[np.arange(cutoff,2000-cutoff+1)])\n",
    "    # p_xa_s[g] = np.sum(up_xa_s[g], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# moments.Plotting.plot_1d_fs(p_xa_s[gamma2[-15]])\n",
    "gamma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(dpi=120)\n",
    "fs = moments.Spectrum(np.zeros(50)); fs[1] = 1\n",
    "fs.integrate([0.5],4,gamma=-5); fs = fs.project([11])*50/11\n",
    "plt.bar(x=np.arange(1,11),height=np.array(fs[1:-1]/np.sum(fs)),color='pink',alpha=0.8,); plt.xlabel('# of allele copies'); plt.ylabel('E[i|γ]'); plt.ylim((0,1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(p_xa_s[gamma2[-10]],np.sum(up_xa_s[gamma2[-10]],axis=0),alpha=0.8); plt.loglog(); plt.axline((0,0),(1,1),ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.imshow(up_xa_s[gamma[15]],aspect='auto',norm=colors.LogNorm(vmax=1e-7,vmin=1e-20)); plt.colorbar()\n",
    "# np.min(p_xa_s[gamma[4]][10,:])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Reading in simulation data for comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import os\n",
    "# os.chdir(\"/Users/vivaswatshastry/selCoefEst/PReFerSims\")\n",
    "## using the Rcpp code to simulate population allele freqs\n",
    "# df2 = pd.read_csv(\"../traindata/trip-2022-03-29.csv\")\n",
    "# df2['gamma'] = df2['gamma'].round(decimals=2)\n",
    "# df2['empty'] = ''\n",
    "# df2['empty2'] = ''\n",
    "# df2['sXl'] = rng.binomial(n=2000, p=df2['Xl'])\n",
    "# gamma = np.unique(df2['gamma'])\n",
    "## using PReFerSim to simulate sample allele freqs (already simulated, just reading in)\n",
    "gamma = np.array([-100.,-30.,-10.,-3.,-1.])\n",
    "Xldata = np.empty(1,dtype='int'); aldata = np.empty(1,dtype='int'); gldata = np.empty(1)\n",
    "for g in gamma:\n",
    "    df = pd.read_csv(\"outfiles/ConstantSize{}_n400_sim{}.3.full_out.txt\".format(-g,12),sep='\\t',header=None,)\n",
    "    df.columns = ['','Xl','s','al','id']\n",
    "    df['empty'] = ''\n",
    "    # Xldata.append((df['Xl']*400).astype('int').tolist())\n",
    "    Xldata = np.append(Xldata,(df['Xl']*400).astype('int').tolist())\n",
    "    df['al'] = 80000+1 - df['al']\n",
    "    aldata = np.append(aldata,df['al'].astype('int').tolist())\n",
    "    gldata = np.append(gldata,np.repeat(g,len(df)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2 = pd.DataFrame({'g':gldata[1:],'X':Xldata[1:],'a':aldata[1:]})\n",
    "dat2 = df2.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'gamma' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Input \u001b[0;32mIn [8]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# df1['sXl'] = np.around(df1['Xl']*n).astype(int)\u001b[39;00m\n\u001b[1;32m      2\u001b[0m nsites \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m\n\u001b[0;32m----> 3\u001b[0m idx2keep \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mempty(\u001b[38;5;28mlen\u001b[39m(\u001b[43mgamma\u001b[49m)\u001b[38;5;241m*\u001b[39mnsites,dtype\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mint\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m ig, _ \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(gamma):\n\u001b[1;32m      5\u001b[0m     idx2keep[(ig\u001b[38;5;241m*\u001b[39mnsites):(ig\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39mnsites] \u001b[38;5;241m=\u001b[39m rng\u001b[38;5;241m.\u001b[39mchoice(np\u001b[38;5;241m.\u001b[39mwhere(df2[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msXl\u001b[39m\u001b[38;5;124m'\u001b[39m][(ig\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5000\u001b[39m):(ig\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m)\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5000\u001b[39m]\u001b[38;5;241m>\u001b[39m\u001b[38;5;241m1\u001b[39m)[\u001b[38;5;241m0\u001b[39m], nsites, \u001b[38;5;28;01mFalse\u001b[39;00m) \u001b[38;5;241m+\u001b[39m ig\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m5000\u001b[39m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'gamma' is not defined"
     ]
    }
   ],
   "source": [
    "# df1['sXl'] = np.around(df1['Xl']*n).astype(int)\n",
    "nsites = 2000\n",
    "idx2keep = np.empty(len(gamma)*nsites,dtype='int')\n",
    "for ig, _ in enumerate(gamma):\n",
    "    idx2keep[(ig*nsites):(ig+1)*nsites] = rng.choice(np.where(df2['sXl'][(ig*5000):(ig+1)*5000]>1)[0], nsites, False) + ig*5000\n",
    "df2 = df2.iloc[idx2keep,:]\n",
    "dat2 = df2.to_numpy()\n",
    "df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from statsmodels.distributions.empirical_distribution import ECDF\n",
    "## PReFerSim selection coefficient is HALF of backward WF sims (need to test this further—simple to rerun cell, but long runtime)\n",
    "def plot_ecdf_al_sxl(idx):\n",
    "    indices = np.arange((19*1000),(19+1)*1000)\n",
    "    indices2 = np.arange((16*1000),(16+1)*1000)\n",
    "    age1_ecdf = ECDF(df1['al'][::-1].iloc[indices])\n",
    "    age2_ecdf = ECDF(df2['al'].iloc[indices2])\n",
    "    x = np.linspace(1,np.max(df2['al'].iloc[indices]))\n",
    "    y1 = age1_ecdf(x)\n",
    "    y2 = age2_ecdf(x)\n",
    "    plt.plot(x, y1, color='green', alpha=0.7, label='PReFerSim vals'); plt.xlabel('age (gens)'); plt.semilogx()\n",
    "    plt.plot(x, y2, color='purple', alpha=0.7, label='backward approx WF vals'); plt.title('γ={}'.format(gamma[0])); plt.legend()\n",
    "\n",
    "plot_ecdf_al_sxl(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df2['gamma'].iloc[np.arange((16*1000),(16+1)*1000)], df1['s'][::-1].iloc[np.arange((19*1000),(19+1)*1000)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# interpolate gamma (in other words, I need a denser grid of gamma values around the MLE for better quadratic estimation)\n",
    "interp_gamma = np.zeros((len(gamma),5))\n",
    "interp_gamma[0,] = -np.exp(np.linspace(np.log(-gamma[1]),np.log(125),5))\n",
    "for ig, g in enumerate(gamma[1:-1]):\n",
    "    interp_gamma[ig+1,] = -np.exp(np.linspace(np.log(-gamma[ig+2]),np.log(-gamma[ig]),5))\n",
    "interp_gamma[-1,] = -np.exp(np.linspace(np.log(0.7),np.log(-gamma[-2]),5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## going through and deleting entries that are very close to each other (tol=1)\n",
    "interp_gamma = interp_gamma.round(2)\n",
    "print(interp_gamma)\n",
    "it_gamma = np.unique(np.hstack((gamma,np.ravel(interp_gamma))))\n",
    "it_gamma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function to obtain the log P(X,|gamma)\n",
    "def get_lp_xl(g, sXlred, n=2000, cutoff=20):\n",
    "    \"\"\"function to compute L(gamma|Xl), where gamma is a range of values and Xl is a given set of freqs\"\"\"\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1))) #np.empty(len(Xlred))\n",
    "\n",
    "    # just performing a search in a look-up table\n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[idx] = p_xa_s[g][sXlred[i]]\n",
    "    \n",
    "    return np.log(res)\n",
    "\n",
    "def get_lp_xl2(g, sXlred, n=2000, cutoff=20):\n",
    "    \"\"\"function to compute L(gamma|Xl), where gamma is a range of values and Xl is a given set of freqs\"\"\"\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1))) #np.empty(len(Xlred))\n",
    "\n",
    "    # ub = np.exp(2.*g)*scipy.special.expi(-2.*g*0.25/N) - scipy.special.expi(2.*g*(1-0.25/N)) - np.exp(2.*g)*(np.log(0.25/N) - np.log(1-0.25/N))\n",
    "    # lb = np.exp(2.*g)*scipy.special.expi(2.*g*(0.25/N-1)) - scipy.special.expi(2.*g*0.25/N) - np.exp(2.*g)*(np.log(1-0.25/N) - np.log(0.25/N))\n",
    "    ub = np.exp(2.*g)*sp.special.expi(-2.*g*0.5*cutoff/n) - sp.special.expi(2.*g*(1-0.5*cutoff/n)) - np.exp(2.*g)*(np.log(0.5*cutoff/n) - np.log(1-0.5*cutoff/n))\n",
    "    lb = np.exp(2.*g)*sp.special.expi(2.*g*(0.5*cutoff/n-1)) - sp.special.expi(2.*g*0.5*cutoff/n) - np.exp(2.*g)*(np.log(1-0.25/n) - np.log(0.5*cutoff/n))\n",
    "    scalfact = (ub - lb)/np.expm1(2.*g)\n",
    "\n",
    "    # return a vector...\n",
    "    for isx, sx in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[isx] = (1-np.exp(-2*g*(1-sXlred[sx]/n)))/(sXlred[sx]/n*(1-sXlred[sx]/n)*(1-np.exp(-2*g)))\n",
    "\n",
    "    return np.log(res/scalfact)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## don't need a function since the dict already exists\n",
    "Xsamp = np.arange(1,n+1)/n\n",
    "plt.hist([np.argmin(np.abs(dat[i,0]-Xsamp))+1 for i in range(len(dat))],bins=200);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(newdat[:,2],bins=100)\n",
    "# plt.hist2d(np.log(newdat[:,0]),newdat[:,2][::-1],(25,25)); plt.colorbar()\n",
    "# print(newdat[-5:,])\n",
    "np.where(np.isinf(get_lp_alxl(gamma[-2], newdat[:,0], newdat[:,2], 100)))\n",
    "# print(newdat[429,])\n",
    "# get_lp_alxl(gamma[-2], newdat[:,0], newdat[:,2], 100)\n",
    "# sXlred = np.around(newdat[:,0]*100).astype(int)\n",
    "# np.sum((sXlred>0) & (sXlred<100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('error')\n",
    "## just doing a lookup of sorts for the right probability\n",
    "def get_lp_alxl(g, sXlred, alred, n=2000, cutoff=2):\n",
    "    # Xsamp = np.arange(1,n)/n\n",
    "    # sXlred = np.around(Xlred*n).astype(int) # rng.binomial(n, Xlred, len(Xlred))\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1)))\n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        # if too many gens, then pass in a very low number (like -400.)\n",
    "        # res[i] = np.log(p_xa_s[g][-int(alred[i]),np.argmin(np.abs(Xlred[i]-Xsamp))+1]) if (int(alred[i]<p_xa_s[g].shape[0])) else -400. \n",
    "        try:\n",
    "            res[idx] = np.log(up_xa_s[g][-int(alred[i]),sXlred[i]]) if (int(alred[i])<up_xa_s[g].shape[0]) else np.median(np.log(up_xa_s[g][0,cutoff:(n-cutoff+1)]))\n",
    "        except RuntimeWarning:\n",
    "            print(g, sXlred[i], alred[i])\n",
    "        # if np.isinf(res[idx]):\n",
    "        #     print(i, Xlred[i], alred[i])\n",
    "\n",
    "    return res\n",
    "\n",
    "def get_lp_alxl_nocheck(g, sXlred, alred, n=2000, cutoff=2):\n",
    "    ## version of function with no check for cutoff\n",
    "    res = np.log(up_xa_s[g][-int(alred),sXlred]) if (int(alred)<up_xa_s[g].shape[0]) else np.median(np.log(up_xa_s[g][0,cutoff:(n-cutoff+1)]))\n",
    "\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## finding how many alleles have ages beyond computed values in the lookup matrix/table (like 4)\n",
    "for ig, g in enumerate(gamma):\n",
    "    alred = df1['al'].iloc[ig*1000:(ig+1)*1000]\n",
    "    print(g, np.sum(alred>up_xa_s[g].shape[0]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Code to run continuous optimization of framework instead of dicrete grid\n",
    "\n",
    "Here, I will construct a method to compute the likelihood of a given dataset for any $\\gamma$ value. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll_freq(g, sXlred, n=2000, cutoff=2):\n",
    "    fs = moments.Spectrum(np.zeros(n+1))\n",
    "    fs[1] = 1\n",
    "    fs.integrate([0.5], 10, gamma=g)\n",
    "    pxs = fs/np.sum(fs[np.arange(cutoff,n-cutoff+1)])\n",
    "\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1))) #np.empty(len(Xlred))\n",
    "\n",
    "    # just performing a search in a look-up table\n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[idx] = pxs[sXlred[i]]\n",
    "    \n",
    "    return -np.sum(np.log(res))\n",
    "@jit(forceobj=True)\n",
    "def get_ll_freqage(g, sXlred, alred, n=2000, cutoff=2):\n",
    "    pxas = run_mom_iterate(int(100000+900*g), n, 0.5*g/N, N, 1.25e-8, misc = {'dt_fac':0.02, 'adapt_dt':True})\n",
    "    \n",
    "    pxas[:,np.arange(cutoff,n-cutoff+1)] = pxas[:,np.arange(cutoff,n-cutoff+1)]/np.sum(pxas[:,np.arange(cutoff,n-cutoff+1)]) \n",
    "\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1)),dtype='float32')\n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[idx] = np.log(pxas[-int(alred[i]),sXlred[i]]) if (int(alred[i])<pxas.shape[0]) else np.median(np.log(pxas[0,cutoff:(n-cutoff+1)]))\n",
    "\n",
    "    return -np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_sims = 16\n",
    "parestfreq = np.zeros((4,num_sims))\n",
    "parestage = np.zeros((4,num_sims))\n",
    "for ig, g in enumerate([1.,10.,100.]):\n",
    "    for n in range(num_sims):\n",
    "        with open('simfiles/ParameterFilesConstant.txt',\"r\") as file:\n",
    "            data = file.readlines()\n",
    "\n",
    "        data[0] = 'MutationRate: {:f}\\n'.format(2)\n",
    "        data[2] = 'DFEPointSelectionCoefficient: {:.8f}\\n'.format(-0.5*g/10000)\n",
    "        data[7] = 'FilePrefix: outfiles/ConstantSize{}_n{}_sim{}_t2\\n'.format(-g,400,n)\n",
    "\n",
    "        with open('simfiles/ParameterFilesConstant.txt', 'w') as file:\n",
    "            file.writelines(data)\n",
    "        \n",
    "        os.system(\"GSL_RNG_SEED={} GSL_RNG_TYPE=mrg ../../PReFerSim/PReFerSim simfiles/ParameterFilesConstant.txt 3 > /dev/null 2>&1 \".format(rng.integers(100496)))\n",
    "\n",
    "        dft = pd.read_csv('outfiles/ConstantSize{}_n{}_sim{}_t2.3.full_out.txt'.format(-g,400,n),sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "        dft['empty'] = ''\n",
    "        dft['sXl'] = (dft['Xl']*400).astype('int')\n",
    "        dft['al'] = 80000+1 - dft['al']\n",
    "        dft['al'] = dft['al'].astype('int')\n",
    "        dft = dft.iloc[:,1:]\n",
    "        datt = dft.to_numpy()\n",
    "\n",
    "        SMS = np.zeros((80000,400+1),dtype='int16')\n",
    "        mask = np.zeros_like(SMS); mask[0,:] = 1; mask[:,0] = 1; mask[:,-1] = 1;\n",
    "        for i in range(len(datt)):\n",
    "            SMS[datt[i,2],datt[i,5]] += 1\n",
    "        SMSmask = np.ma.array(SMS,mask=mask)\n",
    "\n",
    "        sfs = moments.Spectrum(np.histogram(datt[:,5],bins=range(0,402))[0])\n",
    "\n",
    "        # parestfreq[ig,n] = sp.optimize.minimize_scalar(get_ll_freq, args=(datt[:,5]), options={'xtol': .05,}).x\n",
    "        # parestage[ig,n] = sp.optimize.minimize_scalar(get_ll_freqage, args=(datt[:,5], datt[:,2]), options={'xtol': .2}).x\n",
    "        parestfreq[ig,n] = sp.optimize.minimize_scalar(get_ll_freqconstant_notfm,args=({'sfs':sfs,'theta':2,'p_misid':0},400)).x\n",
    "        parestage[ig,n] = sp.optimize.minimize_scalar(get_ll_freqageconstant_notfm,args=({'sms':SMSmask,'theta':2,'N':10000,'p_misid':0,'gens':80000},400)).x\n",
    "\n",
    "        print(parestfreq[ig,n],parestage[ig,n])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.optimize.minimize_scalar(get_ll_freqconstant_notfm,args=({'sfs':sfs,'theta':200,'p_misid':0},400)).x, sp.optimize.minimize_scalar(get_ll_freqageconstant_notfm,args=({'sms':SMSmask,'theta':200,'N':10000,'p_misid':0,'gens':80000},400)).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parestfreq, parestage/2\n",
    "# 10**sp.optimize.minimize_scalar(get_ll_freqageconstant,args=({'sms':SMSmask,'theta':400,'N':10000,'p_misid':0,'gens':80000},400),).x\n",
    "# 10**sp.optimize.minimize_scalar(get_ll_freqageconstant,args=({'sms':SMSmask,'theta':4,'N':10000,'p_misid':0,'gens':80000},400),).x\n",
    "# run_mom_iterate_constant??\n",
    "# -10**sp.optimize.minimize_scalar(get_ll_freqconstant,args=({'sfs':sfs,'theta':400,'p_misid':0},200)).x\n",
    "# parestfreq.std(axis=1)\n",
    "# dft = pd.read_csv('PReFerSims/outfiles/ConstantSize0.0.1.full_out.txt',sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "# dft['empty'] = ''\n",
    "# dft['sXl'] = (dft['Xl']*400).astype('int')\n",
    "# dft['al'] = 80000+1 - dft['al']\n",
    "# dft['al'] = dft['al'].astype('int')\n",
    "# dft = dft.iloc[:,1:]\n",
    "# datt = dft.to_numpy()\n",
    "\n",
    "# sfs = moments.Spectrum(np.histogram(datt[:,5],bins=range(0,402))[0])\n",
    "# print(sp.optimize.minimize_scalar(get_ll_freqconstant_notfm,args=({'sfs':sfs,'theta':400,'p_misid':0},400)))\n",
    "\n",
    "# SMS = np.zeros((80000,400+1),dtype='int16')\n",
    "# mask = np.zeros_like(SMS); mask[0,:] = 1; mask[:,0] = 1; mask[:,-1] = 1;\n",
    "# for i in range(len(datt)):\n",
    "#     SMS[datt[i,2],datt[i,5]] += 1\n",
    "# SMSmask = np.ma.array(SMS,mask=mask)\n",
    "# plt.plot(np.linspace(-125,125,20),[get_ll_freqageconstant_notfm(g,{'sms':SMSmask,'theta':4,'N':10000,'p_misid':0,'gens':80000},400) for g in np.linspace(-125,125,20)],'ko')\n",
    "# sp.optimize.minimize_scalar(get_ll_freqageconstant_notfm,args=({'sms':SMSmask,'theta':400,'N':10000,'p_misid':0,'gens':80000},400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parestfreq = -np.array([[100.756, 104.793, 104.931, 99.876, 98.784, 90.711, 97.843, 101.897, 100.753, 99.271],\n",
    "#         [9.616, 9.769, 10.315, 9.405, 10.001, 9.913, 9.895, 9.425, 9.713, 10.653],\n",
    "#         [1.113, 1.151, 1.204, 0.938, 1.036, 0.911, 1.122, 0.915, 1.026, 1.046],\n",
    "#         [-4.35832402069063e-45, -4.35832402069063e-45, -4.35832402069063e-45, -4.35832402069063e-45, -4.35832402069063e-45, -1.971976596466917e-15, -1.971976596466917e-15, -1.971975942072855e-15, -4.35832402069063e-45, -4.35832402069063e-45, -4.35832402069063e-45]])\n",
    "# parestage = -np.array([[107.958, 103.559, 111.178, 105.733, 98.938, 95.403, 104.087, 104.810, 103.923, 106.285],\n",
    "#         [10.354, 9.969, 10.613, 9.571, 10.331, 10.372, 10.616, 9.793, 10.120, 11.210],\n",
    "#         [1.005, 1.193, 1.148, 0.99, 0.846, 1.126, 0.93, 1.089, 1.044, 1.02]])\n",
    "\n",
    "# parestage = np.array([[-72.638, -72.416, -72.477, -72.360, -72.582, -72.191, -72.398,\n",
    "#          -72.534, -72.418, -72.591, -72.341, -72.598, -72.206, -72.451,\n",
    "#          -72.207, -72.625, -72.508, -72.380, -72.447, -72.224],\n",
    "#         [-25.950, -26.648, -25.815, -27.308, -26.011, -26.545, -25.472,\n",
    "#          -26.114, -25.423, -26.061, -25.936, -25.875, -25.913, -26.334,\n",
    "#          -26.247, -26.006, -27.079, -26.789, -26.381, -26.240],\n",
    "#         [-11.182, -10.847, -10.509, -10.994, -10.700, -10.616, -10.484,\n",
    "#          -10.843, -10.313, -11.236, -10.623, -10.742, -10.775, -10.517,\n",
    "#          -10.198, -10.811, -10.679, -10.517, -11.417, -10.289],\n",
    "#         [-2.967, -3.017, -3.077, -2.870, -2.618, -3.203, -3.312, -2.521,\n",
    "#          -2.955, -2.772, -2.618, -2.797, -2.593, -2.700, -3.156, -3.265, -3.135, -2.559, -2.755, -2.576],\n",
    "#         [-0.995, -0.618, -0.618, -0.618, -0.618, -0.908, -0.618, -0.618,\n",
    "#          -0.618, -0.618, -0.618, -0.618, -1.181, -0.618, -0.742, -0.618, -0.818, -0.742, -0.618, -0.742]],dtype=float)\n",
    "\n",
    "# parestfreq = np.array(([[-76.064, -70.595, -72.271, -70.274, -76.273, -66.556, -69.697, -74.476, -70.613, -73.723, -71.448, -74.220, -67.808, -71.549, -66.524, -77.530, -74.721, -71.273, -71.199, -66.284],[-23.513, -25.072, -24.235, -24.239, -23.385, -26.478, -23.393, -25.434, -22.406, -23.127, -24.769, -24.344, -24.670, -24.671, -23.045, -22.772, -27.346, -26.433, -24.705, -23.759],[-9.703, -7.282, -8.675, -7.885, -8.933, -9.850, -6.890, -7.391, -10.592, -7.572, -16.959, -7.963, -6.882, -17.281, -10.580, -19.203, -7.826, -18.361, -10.170, -9.423],[-1.969, -1.924, -1.915, -2.075, -2.034, -2.074, -2.038, -1.928, -2.039, -2.079, -2.634, -2.056, -1.916, -2.645, -2.654, -2.971, -2.752, -1.876,\n",
    "#        -2.518, -2.279],[-1.346, -0.618, -0.960, -0.618, -0.916, -1.148, -0.618, -0.618,-1.016, -0.824, -0.618, -0.814, -1.439, -0.943, -0.930, -1.000, -1.083, -0.885, -0.950, -0.964]]),dtype=float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def setViolColors(bp):\n",
    "    bp['bodies'][0].set_facecolor('deepskyblue')\n",
    "    bp['bodies'][0].set_alpha(0.8)\n",
    "    bp['bodies'][0].set_linewidth(1)\n",
    "    bp['cbars'].set_colors('grey')\n",
    "    bp['cbars'].set_alpha(0.6)\n",
    "    bp['cmins'].set_color('grey')\n",
    "    bp['cmaxes'].set_color('grey')\n",
    "    # plt.setp(bp['cbars'][0], color='deepskyblue')\n",
    "    # plt.setp(bp['caps'][1], color='deepskyblue')\n",
    "    # plt.setp(bp['whiskers'][0], color='deepskyblue')\n",
    "    # plt.setp(bp['whiskers'][1], color='deepskyblue')\n",
    "    # plt.setp(bp['fliers'][0], color='deepskyblue')\n",
    "    # plt.setp(bp['medians'][0], color='deepskyblue')\n",
    "\n",
    "    plt.setp(bp['bodies'][1], color='coral', alpha=0.8)\n",
    "    # plt.setp(bp['cbars'][1], color='coral')\n",
    "    # plt.setp(bp['caps'][3], color='coral')\n",
    "    # plt.setp(bp['whiskers'][2], color='coral')\n",
    "    # plt.setp(bp['whiskers'][3], color='coral')\n",
    "    # plt.setp(bp['fliers'][1], color='coral')\n",
    "    # plt.setp(bp['medians'][1], color='coral')\n",
    "\n",
    "fig = plt.figure(dpi=130)\n",
    "ax = plt.axes()\n",
    "s = np.array([-100.,-10.,-1.,0])\n",
    "# hold(True)\n",
    "\n",
    "for i in range(len(s)):\n",
    "    # bp = plt.boxplot([parestfreq[i,~np.isnan(parestfreq[i,:])],parestage[i,~np.isnan(parestage[i,:])]],positions=[3*i+1,3*i+2], widths=0.6,flierprops=dict(marker='x',markersize=5,alpha=0.5),)\n",
    "    # setBoxColors(bp)\n",
    "    vp = plt.violinplot([parestfreq[i,:],parestage[i,:]],positions=[3*i+1,3*i+2], widths=0.6,)\n",
    "    setViolColors(vp)\n",
    "    plt.axhline(s[i],color='grey',ls='--',alpha=0.6)\n",
    "\n",
    "# bp = plt.boxplot([parestfreq0,parestage0],positions=[16,17],widths=0.6,flierprops=dict(marker='x',markersize=5,alpha=0.5))\n",
    "# setBoxColors(bp) \n",
    "# vp = plt.violinplot([-parestfreq[-1,:],-parestage[-1,:]],positions=[9,10],widths=0.6,)\n",
    "# setViolColors(vp)\n",
    "# plt.axhline(0.,color='grey',ls='--',alpha=0.6);\n",
    "\n",
    "# ax.set_xticks([1.5,4.5,7.5,10.5,13.5,16.5]); ax.set_xticklabels(np.ravel(s.tolist()+[0.])); ax.set_yscale('symlog');\n",
    "ax.set_xticks([1.5,4.5,7.5,10.5]); ax.set_xticklabels(np.ravel(s.tolist())); ax.set_yscale('symlog'); ax.set_yticks([-100.,-10.,-1.,0,]); plt.grid()\n",
    "\n",
    "hB, = plt.plot([1,0],'-',color='deepskyblue'); hR, = plt.plot([1,0],'-',color='coral'); hB.set_visible(False); hR.set_visible(False)\n",
    "plt.xlabel('true γ value'); plt.ylabel('MLE γ value (20 replicates)')\n",
    "plt.legend((hB, hR),('freq only, RMSLE: {:.2f}'.format(np.sqrt(np.mean((np.log10(-s+1)-np.log10(np.nanmean(parestfreq,axis=1)))**2))), 'freq & age, RMSLE: {:.2f}'.format(np.sqrt(np.mean((np.log10(-s+1)-np.log10(np.nanmean(parestage,axis=1)))**2)))),loc='upper left')\n",
    "# plt.savefig(\"../figs/MLEfreqage2.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot([-100,-10,-1,0],np.std(parestfreq,axis=1)/np.std(parestage,axis=1),'k-o', alpha=0.7); plt.xscale('symlog'); plt.ylabel('ratio of SD'); plt.xlabel(r'$\\gamma$'); plt.axhline(1,color='grey')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dft = pd.read_csv('outfiles/ConstantSize100.0.3.full_out.txt',sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "dft['empty'] = ''\n",
    "dft['sXl'] = (dft['Xl']*400).astype('int')\n",
    "dft['al'] = 80000+1 - dft['al']\n",
    "dft['al'] = dft['al'].astype('int')\n",
    "dft = dft.iloc[:,1:]\n",
    "datt = dft.to_numpy()\n",
    "\n",
    "SMS = np.zeros((80000,400+1),dtype='int16')\n",
    "mask = np.zeros_like(SMS); mask[0,:] = 1; mask[:,0] = 1; mask[:,-1] = 1;\n",
    "for i in range(len(datt)):\n",
    "    if (datt[i,2]<80000) & (datt[i,5]<400):\n",
    "        SMS[datt[i,2],datt[i,5]] += 1\n",
    "SMSmask = np.ma.array(SMS,mask=mask)\n",
    "\n",
    "# thetas = np.logspace(0,2,12)\n",
    "# gammas = np.logspace(-1,2,12,base=10)\n",
    "# ll2d = np.zeros((len(thetas),len(gammas)))\n",
    "# for it, t in enumerate(thetas):\n",
    "#     for ig, g in enumerate(gammas):\n",
    "#         ll2d[it,ig] = get_ll_freqageconstant(np.log10(g),{'sms':SMSmask,'theta':t,'N':10000,'p_misid':0,'gens':50000},400)\n",
    "\n",
    "# plt.imshow(-ll2d+np.min(ll2d),vmin=-1000); plt.colorbar(); plt.ylabel(r'$\\theta$'); plt.xlabel(r'$\\gamma$'); plt.yticks(np.arange(0,12,3),labels=np.round(thetas[::3],1)); plt.xticks(np.arange(0,12,3),labels=np.round(gammas[::3],1)); plt.plot(8,4,'kx'); plt.axvline(8.3,color='red')\n",
    "# plt.plot(np.linspace(1,10,5),[get_ll_freqageconstant(np.log10(10),{'sms':SMSmask,'theta':t,'N':10000,'p_misid':0,'gens':20000},200) for t in np.linspace(1,10,5)])\n",
    "# get_ll_freqageconstant(np.log10(1),{'sms':SMSmask,'theta':400,'N':10000,'p_misid':0,'gens':100000},400), get_ll_freqageconstant(np.log10(1),{'sms':SMSmask,'theta':4,'N':10000,'p_misid':0,'gens':100000},400), get_ll_freqageconstant(np.log10(1e-7),{'sms':SMSmask,'theta':4,'N':10000,'p_misid':0,'gens':100000},400)\n",
    "# sp.optimize.minimize_scalar(get_ll_freqageconstant,args=({'sms':SMSmask,'theta':7.2,'N':10000,'p_misid':0,'gens':50000},400))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "SMSmask.sum(axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Relevent error distribution for allele ages\n",
    "Initially, using a simplification of estimates from Figure 2 in Albers & McVean, 2018 (piecewise-linear fit) with Poisson distributed error. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_age_err(simal, rng, errvar):\n",
    "    erral = np.zeros_like(simal,dtype='int')\n",
    "    mask1 = (simal>0) & (simal<21)\n",
    "    mask2 = (simal>20) & (simal<1001)\n",
    "    mask3 = (simal>1000) & (simal<20001)\n",
    "    mask4 = simal>20000\n",
    "    \n",
    "    erral[mask1] = rng.normal(rng.poisson(10+simal[mask1].astype('int')*1.5, ),errvar[0])\n",
    "    erral[mask2] = rng.normal(rng.poisson(15+simal[mask2].astype('int')*95/98, ),errvar[1])\n",
    "    erral[mask3] = rng.normal(rng.poisson(700+simal[mask3].astype('int')*6/19, ),errvar[2])\n",
    "    erral[mask4] = rng.normal(rng.poisson(2000+simal[mask4].astype('int')*80/98, ),errvar[3])\n",
    "\n",
    "    # erral[mask1] = rng.lognormal(simal[mask1].astype('int')*1.5, 0.02)\n",
    "    # erral[mask2] = rng.lognormal(15+simal[mask2].astype('int')*95/98, 0.02)\n",
    "    # erral[mask3] = rng.lognormal(400+simal[mask3].astype('int')*11/19, 0.02)\n",
    "    # erral[mask4] = rng.lognormal(2000+simal[mask4].astype('int')*80/98, 0.02)\n",
    "\n",
    "    return erral"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# rng = np.random.RandomState(234)\n",
    "# errvar = [20,100,200,1500]\n",
    "errvar = np.repeat(0,4)\n",
    "erral = get_age_err(np.repeat(np.arange(10000)+1,20),rng,errvar)\n",
    "# plt.hist(erral[mask1],50)\n",
    "# plt.hist(simal[mask1],50)\n",
    "plt.figure(dpi=120); plt.scatter(np.repeat(np.arange(10000)+1,20),erral); plt.loglog(); plt.axline((1,1),(100,100),color='grey',ls='--'); plt.grid(); plt.xlabel('true ages', fontsize=9); plt.ylabel('ages with Normal distributed error rates', fontsize=9); plt.xticks(fontsize=10); plt.yticks(fontsize=10)\n",
    "#plt.plot([1,20],[10,35],color='silver',linewidth=1.5); plt.plot([20,1000],[35,1035],color='silver',linewidth=1.5)\n",
    "# mask1 = (simal>0) & (simal<21)\n",
    "# mask2 = (simal>20) & (simal<1001)\n",
    "# mask3 = (simal>1000) & (simal<20001)\n",
    "# mask4 = simal>20000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.repeat(np.arange(5000)+1,10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# trueg1 = -0.01\n",
    "trueg2 = gamma[-10]\n",
    "# newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==trueg1)),0:3].append(df1.iloc[np.ravel(np.where(dat[:,1]==trueg2)),0:3])\n",
    "newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==trueg2)),:]\n",
    "newdat = newdf1.to_numpy()\n",
    "\n",
    "print(gamma2[np.argmax([np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2])])\n",
    "print(gamma2[np.argmax([np.sum(get_lp_alxl_nocheck(g1, newdat[:,5], newdat[:,2], cutoff=2)) for g1 in gamma2])])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "llfreq, llage = np.zeros(len(gamma2)), np.zeros(len(gamma2))\n",
    "for ig, g in enumerate(gamma2):\n",
    "    llfreq[ig] = get_lp_xl(g, newdat[:,5], cutoff=2)\n",
    "    llfreq[ig] = get_lp_alxl(g, newdat[:,5], newdat[:,2], cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## getting parametric bootstrap, basically compute MLE s for each data point and then find the 95% CI/2 std to get info measure\n",
    "mlegfreq = np.zeros((len(gamma),len(newdat)))\n",
    "mlegage = np.zeros((len(gamma),len(newdat)))\n",
    "for it, trueg2 in enumerate(gamma): \n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==trueg2)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    for i in range(len(newdat)):\n",
    "        mlegfreq[it,i] = gamma2[np.argmax([np.log(p_xa_s[g1][newdat[i,5]]) for g1 in gamma2])]\n",
    "        # mlegfreq[it,i] = gamma2[np.argmax([sp.stats.poisson.logpmf(newdat[i,5],mu=p_xa_s[g1][newdat[i,5]]) for g1 in gamma2])]\n",
    "        mlegage[it,i] = gamma2[np.argmax([get_lp_alxl_nocheck(g1, newdat[i,5], newdat[i,2], cutoff=2) for g1 in gamma2])]\n",
    "        # mlegage[it,i] = gamma2[np.argmax([sp.stats.poisson.logpmf(newdat[i,5],mu=np.exp(get_lp_alxl_nocheck(g1, newdat[i,5], newdat[i,2], cutoff=2))) for g1 in gamma2])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum(mlegfreq,axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(newdat[:,5],mleg,alpha=0.4); plt.xlabel('# of derived alleles'); plt.ylabel('MLE γ'); plt.axhline(trueg2, ls='--', color='red')\n",
    "plt.boxplot(np.array([mlegfreq[5,],mlegage[5,]]).T,labels=['freq only', 'freq & age']); plt.axhline(gamma[5],color='red',ls='--'); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(gamma,mlegfreq.std(axis=1/mlegage.std(axis=1),color='k',alpha=0.7); plt.axhline(1,color='grey',ls='--'); plt.grid(); \n",
    "plt.xlabel('γ'); plt.ylabel('SD of freq/SD of freq & age')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(get_lp_xl(g, newdat[:,5], cutoff=10), get_lp_xl2(g, newdat[:,5], cutoff=10), alpha=0.7, color='k', s=2.5); \n",
    "plt.axline((-5.75,1.75),slope=1.,color='grey',ls='--',linewidth=0.5);\n",
    "plt.xlabel('p(X|γ) using moments framework'); plt.ylabel('using PRF approx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sin_onlyfreq = np.empty(len(gamma2))\n",
    "sin_onlyage = np.empty(len(gamma2))\n",
    "# num_sims = 3\n",
    "# num_samps = [35,350,3500]\n",
    "# info_onlyfreq, info_onlyage = np.zeros((len(num_samps),num_sims)), np.zeros((len(num_samps),num_sims))\n",
    "# nboot = 10\n",
    "# for i in range(nboot):\n",
    "#     newdat = newdat[np.random.choice(len(newdat),1000,replace=True)]\n",
    "    # for ig, g in enumerate(gamma):\n",
    "        # sum log prob for each locus\n",
    "        # sin_onlyfreq[ig] = np.sum(get_lp_xl(g, newdat[:,5], cutoff=2))\n",
    "        # sin_onlyage[ig] = np.sum(get_lp_alxl(g, newdat[:,5], newdat[:,2], cutoff=2))\n",
    "        # mle = get_boot_ci(newdat,nboot=2)\n",
    "    # print(gamma[np.argmax(sin_onlyfreq)], gamma[np.argmax(sin_onlyage)])\n",
    "\n",
    "for ig, g in enumerate(gamma2):\n",
    "    sin_onlyfreq[ig] = np.sum(get_lp_xl(g, newdat[:,5], cutoff=2))\n",
    "    sin_onlyage[ig] = np.sum(get_lp_alxl(g, newdat[:,5], newdat[:,2], cutoff=2))\n",
    "\n",
    "# mle = get_boot_ci(newdat,nboot=20)\n",
    "# mle.mean(axis=0), mle.std(axis=0)\n",
    "\n",
    "# for ins, ns in enumerate(num_samps):\n",
    "#     info_onlyfreq[ins,:], info_onlyage[ins,:] = get_info_content(newdat, num_samps=ns, num_sims=num_sims, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get_mean_sd_werr(newdat, nreps=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## compute gain in information for the same number of sites but over a range of gamma\n",
    "gain_info = np.empty((3,num_sims))\n",
    "info_onlyfreq, info_onlyage = np.zeros_like(gain_info), np.zeros_like(gain_info)\n",
    "# for ig, g in enumerate(gamma):\n",
    "#     newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "#     newdat = newdf1.to_numpy()\n",
    "\n",
    "#     info_onlyfreq[2,:], info_onlyage[2,:] = get_info_content(newdat, num_samps=5000, num_sims=num_sims, cutoff=2)\n",
    "#     gain_info[ig,:] = np.divide(info_onlyage[2,:],info_onlyfreq[2,:])\n",
    "\n",
    "## but need to resimulate a bunch of new sites for each gamma (do it only for 1, 10, 100 first)\n",
    "for ig, g in enumerate([-1., -10., -100.]):\n",
    "    for n in range(num_sims):\n",
    "        with open('simfiles/ParameterFilesConstant.txt',\"r\") as file:\n",
    "            data = file.readlines()\n",
    "\n",
    "        data[0] = 'MutationRate: {:f}\\n'.format(250)\n",
    "        data[2] = 'DFEPointSelectionCoefficient: {:.8f}\\n'.format(-0.25*g/10000)\n",
    "        data[7] = 'FilePrefix: outfiles/ConstantSize{}\\n'.format(-g)\n",
    "\n",
    "        with open('simfiles/ParameterFilesConstant.txt', 'w') as file:\n",
    "            file.writelines(data)\n",
    "        \n",
    "        os.system(\"GSL_RNG_SEED={} GSL_RNG_TYPE=mrg ../../PReFerSim/PReFerSim simfiles/ParameterFilesConstant.txt 3 > /dev/null 2>&1 \".format(rng.integers(100496)))\n",
    "\n",
    "        dft = pd.read_csv('outfiles/ConstantSize{}.3.full_out.txt'.format(-g),sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "        dft['empty'] = ''\n",
    "        dft['sXl'] = (dft['Xl']*2000).astype('int')\n",
    "        dft['al'] = 80000+1 - dft['al']\n",
    "        dft['al'] = dft['al'].astype('int')\n",
    "        dft = dft.iloc[:,1:]\n",
    "        if(len(dft)>1000):\n",
    "            datt = dft.sample(n=1000).to_numpy()\n",
    "        else: \n",
    "            datt = dft.to_numpy()\n",
    "\n",
    "        info_onlyfreq[ig,n], info_onlyage[ig,n] = get_info_content(datt, num_samps=len(datt), num_sims=1, cutoff=2)\n",
    "    \n",
    "    gain_info[ig,:] = np.divide(info_onlyage[ig,:],info_onlyfreq[ig,:])\n",
    "    # print(gain_info[ig,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# gain_info[1,:] = [1.412, 1.498, 1.583, 1.728, 1.718, 1.688, 1.489, 1.541, 1.494, 1.526, 1.440, 1.337, 1.306, 1.564, 1.461, 1.488]\n",
    "# gain_info[2,:] = [1.546, 1.551, 1.545, 1.556, 1.542, 1.547, 1.537, 1.538, 1.532, 1.544, 1.546, 1.543, 1.539, 1.551, 1.553, 1.554]\n",
    "# gain_info[0,:] = [np.nan, 1.100, 1.132, 1.092, 1.088, 1.098, 1.104, 1.090, 1.130, 1.099, 1.122, 1.093, 1.094, 1.105, 1.105, 1.118]\n",
    "# (array([1.962, 2.510, 2.103, 1.538, 1.352, 1.590]),\n",
    "#  array([0.267, 0.974, 0.428, 0.224, 0.032, 0.011]))\n",
    "# array([[1.814, 1.361, 1.377, 1.944, 1.836, 1.736, 0.520, 1.882, 1.884,\n",
    "#         1.469, 1.042, 0.974, 1.816, 1.457, 2.198, 2.188],\n",
    "#        [0.074, 0.082, 0.077, 0.176, 0.080, 0.068, 0.077, 0.087, 0.076,\n",
    "#         0.075, 0.070, 0.072, 0.078, 0.073, 0.070, 0.164],\n",
    "#        [1.502, 1.510, 1.494, 1.521, 1.512, 1.539, 1.526, 1.513, 1.521,\n",
    "#         1.517, 1.512, 1.532, 1.483, 1.505, 1.522, 1.516]])\n",
    "# gain_info.mean(axis=1), gain_info.std(axis=1)\n",
    "# mean and sd of -0.1, -1., -10., -100 under 2 different regimes (no error, low GEVA error)\n",
    "gain_info_mean = np.array([[1.048, 0.988, 1.005, 1.019, 1.011, 1.32, 1.484, 1.435, 1.494]])\n",
    "gain_info_sd = np.array([[0.121, 0.06, 0.027, 0.038, 0.017, 0.42, 0.059, 0.135, 0.149]])\n",
    "# gain_info_mean = np.array([[1.048, 1.005, 1.484, 1.494],[0.821,0.838,1.037,1.307]])\n",
    "# gain_info_sd = np.array([[0.121, 0.027, 0.059, 0.149],[0.01,0.037,0.222,0.234]])\n",
    "# no point in computing the gain in information under high error since MLE is not even the same...\n",
    "# gamma[2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(info_onlyage, info_onlyfreq)\n",
    "print(gain_info)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.divide(infoage, infofreq)\n",
    "np.abs([get_bfq(ll_adam, gamma2)[0], get_bfq(sin_onlyfreq, gamma2)[0], get_bfq(sin_onlyage, gamma2)[0]])\n",
    "# -get_bfq(ll_adam-np.max(ll_adam), gamma2)[1]*0.5/get_bfq(ll_adam-np.max(ll_adam), gamma2)[0], -get_bfq(sin_onlyfreq-np.max(sin_onlyfreq), gamma2)[1]*0.5/get_bfq(sin_onlyfreq-np.max(sin_onlyfreq), gamma2)[0], -get_bfq(sin_onlyage-np.max(sin_onlyage), gamma2)[1]*0.5/get_bfq(sin_onlyage-np.max(sin_onlyage), gamma2)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# seaborn.stripplot(data=pd.DataFrame(gain_info.T,columns=gamma),color='salmon',alpha=0.8,size=7); \n",
    "# plt.xlabel('|γ|'); plt.ylabel('gain in information'); plt.title('20 reps of 5000 sites'); plt.grid();\n",
    "plt.figure(dpi=130)\n",
    "plt.scatter(np.array([0.099,0.299,0.99,1.77,3.29,7.29,9.9,29,98]),gain_info_mean[0,:],color='slategrey',alpha=0.9,); \n",
    "# plt.scatter(np.array([0.11,1.01,10.1,102]),gain_info_mean[1,:],color='lightsteeldeepskydeepskydeepskyblue',alpha=0.9,label='GEVA error'); plt.grid()\n",
    "plt.errorbar(np.array([0.099,0.299,0.99,1.77,3.29,7.29,9.9,29,98]),gain_info_mean[0,:],yerr=gain_info_sd[0,:],color='slategrey',alpha=0.9,linewidth=2,ls='none'); plt.xticks(fontsize=10); plt.yticks(fontsize=10)\n",
    "# plt.errorbar(np.array([0.11,1.01,10.1,102]),gain_info_mean[1,:],yerr=gain_info_sd[1,:],color='lightsteelblue',alpha=0.9,linewidth=2,ls='none'); \n",
    "# plt.scatter(-gamma[2:],gain_info[0],alpha=0.8,color='k'); plt.semilogx(); plt.xlabel('|γ|'); plt.title('20 reps of 1000 sites')\n",
    "# plt.errorbar(-gamma[2:],gain_info[0],yerr=2*gain_info[1],color='k',alpha=0.8); plt.grid(); plt.ylabel('gain in info'); \n",
    "plt.axhline(1.,color='grey',ls='--',linewidth=2,alpha=0.7); plt.ylabel('ratio of curvature +/- 1 SD', fontsize=10); plt.xlabel('|γ|', fontsize=16); plt.semilogx(); plt.grid(); #plt.legend(loc=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Working with Adam's log-likelihoods\n",
    "(and data, since we only need a subset of alleles...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ll_adam = np.array([-12779.905577243711,-12779.67560657378,-12779.345559393892,-12778.872363586619,-12778.19492458077,-12777.22714620313,-12775.848879337178,-12773.89494812682,-12771.143604153498,-12767.30870429352,-12762.046666304424,-12755.004172803323,-12745.96462111521,-12735.2182496041,-12724.415368038992,-12718.41220639416,-12729.002025638603,-12781.678920760727,-12925.363284151737,-13238.84902857637]) # using ~ 500 trajectories\n",
    "ll_adam=np.array([-29565.76313316775,-29565.621718394377,-29565.418924835354,-29565.128508755162,-29564.713434007765,-29564.121904008814,-29563.282471330967,-29562.098695611345,-29560.44496421317,-29558.16773914124,-29555.102378376516,-29551.12840744588,-29546.313073918434,-29541.248815564642,-29537.801653373364,-29540.693962031066,-29560.662504959695,-29620.153166439388,-29761.530313756353,-30052.589833320435]) # using ~3000 trajectories \n",
    "# plt.plot(-gamma2,ll_adam-np.max(ll_adam),'-o',alpha=0.5,label='full traj',color='k'); plt.grid(); plt.plot(-gamma2, sin_onlyfreq-np.max(sin_onlyfreq),'-o',alpha=0.5,label=\"only freq\",color='deepskyblue'); plt.plot(-gamma2,sin_onlyage-np.max(sin_onlyage),'-o',alpha=0.5,label=\"freq & age\",color='coral'); plt.ylim((-200,10)); plt.semilogx()\n",
    "plt.plot(-gamma2,ll_adam-np.max(ll_adam),'-o',alpha=0.5,label='full traj',color='k'); plt.grid(); plt.plot(-gamma2, np.sum(mlegfreq,axis=1)-np.max(np.sum(mlegfreq,axis=1)),'-o',alpha=0.5,label=\"only freq\",color='deepskyblue'); plt.plot(-gamma2,np.sum(mlegage,axis=1)-np.max(np.sum(mlegage,axis=1)),'-o',alpha=0.5,label=\"freq & age\",color='coral'); plt.ylim((-200,10)); plt.semilogx()\n",
    "#plt.axvline(-gamma2[np.argmax(sin_onlyage)],color='grey',ls='--'); \n",
    "plt.axvline(100.,color='red',); plt.xlabel('|γ|'); plt.ylabel('log-lik'); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(dft.loc[dft['id'].isin(alls['IDs'])]['sXl']/20,dft.loc[dft['id'].isin(alls['IDs'])]['al'],color='grey',alpha=0.7); plt.xlabel('allele freq (%)'); plt.ylabel('allele age'); plt.semilogy()\n",
    "# datt = dft.loc[dft['id'].isin(alls['IDs'])].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-np.repeat(gamma,num_sims),gain_info,s=10,color='salmon',alpha=0.6); plt.semilogx()\n",
    "plt.xlabel('|γ|'); plt.ylabel('gain in information'); plt.title('20 reps of 5000 sites'); plt.grid();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_boot_ci(newdat, nsamps=1000, nboot=20, cutoff=2):\n",
    "    mle = np.zeros((nboot,2))\n",
    "    sin_onlyfreq, sin_onlyage = np.empty(len(gamma2)), np.empty(len(gamma2))\n",
    "    for i in range(nboot):\n",
    "        newnewdat = newdat[np.random.choice(len(newdat),nsamps,replace=True)]\n",
    "        for ig, g in enumerate(gamma2):\n",
    "            sin_onlyfreq[ig] = np.sum(get_lp_xl(g, newnewdat[:,5], cutoff=cutoff))\n",
    "            sin_onlyage[ig] = np.sum(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff))\n",
    "        \n",
    "        mle[i,0] = gamma2[np.argmax(sin_onlyfreq)]\n",
    "        mle[i,1] = gamma2[np.argmax(sin_onlyage)]\n",
    "\n",
    "    return mle            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mean_sd_werr(newdat, errvar, nreps=20, cutoff=2):\n",
    "    ests = np.zeros(nreps)\n",
    "    sin_onlyage = np.empty(len(gamma2))\n",
    "    for i in range(nreps):\n",
    "        newage = get_age_err(newdat[:,2],rng,errvar)\n",
    "        sin_onlyage = [np.sum(get_lp_alxl(g, newdat[:,5], newage, cutoff=cutoff)) for g in gamma2]\n",
    "        \n",
    "        ests[i] = gamma2[np.argmax(sin_onlyage)]\n",
    "    \n",
    "    return ests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.stripplot(data=pd.DataFrame(np.divide(info_onlyage, info_onlyfreq).T,columns=num_samps),color='salmon',alpha=0.8); \n",
    "plt.xlabel('# of sites'); plt.ylabel('gain in information'); plt.title('γ = {:.1f}'.format(trueg2)); plt.grid(); "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.stripplot(data=pd.DataFrame(info_onlyfreq.T,columns=num_samps), color='deepskyblue', alpha=0.7, label='only freq')\n",
    "seaborn.stripplot(data=pd.DataFrame(info_onlyage.T,columns=num_samps), color='coral', alpha=0.7, label='freq & age')\n",
    "plt.xlabel('# of sites'); plt.ylabel('information measure'); plt.grid(); plt.title('γ = {:.1f}'.format(trueg2)); \n",
    "plt.legend(handles=[mpatches.Patch(color='deepskyblue', label='only freq, total info: {:.2f}'.format(np.sum(info_onlyfreq))), mpatches.Patch(color='coral', label='freq & age, total info: {:.2f}'.format(np.sum(info_onlyage)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_content(newdat, num_samps=800, num_sims=16, cutoff=2):\n",
    "    ci_freq, ci_age = np.zeros(num_sims), np.zeros(num_sims)\n",
    "    for n in range(num_sims):\n",
    "        newnewdat = newdat[rng.choice(newdat.shape[0], num_samps, replace=False),:]\n",
    "        sin_onlyfreq = [np.sum(get_lp_xl(g1, newnewdat[:,5], cutoff=cutoff)) for g1 in gamma2]\n",
    "        sin_onlyage = [np.sum(get_lp_alxl(g1, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff)) for g1 in gamma2]\n",
    "\n",
    "        ci_freq[n] = np.abs(get_bfq(sin_onlyfreq-np.max(sin_onlyfreq), gamma2)[0])\n",
    "        ci_age[n] = np.abs(get_bfq(sin_onlyage-np.max(sin_onlyage), gamma2)[0])\n",
    "\n",
    "    return [ci_freq, ci_age]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_info_content_werr(newdat, errvar, num_samps=800, reps=16, cutoff=2):\n",
    "    ci_freq, ci_age = np.zeros(reps), np.zeros(reps)\n",
    "    for n in range(reps):\n",
    "        newnewdat = newdat[rng.choice(newdat.shape[0], num_samps, replace=False),:]\n",
    "        sin_onlyfreq = [np.sum(get_lp_xl(g1, newnewdat[:,5], cutoff=cutoff)) for g1 in gamma2]\n",
    "        ci_freq[n] = np.abs(get_bfq(sin_onlyfreq-np.max(sin_onlyfreq), gamma2)[0])\n",
    "        for r in range(reps):\n",
    "            newage = get_age_err(newnewdat[:,2],rng,errvar)\n",
    "            sin_onlyage = [np.sum(get_lp_alxl(g1, newnewdat[:,5], newage, cutoff=cutoff)) for g1 in gamma2]\n",
    "            # print(gamma2[np.argmax(sin_onlyage)])\n",
    "            ci_age[n] += np.abs(get_bfq(sin_onlyage-np.max(sin_onlyage), gamma2)[0])\n",
    "\n",
    "    return [ci_freq, ci_age/reps]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_conf_int(loglik, thresh=2):\n",
    "    mle = gamma[np.argmax(loglik)]\n",
    "\n",
    "    if mle==np.min(gamma):\n",
    "        lower_thresh = gamma[1]  \n",
    "        return [(np.max(loglik)-thresh-loglik[np.argmax(loglik)+1])/(np.max(loglik) - loglik[np.argmax(loglik)+1])/(mle - lower_thresh)+lower_thresh, mle]\n",
    "    elif mle==np.max(gamma):\n",
    "        upper_thresh = gamma[-2] \n",
    "        return [mle, -thresh/(loglik[np.argmax(loglik)-1] - np.max(loglik))/(upper_thresh - mle)+mle]\n",
    "    else:\n",
    "        lower_thresh = gamma[np.argmax(loglik)+1] \n",
    "        upper_thresh = gamma[np.argmax(loglik)-1] \n",
    "        return [(np.max(loglik)-thresh-loglik[np.argmax(loglik)+1])*(mle - lower_thresh)/(np.max(loglik) - loglik[np.argmax(loglik)+1])+lower_thresh, -thresh*(upper_thresh - mle)/(loglik[np.argmax(loglik)-1] - np.max(loglik))+mle,]\n",
    "        # return [(np.max(loglik)-thresh-loglik[np.argmax(loglik)+1])/(np.max(loglik) - loglik[np.argmax(loglik)+1])/(mle - lower_thresh)+lower_thresh, -thresh/(loglik[np.argmax(loglik)-1] - np.max(loglik))/(upper_thresh - mle)+mle]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run the same search on a denser grid\n",
    "win_sin_onlyfreq = np.empty(interp_gamma.shape[1])\n",
    "for ig, g in enumerate(interp_gamma[np.argmax(sin_onlyfreq),]):\n",
    "    win_sin_onlyfreq[ig] = np.sum(get_lp_xl(g, newdat[:,5], cutoff=10))\n",
    "\n",
    "win_sin_onlyage = np.empty(interp_gamma.shape[1])\n",
    "for ig, g in enumerate(interp_gamma[np.argmax(sin_onlyage),]):\n",
    "    win_sin_onlyage[ig] = np.sum(get_lp_alxl(g, newdat[:,5], newdat[:,2], cutoff=10))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "densegrid = -np.logspace(0,2,base=10,num=100)\n",
    "lxlbfq = get_bfq(sin_onlyfreq-np.max(sin_onlyfreq), gamma) @ np.vstack((densegrid**2, densegrid,np.repeat(1.0,100)))\n",
    "# lxlbfq = get_bfq_win(sin_onlyfreq-np.max(sin_onlyfreq), gamma) @ np.vstack((np.repeat(1.0,len(gamma)), gamma, gamma**2,))\n",
    "# lxlalbfq = np.polynomial.polynomial.Polynomial.fit(gamma[7:10],(sin_onlyage-np.max(sin_onlyage))[7:10],deg=2).coef @ np.vstack((np.repeat(1.0,4), gamma[(np.argmax(sin_onlyage)-1):(np.argmax(sin_onlyage)+3)], gamma[(np.argmax(sin_onlyage)-1):(np.argmax(sin_onlyage)+3)]**2,))\n",
    "lxlalbfq = get_bfq(sin_onlyage-np.max(sin_onlyage), gamma) @ np.vstack((densegrid**2, densegrid,np.repeat(1.0,100)))\n",
    "# lxlalbfq = get_bfq_win(sin_onlyage-np.max(sin_onlyage), gamma) @ np.vstack((np.repeat(1.0,len(gamma)), gamma, gamma**2,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(-gamma2, sin_onlyfreq-np.max(sin_onlyfreq),'grey', label='freq'); plt.ylim((-10,1)); plt.xlabel('est gamma')\n",
    "plt.axvline(-gamma2[np.argmax(sin_onlyfreq)], color='grey', linestyle='--'); \n",
    "# plt.plot(-densegrid, lxlbfq-np.max(lxlbfq), color='deepskyblue', alpha=0.6,label='best-fit quadratic Xl');#interp_gamma\n",
    "plt.axvline(1., color='red', ls='--'); plt.semilogx()\n",
    "plt.plot(-gamma2, sin_onlyage-np.max(sin_onlyage),'k', label='freq & age'); plt.ylim((-10,1)); \n",
    "# plt.plot(-densegrid, lxlalbfq-np.max(lxlalbfq), color='coral', alpha=0.6,label='best-fit quadratic Xl, al');#interp_gamma[np.argmax(sin_onlyage)]\n",
    "plt.axvline(-gamma2[np.argmax(sin_onlyage)], color='k', linestyle='--'); plt.ylabel('log-lik units'); plt.legend(); plt.grid()\n",
    "plt.axhline(-2.,color='red',alpha=0.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_bfq(loglik, gamma):\n",
    "    ## does not work for some reason—wasted multiple hours on it...\n",
    "    # return np.polynomial.polynomial.Polynomial.fit(-gamma[(ig-3):(ig+3)], loglik[(ig-3):(ig+3)], deg=2)\n",
    "    igamma = gamma[(np.argmax(loglik)-1):(np.argmax(loglik)+2)] if np.argmax(loglik)>0 else gamma[0:3]\n",
    "    loglik = loglik[(np.argmax(loglik)-1):(np.argmax(loglik)+2)] if np.argmax(loglik)>0 else loglik[0:3]\n",
    "\n",
    "    rhs = np.array([np.dot(igamma**2,loglik), np.dot(igamma,loglik), np.sum(loglik)])\n",
    "    lhs = np.array([[np.sum(igamma**4), np.sum(igamma**3), np.sum(igamma**2)],\n",
    "    [np.sum(igamma**3), np.sum(igamma**2), np.sum(igamma)],\n",
    "    [np.sum(igamma**2), np.sum(igamma), len(igamma)]])\n",
    "\n",
    "    return np.linalg.solve(lhs, rhs) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sin_onlyfreq = np.zeros(len(s))\n",
    "ci_sin_onlyfreq = np.zeros((len(s),2))\n",
    "\n",
    "for ig, g in enumerate(s):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    # sin_onlyfreq = [np.sum(get_lp_xl(g1, newdat[:,5], cutoff=5)) for g1 in gamma]\n",
    "    # preds_sin_onlyfreq[ig] = gamma[np.argmax(sin_onlyfreq)]\n",
    "    # ci_sin_onlyfreq[ig] = 1/np.abs(get_bfq(sin_onlyfreq - np.argmax(sin_onlyfreq), gamma)[0]) # get_conf_int(sin_onlyfreq)\n",
    "    info_onlyfreq[ig,:], info_onlyage[ig,:] = get_info_content(newdat, num_samps=1000, num_sims=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preds_sin_agefreq = np.zeros(len(gamma))\n",
    "# for ig, g in enumerate(gamma):\n",
    "#     newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "#     newdat = newdf1.to_numpy()\n",
    "#     sin_agefreq = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2]) + get_lp_xl(g1, newdat[:,5])) for g1 in gamma]\n",
    "#     # sin_agefreq = [np.sum(get_lp_alxl(g1, newdat[:,0], newdat[:,2], n=100)) for g1 in gamma]\n",
    "#     preds_sin_agefreq[ig] = gamma[np.nanargmax(sin_agefreq)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sin_onlyage = np.zeros(len(gamma))\n",
    "ci_sin_onlyage = np.zeros((len(gamma),2))\n",
    "for ig, g in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    # newdat = newdf1.loc[np.logical_and(newdf1['al']>1, newdf1['al']<60),:].to_numpy()\n",
    "    sin_onlyage = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2], cutoff=5)) for g1 in gamma]\n",
    "    preds_sin_onlyage[ig] = gamma[np.argmax(sin_onlyage)]\n",
    "    ci_sin_onlyage[ig] = 1/np.abs(get_bfq(sin_onlyage-np.argmax(sin_onlyage), gamma)[0]) # get_conf_int(sin_onlyage)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get bootstrap std estimates but mle only calculated once\n",
    "preds_sin_onlyfreq, preds_sin_onlyage = np.zeros(len(gamma)), np.zeros(len(gamma))\n",
    "ci_sin_onlyfreq, ci_sin_onlyage = np.zeros((len(gamma),)), np.zeros((len(gamma),))\n",
    "\n",
    "for ig, g in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    sin_onlyfreq = [np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2]\n",
    "    sin_onlyage = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2], cutoff=2)) for g1 in gamma2]\n",
    "    preds_sin_onlyfreq[ig] = gamma2[np.argmax(sin_onlyfreq)]\n",
    "    preds_sin_onlyage[ig] = gamma2[np.argmax(sin_onlyage)]\n",
    "    mle = get_boot_ci(newdat, nsamps=len(newdat), nboot=5)\n",
    "    ci_sin_onlyfreq[ig,], ci_sin_onlyage[ig,] = mle.std(axis=0) #np.percentile(mle[:,0],[97.5,2.5]), np.percentile(mle[:,1],[97.5,2.5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get age estimates but with error introduced into the mix \n",
    "preds_sin_onlyfreq, preds_sin_onlyage = np.zeros(len(gamma)), np.zeros(len(gamma))\n",
    "ci_sin_onlyfreq, ci_sin_onlyage = np.zeros((len(gamma),)), np.zeros((len(gamma),))\n",
    "\n",
    "for ig, g in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    sin_onlyfreq = [np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2]\n",
    "    # sin_onlyage = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2], cutoff=2)) for g1 in gamma2]\n",
    "    preds_sin_onlyfreq[ig] = gamma2[np.argmax(sin_onlyfreq)]\n",
    "    ests_age = get_mean_sd_werr(newdat, errvar = np.repeat(0,4), nreps=5)\n",
    "    # print(ests_age)\n",
    "    preds_sin_onlyage[ig] = np.mean(ests_age)\n",
    "    ci_sin_onlyage[ig] = np.std(ests_age)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==gamma[-10])),:]\n",
    "# newdat = newdf1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## predictions with data from neutral case only \n",
    "dfneut = pd.read_csv(\"outfiles/ConstantSize0.0.1.full_out.txt\",sep='\\t',header=None,)\n",
    "dfneut.columns = ['','Xl','s','al','id']\n",
    "dfneut['empty'] = ''\n",
    "dfneut['sXl'] = (dfneut['Xl']*2000).astype('int')\n",
    "dfneut['al'] = 80000+1 - dfneut['al']\n",
    "dfneut['al'] = dfneut['al'].astype('int')\n",
    "dfneut = dfneut.iloc[:,1:]\n",
    "datneut = dfneut.to_numpy()\n",
    "dfneut"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shufidx = np.arange(len(datneut))\n",
    "rng.shuffle(shufidx)\n",
    "parestfreq0 = np.zeros(11)\n",
    "parestage0 = np.zeros(11)\n",
    "for i in range(11):    \n",
    "    parestfreq0[i] = sp.optimize.minimize_scalar(get_ll_freq, args=(datneut[shufidx[(i*962):((i+1)*962)],5]), options={'xtol': .1,}).x\n",
    "    parestage0[i] = sp.optimize.minimize_scalar(get_ll_freqage, args=(datneut[shufidx[(i*962):((i+1)*962)],5], datneut[shufidx[(i*962):((i+1)*962)],2]), options={'xtol': .1}).x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "parestfreq0 = np.array([-0.239, 0.230, -0.841, 0.284, 0.088, 0.249, 0.083, -0.115, -0.004, 0.031, -0.003])\n",
    "parestage0 = np.array([0.027, 0.538, -0.618, 0.680, 0.420, 0.547, 0.420, 0.187, 0.317, 0.382, 0.277])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dfhund = pd.read_csv(\"outfiles/ConstantSize100.0.1.full_out.txt\",sep='\\t',header=None,).sample(n=2000)\n",
    "# dfhund.columns = ['','Xl','s','al','id']\n",
    "# dfhund['empty'] = ''\n",
    "# dfhund['sXl'] = (dfhund['Xl']*2000).astype('int')\n",
    "# dfhund['al'] = 100000+1 - dfhund['al']\n",
    "# dfhund['al'] = dfhund['al'].astype('int')\n",
    "# dfhund = dfhund.iloc[:,1:]\n",
    "# dathund = dfhund.to_numpy()\n",
    "# dfhund"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(dfhund['al'],alpha=0.8); plt.hist(dfneut['al'],alpha=0.4); plt.semilogx()\n",
    "plt.plot(p_xa_s[gamma2[-5]],'o'); plt.plot(p_xa_s[0.],'o',alpha=0.8); plt.loglog()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sin_onlyfreq = [np.sum(get_lp_xl(g1, datneut[:,5], cutoff=2)) for g1 in gamma2]\n",
    "# sin_onlyage = [np.sum(get_lp_alxl(g1, datneut[:,5], datneut[:,2], cutoff=2)) for g1 in gamma2]\n",
    "# print(gamma2[np.argmax(sin_onlyfreq)], gamma2[np.argmax(sin_onlyage)])\n",
    "mle = get_boot_ci(datneut, nsamps=len(datneut), nboot=100)\n",
    "# mle.std(axis=0)\n",
    "\n",
    "# plt.scatter(np.repeat(0.001,len(mle)),mle[:,0],alpha=0.5,color='deepskyblue',label='only freq'); plt.ylabel('estimated γ')\n",
    "# plt.scatter(np.repeat(-.001,len(mle)),mle[:,1],alpha=0.5,color='coral',label='freq & age'); plt.xlabel('true γ'); #plt.semilogy()\n",
    "# plt.legend(); plt.grid()\n",
    "# np.corrcoef(mle[:,0],mle[:,1])\n",
    "# mle.mean(axis=0), mle.std(axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## get bootstrap std estimates but mle only calculated once\n",
    "preds_sin_onlyfreq, preds_sin_onlyage = np.zeros(len(s)), np.zeros(len(s))\n",
    "ci_sin_onlyfreq, ci_sin_onlyage = np.zeros((len(s),)), np.zeros((len(s),))\n",
    "\n",
    "for ig, g in enumerate(s):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    newdat = newdf1.to_numpy()\n",
    "    sin_onlyfreq = [np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2]\n",
    "    sin_onlyage = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2], cutoff=2)) for g1 in gamma2]\n",
    "    preds_sin_onlyfreq[ig] = gamma2[np.argmax(sin_onlyfreq)]\n",
    "    preds_sin_onlyage[ig] = gamma2[np.argmax(sin_onlyage)]\n",
    "    mle = get_boot_ci(newdat, nsamps=len(newdat), nboot=50)\n",
    "    ci_sin_onlyfreq[ig,], ci_sin_onlyage[ig,] = mle.std(axis=0) #np.percentile(mle[:,0],[97.5,2.5]), np.percentile(mle[:,1],[97.5,2.5]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==s[4])),:]\n",
    "# newdat = newdf1.to_numpy()\n",
    "# sin_onlyfreq = [np.sum(get_lp_xl(g1, newdat[:,5], cutoff=2)) for g1 in gamma2]\n",
    "# sin_onlyage = [np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2], cutoff=2)) for g1 in gamma2]\n",
    "# gamma2[np.argmax(sin_onlyfreq)], gamma2[np.argmax(sin_onlyage)]\n",
    "# get_boot_ci(newdat, nsamps=len(newdat), nboot=50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## basically, do fitdadi inference for each selection coefficient\n",
    "## cannot do point selection coefficient inference\n",
    "import dadi\n",
    "df = pd.read_csv(\"PReFerSims/outfiles/ConstantSize2.0.1.full_out.txt\", sep=\"\\t\", header=None).sample(n=1000)\n",
    "fs = dadi.Spectrum(np.histogram(fdf.iloc[:, 1] * 2000, bins=2001)[0])\n",
    "def one_epoch_sel(params, ns, pts):\n",
    "    nu, T, gamma = params\n",
    "    xx = dadi.Numerics.default_grid(pts)\n",
    "    phi = dadi.PhiManip.phi_1D(xx, gamma=gamma)\n",
    "    phi = dadi.Integration.one_pop(phi, xx, T, nu, gamma=gamma)\n",
    "    fs = dadi.Spectrum.from_phi(phi, ns, (xx,))\n",
    "    return fs\n",
    "pts_l = [600, 800, 1000]\n",
    "spectra = Selection.spectra(\n",
    "    [1, 2],\n",
    "    np.array([2000]),\n",
    "    one_epoch_sel,\n",
    "    pts_l=pts_l,\n",
    "    int_bounds=[0.1, 100],\n",
    "    Npts=20,\n",
    "    echo=True,\n",
    ")\n",
    "sel_params = [0.1, 200.0]\n",
    "lower_bound = [1e-3, 1e-2]\n",
    "upper_bound = [1, 100.0]\n",
    "p0 = dadi.Misc.perturb_params(sel_params, lower_bound=lower_bound, upper_bound=upper_bound)\n",
    "popt = Selection.optimize_log(\n",
    "    p0,\n",
    "    fs,\n",
    "    spectra.integrate,\n",
    "    Selection.normal_dist,\n",
    "    300,\n",
    "    lower_bound=lower_bound,\n",
    "    upper_bound=upper_bound,\n",
    "    verbose=len(sel_params),\n",
    "    maxiter=30,\n",
    ")\n",
    "spectra.Integrate(popt[1], Selection.normal_dist, 300)\n",
    "spectra.integrate([1.,4.], Selection.normal_dist, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-s, -preds_sin_onlyfreq, color='deepskyblue', alpha=0.5, label='only freq, rel. error: {:.1f}'.format(np.sum(np.abs(s-preds_sin_onlyfreq)*100/-s)),)#s=truenumloci*50/1000)\n",
    "plt.errorbar(-s, -preds_sin_onlyfreq, yerr=1.96*ci_sin_onlyfreq[:], color='deepskyblue', alpha=0.5, ls='none')\n",
    "plt.scatter(-s, -preds_sin_onlyage, color='coral', alpha=0.5, label='freq & age, rel. error: {:.1f}'.format(np.sum(np.abs(s-preds_sin_onlyage)*100/-s)),)#s=truenumloci*50/1000)\n",
    "plt.errorbar(-s, -preds_sin_onlyage, yerr=1.96*ci_sin_onlyage[:], color='coral', alpha=0.5, ls='none')\n",
    "plt.xlabel('true -γ value'); plt.ylabel('MLE -γ value'); plt.legend(); plt.loglog()\n",
    "plt.axline((1,1),(100,100),color='grey',ls='--', linewidth=1.); plt.ylim((0.1,1000)); plt.grid()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(-gamma, -preds_sin_onlyfreq, color='deepskyblue', alpha=0.5, label='only freq, RMSLE: {:.2f}'.format(np.sqrt(np.mean((np.log10(-gamma)-np.log10(-preds_sin_onlyfreq))**2))))#s=truenumloci*50/1000)\n",
    "# plt.scatter(-gamma, -preds_sin_onlyfreq, color='deepskyblue', alpha=0.5, label='only freq, r2: {:.2f}'.format(sp.stats.pearsonr(np.log(-gamma),np.log(-preds_sin_onlyfreq))[0]**2))\n",
    "plt.xticks(fontsize=10); plt.yticks(fontsize=10); \n",
    "# plt.vlines(-gamma, -ci_sin_onlyfreq[:,0], -ci_sin_onlyfreq[:,1], color='deepskyblue', alpha=0.5)\n",
    "plt.errorbar(-gamma, -preds_sin_onlyfreq, yerr=1.96*ci_sin_onlyfreq[:], color='deepskyblue', alpha=0.5, ls='none')\n",
    "plt.errorbar(-gamma, -preds_sin_onlyfreq, yerr=-ci_sin_onlyfreq.T, color='deepskyblue', alpha=0.5, ls='none')\n",
    "plt.scatter(-gamma, -preds_sin_onlyage, color='coral', alpha=0.5, label='freq & age, RMSLE: {:.2f}'.format(np.sqrt(np.mean((np.log10(-gamma)-np.log10(-preds_sin_onlyage))**2))))#s=truenumloci*50/1000)\n",
    "# plt.scatter(-gamma, -preds_sin_onlyage, color='coral', alpha=0.5, label='freq & age, r2: {:.2f}'.format(sp.stats.pearsonr(np.log(-gamma),np.log(-preds_sin_onlyage))[0]**2))\n",
    "# plt.vlines(-gamma, -ci_sin_onlyage[:,0], -ci_sin_onlyage[:,1], color='coral', alpha=0.5)\n",
    "plt.errorbar(-gamma, -preds_sin_onlyage, yerr=1.96*ci_sin_onlyage[:], color='coral', alpha=0.5, ls='none')\n",
    "plt.errorbar(-gamma, -preds_sin_onlyage, yerr=-ci_sin_onlyage.T, color='coral', alpha=0.5, ls='none'); plt.yscale('log')\n",
    "# plt.scatter(-gamma, -preds_sin_agefreq, color='darkgreen', alpha=0.5, label='age & freq, abs. error: {:.1f}'.format(np.sum(np.abs(gamma-preds_sin_agefreq))))\n",
    "plt.xlabel('true |γ| value', fontsize=10); plt.ylabel('MLE |γ| value', fontsize=10); plt.legend(loc='lower right', fontsize=10); plt.loglog()\n",
    "plt.axline((1,1),(100,100),color='grey',ls='--', linewidth=1.); plt.ylim((0.2,200)); plt.grid()\n",
    "# plt.xticks(fontsize=8)\n",
    "# plt.yticks(fontsize=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.stats.pearsonr(np.log(-gamma),np.log(-preds_sin_onlyfreq))[0]**2\n",
    "preds_sin_onlyage, preds_sin_onlyfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft = pd.read_csv(\"../traindata/trip-2022-04-05.csv\")\n",
    "# dft['gamma'] = dft['gamma'].round(decimals=2)\n",
    "preds_sin_onlyfreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## comparing empirical distribution from data of frequency values with likelihood from moments framework\n",
    "# basically take samples from binomial for each rep and then store the values in a vector that keeps getting updated...\n",
    "ir = np.empty((100,1500),dtype=int)\n",
    "for n in range(100): #nreps\n",
    "    ir[n,:] = rng.binomial(n=2000, p=df1[df1['s']==-10.]['Xl'])\n",
    "counts, bins, _ = plt.hist(np.ravel(ir),bins=2000,range=(0,2000),density=True); plt.semilogx(); plt.xlabel('# of allele copies')\n",
    "counts[cutoff:(2000-cutoff+1)] = counts[cutoff:(2000-cutoff+1)]/np.sum(counts[cutoff:(2000-cutoff+1)])\n",
    "counts[0:cutoff] = counts[-cutoff:] = np.repeat(0,cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## numerical integration of likelihood to get analytical expression (from eq 2 in Bustamante et al 2001)\n",
    "def Fanal(gg, i, n):\n",
    "    with np.errstate(divide='ignore'):\n",
    "        return [(1-np.exp(-2*gg*(1-x)))*2/((1-np.exp(-2*gg))*x*(1-x)) * sp.stats.binom.pmf(i,n,x) for x in np.logspace(-8,-0.01,99)]\n",
    "\n",
    "analexp = [sp.integrate.trapezoid(Fanal(-11.625/2,i,2000),np.logspace(-8,-0.01,99)) for i in range(2000)]\n",
    "analexp[cutoff:(2000-cutoff+1)] = analexp[cutoff:(2000-cutoff+1)]/np.sum(analexp[cutoff:(2000-cutoff+1)])\n",
    "analexp[0:cutoff] = analexp[-cutoff:] = np.repeat(0,cutoff)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.corrcoef([sp.integrate.trapezoid(Fanal(gamma[19],i,2000),np.linspace(1e-6,1-1e-6,200)) for i in range(20)], [sp.integrate.trapezoid(Fanal(gamma[0],i,2000),np.linspace(1e-6,1-1e-6,200)) for i in range(20)])\n",
    "# Fanal(gamma[19],10,2000), Fanal(gamma[0],10,2000) \n",
    "# np.linspace(1e-6,1-1e-6,20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.scatter(p_xa_s[gamma[15]],p_xa_s[gamma[17]]); plt.loglog(); plt.axline((0.1,0.1),(0,0))\n",
    "# np.allclose(p_xa_s[gamma[19]],p_xa_s[gamma[16]])\n",
    "gamma2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(np.arange(2,100+1),p_xa_s[gamma2[15]][2:101],color='purple',label='moments, error={:.2f}'.format(np.sum(np.abs(p_xa_s[gamma2[15]][2:101]-analexp[2:101]))),alpha=0.5);\n",
    "# plt.scatter(np.arange(2,100+1),testp_xa_s[2:101],color='grey',label='moments2, error={:.2f}'.format(np.sum(np.abs(testp_xa_s[2:101]-analexp[2:101]))),alpha=0.5);\n",
    "# plt.scatter(np.arange(2,100+1),counts[2:101],color='green',label='PReFerSims, error={:.2f}'.format(np.sum(np.abs(counts[2:101]-analexp[2:101]))),alpha=0.5); \n",
    "plt.scatter(np.arange(2,100+1),analexp[2:101],color='lightpink',marker='+',label='analytical expression');  plt.grid(); plt.loglog()\n",
    "plt.ylabel('probability'); plt.title('γ = {}'.format(-10.)); plt.legend(); plt.xlabel('# of allele copies')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting different SFS from moments on the same plot\n",
    "plt.scatter(np.arange(2,100+1),p_xa_s[gamma[0]][2:101],color=cm.get_cmap('Purples',6)(5),alpha=0.6,label='γ={}'.format(gamma[0])); \n",
    "plt.scatter(np.arange(2,100+1),p_xa_s[gamma[10]][2:101],color=cm.get_cmap('Purples',6)(3),label='γ={}'.format(gamma[10])); \n",
    "plt.scatter(np.arange(2,100+1),p_xa_s[gamma[-1]][2:101],color=cm.get_cmap('Purples',6)(1),label='γ={}'.format(gamma[-1])); \n",
    "plt.xlabel('# of allele copies'); plt.ylabel('moments likelihood'); plt.legend(); plt.loglog(); plt.grid()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds_sin_onlyfreq, ci_sin_onlyfreq, preds_sin_onlyage, ci_sin_onlyage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.figure(dpi=150)\n",
    "import matplotlib.patches as mpatches\n",
    "seaborn.stripplot(data=pd.DataFrame(info_onlyfreq.T,columns=-gamma[::-1]), color='deepskyblue', alpha=0.7, label='only freq',s=4)\n",
    "seaborn.stripplot(data=pd.DataFrame(info_onlyage.T,columns=-gamma[::-1]), color='coral', alpha=0.7, label='freq & age',s=4)\n",
    "plt.semilogy(); plt.xlabel('gamma'); plt.ylabel('information measure'); plt.grid(); \n",
    "plt.legend(handles=[mpatches.Patch(color='deepskyblue', label='only freq, total info: {:.2f}'.format(np.sum(info_onlyfreq))), mpatches.Patch(color='coral', label='freq & age, total info: {:.2f}'.format(np.sum(info_onlyage)))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting error rates across selection coefficients\n",
    "plt.plot(-gamma, np.abs(gamma-preds_sin_onlyfreq), color='deepskyblue', alpha=0.8, label='only freq'.format(np.sum(np.abs(gamma-preds_sin_onlyfreq))), ls='--')\n",
    "plt.plot(-gamma, np.abs(gamma-preds_sin_onlyage), color='coral', label='freq & age', alpha=0.8, ls='--')\n",
    "plt.legend(); plt.semilogx(); plt.xlabel('-γ'); plt.ylabel('absolute error'); plt.show()\n",
    "\n",
    "plt.plot(-gamma, -np.abs(gamma-preds_sin_onlyfreq)*100/gamma, color='deepskyblue', alpha=0.8, label='only freq, total: {:.2f}'.format(np.sum(-np.abs(gamma-preds_sin_onlyfreq)*100/gamma)), ls='--')\n",
    "plt.plot(-gamma, -np.abs(gamma-preds_sin_onlyage)*100/gamma, color='coral', label='freq & age, total: {:.2f}'.format(np.sum(-np.abs(gamma-preds_sin_onlyage)*100/gamma)), alpha=0.8, ls='--')\n",
    "plt.legend(); plt.semilogx(); plt.xlabel('-γ'); plt.ylabel('relative error'); plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## picking a choice of g1 and g2 & creating a new data frame\n",
    "trueg1 = gamma[-4]\n",
    "trueg2 = gamma[-10]\n",
    "# 2000 x 3 (first 1000 is g1, second 1000 is g2)\n",
    "newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==trueg1)),:].append(df1.iloc[np.ravel(np.where(dat[:,1]==trueg2)),:])\n",
    "# newdf1 = newdf1.sample(frac=1)\n",
    "\n",
    "# only keeping alleles with ages > 1 (cos NN & PRF approx finds really high prob for these alleles to have small gamma...)\n",
    "newdat = newdf1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## need code to do scipy.optimize for two parameters...\n",
    "def get_ll_freq2(g, sXlred, n=2000, cutoff=2):\n",
    "    g1, g2 = g\n",
    "\n",
    "    fs1 = moments.Spectrum(np.zeros(n+1))\n",
    "    fs1[1] = 1\n",
    "    fs1.integrate([0.5], 10, gamma=g1)\n",
    "    pxs1 = fs1/np.sum(fs1[np.arange(cutoff,n-cutoff+1)])\n",
    "\n",
    "    fs2 = moments.Spectrum(np.zeros(n+1))\n",
    "    fs2[1] = 1\n",
    "    fs2.integrate([0.5], 10, gamma=g2)\n",
    "    pxs2 = fs2/np.sum(fs2[np.arange(cutoff,n-cutoff+1)])\n",
    "\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1))) #np.empty(len(Xlred))\n",
    "\n",
    "    # just performing a search in a look-up table\n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[idx] = np.log(0.5*pxs1[sXlred[i]]+0.5*pxs2[sXlred[i]])\n",
    "    \n",
    "    return -np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_ll_freqage2(g, sXlred, alred, n=2000, cutoff=2):\n",
    "    g1, g2 = g\n",
    "\n",
    "    pxas1 = run_mom_iterate(int(100000+900*g1), n, 0.5*g1/N, N, 1.25e-8, misc = {'dt_fac':0.02, 'adapt_dt':True})\n",
    "    pxas1[:,np.arange(cutoff,n-cutoff+1)] /= np.sum(pxas1[:,np.arange(cutoff,n-cutoff+1)]) \n",
    "\n",
    "    pxas2 = run_mom_iterate(int(100000+900*g2), n, 0.5*g2/N, N, 1.25e-8, misc = {'dt_fac':0.02, 'adapt_dt':True})\n",
    "    pxas2[:,np.arange(cutoff,n-cutoff+1)] /= np.sum(pxas2[:,np.arange(cutoff,n-cutoff+1)]) \n",
    "\n",
    "    res = np.empty(np.sum((sXlred>cutoff) & (sXlred<n-cutoff+1)))\n",
    "    \n",
    "    for idx, i in enumerate(np.where((sXlred>cutoff) & (sXlred<n-cutoff+1))[0]):\n",
    "        res[idx] = np.log(0.5*pxas1[-int(alred[i]),sXlred[i]] + 0.5*pxas2[-int(alred[i]),sXlred[i]])\n",
    "\n",
    "    return -np.sum(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.sum((newdat[:,5]>cutoff) & (newdat[:,5]<2000-cutoff+1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 0.5*pxs1[newdat[10,5]] + 0.5*pxs2[newdat[10,5]]\n",
    "# trueg1, trueg2, N, 41843.793\n",
    "# sp.optimize.minimize(get_ll_freqage2, x0=[trueg1, trueg2], method='L-BFGS-B', args=(newdat[:,5], newdat[:,2]), options={'maxiter':5, 'ftol':1.}, bounds=[(-200,-0.2),(-200,-0.2)])\n",
    "np.sum((trueg1+24.772)**2+(trueg2+11.16)**2)/2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp.optimize.basinhopping(get_ll_freq2, x0=[-10,-10], minimizer_kwargs={'method': 'L-BFGS-B', 'args': (newdat[:,5]), 'tol': (1., 1.)})\n",
    "sp.optimize.minimize(get_ll_freq2, x0=[-1,-10], method='L-BFGS-B', args=(newdat[:,5]), options={'maxiter':50, 'ftol':1e-2,}, bounds=[(-200,-0.2),(-200,-0.2)])\n",
    "# Nelder-Mead: 'xatol':0.25, 'fatol': 1., takes ~1min/iter and progresses slowly (need to initialize close to true for faster convergence)\n",
    "# sp.optimize.minimize(get_ll_freqage2, x0=[trueg1+1, trueg2+1], method='TNC', args=(newdat[:,5], newdat[:,2]), options={'eps':1e-2,'ftol':1,'xtol':1e-2,'gtol':1e-2,},)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assuming two selection coefficients and only freq info (split 50/50)\n",
    "dub_onlyfreq = np.zeros((len(gamma2),len(gamma2))) # need a 2d search\n",
    "# for ig1, g1 in enumerate(gamma2):\n",
    "#     for ig2, g2 in enumerate(gamma2[0:(ig1+1)]):\n",
    "#         dub_onlyfreq[ig1, ig2] = np.sum(np.log(0.5*np.exp(get_lp_xl(g1, newdat[:,5])) + 0.5*np.exp(get_lp_xl(g2, newdat[:,5]))))\n",
    "\n",
    "mask = np.full(dub_onlyfreq.shape,False)\n",
    "mask[np.triu_indices_from(dub_onlyfreq,k=1)] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.heatmap(dub_onlyfreq,alpha=0.95,cmap='viridis_r',mask=mask,vmax=np.max(dub_onlyfreq[~mask])-5,vmin=np.max(dub_onlyfreq[~mask]))\n",
    "plt.xticks(np.linspace(0,24,6,dtype='int'),gamma2[np.linspace(0,24,6,dtype='int')].round(2))\n",
    "plt.yticks(np.linspace(0,24,6,dtype='int'),gamma2[np.linspace(0,24,6,dtype='int')].round(2))\n",
    "np.take(gamma, np.unravel_index(np.nanargmax(np.ma.masked_array(dub_onlyfreq, mask)),dub_onlyfreq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## assuming two selection coefficients and only age info (split 50/50)\n",
    "dub_onlyage = np.zeros((len(gamma2),len(gamma2))) # need a 2d search\n",
    "for ig1, g1 in enumerate(gamma2):\n",
    "    for ig2, g2 in enumerate(gamma2[0:(ig1+1)]):\n",
    "        dub_onlyage[ig1, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g1, newdat[:,5], newdat[:,2])) + \n",
    "        0.5*np.exp(get_lp_alxl(g2, newdat[:,5], newdat[:,2]))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.heatmap(dub_onlyage,alpha=0.75,xticklabels=gamma,yticklabels=gamma,cmap='Blues',mask=mask,vmin=np.max(dub_onlyage[~mask])-10,vmax=np.max(dub_onlyage[~mask]))\n",
    "plt.xticks(np.linspace(0,24,6,dtype='int'),gamma2[np.linspace(0,24,6,dtype='int')].round(2))\n",
    "plt.yticks(np.linspace(0,24,6,dtype='int'),gamma2[np.linspace(0,24,6,dtype='int')].round(2))\n",
    "np.take(gamma, np.unravel_index(np.argmax(np.ma.masked_array(dub_onlyage, mask)),dub_onlyfreq.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unravel_index(np.argmax(np.ma.masked_array(dub_onlyage, mask)),dub_onlyage.shape)\n",
    "np.unravel_index(np.nanargmax(np.ma.masked_array(dub_onlyfreq, mask)),dub_onlyfreq.shape)\n",
    "# print(np.max(dub_onlyfreq[~mask]))\n",
    "# print(np.max(dub_onlyage[~mask]))\n",
    "# dub_onlyfreq[24,]\n",
    "# dub_onlyage[21,]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What if there was only one $\\gamma$ in the data? "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "samepredsonlyfreq = np.zeros((len(gamma),4))\n",
    "samepredsagefreq = np.zeros((len(gamma),4))\n",
    "for itg, trueg in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==trueg)),:]\n",
    "\n",
    "    newdat = newdf1.to_numpy()\n",
    "    \n",
    "    sin_onlyfreq = np.zeros(len(gamma))\n",
    "    sin_agefreq = np.zeros(len(gamma))\n",
    "    \n",
    "    dub_onlyfreq = np.zeros((len(gamma),len(gamma))) # need a 2d search\n",
    "    dub_agefreq = np.zeros((len(gamma),len(gamma))) # need a 2d search\n",
    "\n",
    "    for ig1, g1 in enumerate(gamma):\n",
    "        sin_onlyfreq[ig1] = np.sum(get_lp_xl(g1, newdat[:,5]))\n",
    "        # sin_agefreq[ig1] = np.sum(get_lp_alxl(g1, newdat[:,0], newdat[:,2], n=100) + get_lp_xl(g1, newdat[:,0]))\n",
    "        sin_agefreq[ig1] = np.sum(get_lp_alxl(g1, newdat[:,5], newdat[:,2]))\n",
    "\n",
    "        for ig2, g2 in enumerate(gamma[0:(ig1+1)]):        \n",
    "            dub_onlyfreq[ig1, ig2] = np.sum(np.log(0.5*np.exp(get_lp_xl(g1, newdat[:,5])) + 0.5*np.exp(get_lp_xl(g2, newdat[:,5]))))\n",
    "    \n",
    "            # dub_agefreq[ig1, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g1, newdat[:,0], newdat[:,2], n=100) + get_lp_xl(g1, newdat[:,0])) + 0.5*np.exp(get_lp_alxl(g2, newdat[:,0], newdat[:,2], n=100) + get_lp_xl(g2, newdat[:,0]))))\n",
    "            \n",
    "            dub_agefreq[ig1, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g1, newdat[:,5], newdat[:,2])) + 0.5*np.exp(get_lp_alxl(g2, newdat[:,5], newdat[:,2]))))\n",
    "\n",
    "    estgonlyfreq = gamma[np.argmax(sin_onlyfreq)]\n",
    "\n",
    "    estg1onlyfreq = gamma[np.unravel_index(dub_onlyfreq.argmax(), dub_onlyfreq.shape)[0]]\n",
    "    estg2onlyfreq = gamma[np.unravel_index(dub_onlyfreq.argmax(), dub_onlyfreq.shape)[1]]\n",
    "\n",
    "    lambfreq = 2.*(np.max(dub_onlyfreq[~mask]) - np.max(sin_onlyfreq))\n",
    "\n",
    "    samepredsonlyfreq[itg,2] = estgonlyfreq\n",
    "\n",
    "    samepredsonlyfreq[itg,:2] = np.take(gamma, np.unravel_index(np.nanargmax(np.ma.masked_array(dub_onlyfreq, mask)),dub_onlyfreq.shape))\n",
    "\n",
    "    if(chi2.sf(lambfreq, 1)<0.05):\n",
    "        samepredsonlyfreq[itg,3] = True\n",
    "    else:\n",
    "        samepredsonlyfreq[itg,3] = False\n",
    "\n",
    "    estgagefreq = gamma[np.nanargmax(sin_agefreq)]        \n",
    "\n",
    "    estg1agefreq = np.take(gamma, np.unravel_index(np.nanargmax(np.ma.masked_array(dub_agefreq, mask)),dub_agefreq.shape))[0]\n",
    "    estg2agefreq = np.take(gamma, np.unravel_index(np.nanargmax(np.ma.masked_array(dub_agefreq, mask)),dub_agefreq.shape))[1]\n",
    "\n",
    "    lambagefreq = 2.*(np.nanmax(dub_agefreq[~mask]) - np.nanmax(sin_agefreq))\n",
    "\n",
    "    samepredsagefreq[itg,2] = estgagefreq\n",
    "\n",
    "    samepredsagefreq[itg,:2] = np.take(gamma, np.unravel_index(np.nanargmax(np.ma.masked_array(dub_agefreq, mask)),dub_agefreq.shape))\n",
    "\n",
    "    if(chi2.sf(lambagefreq, 1)<0.05):\n",
    "        samepredsagefreq[itg,3] = True\n",
    "    else:\n",
    "        samepredsagefreq[itg,3] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# np.max(dub_onlyfreq) - np.max(sin_onlyfreq)\n",
    "samepredsagefreq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plotting the above results\n",
    "plt.scatter(-gamma, -samepredsonlyfreq[:,0], color='deepskyblue', marker='+', alpha=0.5)\n",
    "plt.scatter(-gamma, -samepredsonlyfreq[:,1], color='deepskyblue', marker='+', label='estimates using only freq', alpha=0.5)\n",
    "plt.scatter(-gamma, -samepredsagefreq[:,0], color='coral', marker='*', label='estimates using freq & age', alpha=0.5)\n",
    "plt.scatter(-gamma, -samepredsagefreq[:,1], color='coral', marker='*', alpha=0.5)\n",
    "plt.xlabel('true -γ value'); plt.ylabel('predicted -γ value(s)'); plt.loglog()\n",
    "plt.axline((0.01,0.01),(100,100),color='grey',ls='--'); plt.legend()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Template code to compute difference in $\\gamma$ given set of data\n",
    "\n",
    "Here, I will run the mechanism to compute the probability of a significant difference in selection coefficients is detected given a set of large data i.e., 2000 data points and I will resample 25 times to obtain smaller datasets of 500. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_sims is number of reps to run to calculate prob\n",
    "# num_samps is number of rows to resample the big data from\n",
    "# gamma is np.array of values to calculate over\n",
    "# thresh is threshold to assign significance\n",
    "def resample_calculateprob_freq(newdat, gamma, num_sims=16, num_samps=500, thresh=0.05, cutoff=cutoff):\n",
    "    prob = 0.\n",
    "    sin_onlyfreq = np.empty(len(gamma))\n",
    "    dub_onlyfreq = np.zeros((len(gamma),len(gamma)))\n",
    "    for n in np.arange(num_sims):\n",
    "        newnewdat = newdat[np.random.choice(newdat.shape[0], num_samps, replace=False),:]\n",
    "        for ig, g in enumerate(gamma):\n",
    "            # sum log prob for each locus\n",
    "            sin_onlyfreq[ig] = np.sum(get_lp_xl(g, newnewdat[:,5], cutoff=cutoff))\n",
    "            for ig2, g2 in enumerate(gamma[0:(ig+1)]):\n",
    "                dub_onlyfreq[ig, ig2] = np.sum(np.log(0.5*np.exp(get_lp_xl(g, newnewdat[:,5], cutoff=cutoff)) + 0.5*np.exp(get_lp_xl(g2, newnewdat[:,5], cutoff=cutoff))))\n",
    "\n",
    "\n",
    "        estgonlyfreq = gamma[np.argmax(sin_onlyfreq)]\n",
    "\n",
    "        # estg1onlyfreq = gamma[np.unravel_index(dub_onlyfreq.argmax(), dub_onlyfreq.shape)[0]]\n",
    "        # estg2onlyfreq = gamma[np.unravel_index(dub_onlyfreq.argmax(), dub_onlyfreq.shape)[1]]\n",
    "        estg1onlyfreq, estg2onlyfreq = np.take(gamma, np.unravel_index(np.argmax(np.ma.masked_array(dub_onlyfreq, mask)),dub_onlyfreq.shape))\n",
    "\n",
    "        lambfreq = 2.*(dub_onlyfreq[gamma==estg1onlyfreq,gamma==estg2onlyfreq] - sin_onlyfreq[gamma==estgonlyfreq])\n",
    "\n",
    "        if(chi2.sf(lambfreq, 1)<thresh):\n",
    "            prob += 1.\n",
    "\n",
    "    return [prob/num_sims, estgonlyfreq, np.array([estg1onlyfreq, estg2onlyfreq])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [],
   "source": [
    "## function call to find MLE using scipy.optimize (and corresponding changes in the next steps for LRT)\n",
    "## pass in the entire data set & positive gamma and do wrangling inside function\n",
    "def resample_calculateprob_freqcont(dft, gamma, t=200, n=200, thresh=0.05):\n",
    "    dft['empty'] = ''\n",
    "    dft['sXl'] = (dft['Xl']*n).astype('int')\n",
    "    dft['al'] = 80000+1 - dft['al']\n",
    "    dft['al'] = dft['al'].astype('int')\n",
    "    dft = dft.iloc[:,1:]\n",
    "    datt = dft.to_numpy()\n",
    "    sfs = moments.Spectrum(np.histogram(datt[:,5],bins=range(0,n+2))[0])\n",
    "    SMS = np.zeros((80000,n+1),dtype='int16')\n",
    "    mask = np.zeros_like(SMS); mask[0,:] = 1; mask[:,0] = 1; mask[:,-1] = 1;\n",
    "    for i in range(len(datt)):\n",
    "        SMS[datt[i,2],datt[i,5]] += 1\n",
    "    SMSmask = np.ma.array(SMS,mask=mask)\n",
    "\n",
    "    ressinf = sp.optimize.minimize_scalar(get_ll_freqconstant,args=({'sfs':sfs,'theta':t,'p_misid':0},n))\n",
    "    lldubf = get_ll_freqconstant_twogam(np.log10([-gamma[0],-gamma[1]]),{'sfs':sfs,'theta':t,'p_misid':0},n)\n",
    "    # print(ressinf.fun, lldubf)\n",
    "\n",
    "    if(chi2.sf(2.*(ressinf.fun - lldubf),1)<thresh):\n",
    "        probf = 1\n",
    "    else:\n",
    "        probf = 0\n",
    "\n",
    "    ressina = sp.optimize.minimize_scalar(get_ll_freqageconstant,args=({'sms':SMSmask,'theta':t,'N':10000,'p_misid':0,'gens':80000},n))\n",
    "    llduba = get_ll_freqageconstant_twogam(np.log10([-gamma[0],-gamma[1]]),{'sms':SMSmask,'theta':t,'N':10000,'gens':80000},n)\n",
    "    \n",
    "    # print(ressina.fun, llduba)\n",
    "    if(chi2.sf(2.*(ressina.fun - llduba),1)<thresh):\n",
    "        proba = 1\n",
    "    else:\n",
    "        proba = 0\n",
    "\n",
    "    return [probf, proba, ressinf.x, ressina.x]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samps is number of rows to resample the big data from\n",
    "# gamma is np.array of values to calculate over\n",
    "# thresh is threshold to assign significance\n",
    "def resample_calculateprob_agefreq(newdat, gamma, num_sims=16, num_samps=500, thresh=0.05):\n",
    "    prob = 0.\n",
    "\n",
    "    sin_agefreq = np.empty(len(gamma))\n",
    "    \n",
    "    dub_agefreq = np.zeros((len(gamma),len(gamma)))\n",
    "    for n in np.arange(num_sims):\n",
    "        newnewdat = newdat[np.random.choice(newdat.shape[0], num_samps, replace=False),:]\n",
    "        for ig, g in enumerate(gamma):\n",
    "            # sum log prob for each locus\n",
    "            sin_agefreq[ig] = np.sum(get_lp_alxl(g, newnewdat[:,0], newnewdat[:,2], n=100) + get_lp_xl(g, newnewdat[:,0]))\n",
    "            for ig2, g2 in enumerate(gamma[0:(ig+1)]):\n",
    "                dub_agefreq[ig, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2]) + get_lp_xl(g, newnewdat[:,5])) + 0.5*np.exp(get_lp_alxl(g2, newnewdat[:,5], newnewdat[:,2]) + get_lp_xl(g2, newnewdat[:,5]))))\n",
    "\n",
    "        estgagefreq = gamma[np.nanargmax(sin_agefreq)]        \n",
    "\n",
    "        estg1agefreq = gamma[np.unravel_index(np.nanargmax(dub_agefreq[~mask]), dub_agefreq.shape)[0]]\n",
    "        estg2agefreq = gamma[np.unravel_index(np.nanargmax(dub_agefreq[~mask]), dub_agefreq.shape)[1]]\n",
    "\n",
    "        lambagefreq = 2.*(dub_agefreq[gamma==estg1agefreq,gamma==estg2agefreq] - sin_agefreq[gamma==estgagefreq])\n",
    "\n",
    "        if(chi2.sf(lambagefreq, 1)<thresh):\n",
    "            prob += 1.\n",
    "\n",
    "    return prob/num_sims"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_samps is number of rows to resample the big data from\n",
    "# gamma is np.array of values to calculate over\n",
    "# thresh is threshold to assign significance\n",
    "def resample_calculateprob_age(newdat, gamma, num_sims=16, num_samps=500, thresh=0.05, cutoff=cutoff):\n",
    "    prob = 0.\n",
    "\n",
    "    sin_onlyage = np.empty(len(gamma))\n",
    "    \n",
    "    dub_onlyage = np.zeros((len(gamma),len(gamma)))\n",
    "    for n in np.arange(num_sims):\n",
    "        newnewdat = newdat[np.random.choice(newdat.shape[0], num_samps, replace=False),:]\n",
    "        for ig, g in enumerate(gamma):\n",
    "            # sum log prob for each locus\n",
    "            sin_onlyage[ig] = np.sum(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff))\n",
    "            for ig2, g2 in enumerate(gamma[0:(ig+1)]):\n",
    "                dub_onlyage[ig, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff)) + 0.5*np.exp(get_lp_alxl(g2, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff))))\n",
    "\n",
    "        estgonlyage = gamma[np.argmax(sin_onlyage)]        \n",
    "\n",
    "        # estg1onlyage = gamma[np.unravel_index(dub_onlyage.argmax(), dub_onlyage.shape)[0]]\n",
    "        # estg2onlyage = gamma[np.unravel_index(dub_onlyage.argmax(), dub_onlyage.shape)[1]]\n",
    "        estg1onlyage, estg2onlyage = np.take(gamma, np.unravel_index(np.argmax(np.ma.masked_array(dub_onlyage, mask)),dub_onlyage.shape))\n",
    "\n",
    "        lambonlyage = 2.*(dub_onlyage[gamma==estg1onlyage,gamma==estg2onlyage] - sin_onlyage[gamma==estgonlyage])\n",
    "\n",
    "        if(chi2.sf(lambonlyage, 1)<thresh):\n",
    "            prob += 1.\n",
    "\n",
    "    return [prob/num_sims, estgonlyage, np.array([estg1onlyage, estg2onlyage])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[-1.000 -2.000]\n",
      "[0, 0, 0.1099920388368915, 0.1407430080335168]\n",
      "[0, 0, 0.13124578028776024, 0.16253962109816514]\n",
      "[0, 0, 0.1833990424064205, 0.18124590176563812]\n",
      "[0, 0, 0.089969747469006, 0.14628107760096634]\n",
      "[0, 0, 0.14843734575484058, 0.16701528160758103]\n",
      "[0, 0, 0.11039516443815288, 0.12258368807152525]\n",
      "[0, 0, 0.12570307184650056, 0.13556539810517054]\n",
      "[0, 0, 0.07182145702675809, 0.1059951324031243]\n",
      "[0, 0, 0.18949478297317335, 0.18937280565197004]\n",
      "[0, 0, 0.036395801186329194, 0.0815942458827409]\n",
      "[0, 0, 0.1523289241552939, 0.14902702060334455]\n",
      "[0, 0, 0.12271494158564067, 0.14415342057565106]\n",
      "[0, 0, 0.09387365105758642, 0.10245183116842131]\n",
      "[0, 0, 0.13689310343929362, 0.16587897921376743]\n",
      "[0, 0, 0.14747598909113377, 0.18039947199598924]\n",
      "[-1.000 -5.000]\n",
      "[1, 1, 0.28761207142940637, 0.2973363612644125]\n",
      "[0, 1, 0.2867005328063595, 0.2676523350023436]\n",
      "[0, 0, 0.27656429648472497, 0.275252613767299]\n",
      "[0, 1, 0.2962816086087629, 0.2864776842369939]\n",
      "[1, 1, 0.3378052345185885, 0.3342099653785007]\n",
      "[1, 1, 0.24130969494567076, 0.2571482870788448]\n",
      "[1, 1, 0.2686262749710617, 0.24765838473011356]\n",
      "[1, 1, 0.2508440093207379, 0.2581132913922738]\n",
      "[0, 1, 0.2861600012012128, 0.2884941563802102]\n",
      "[1, 1, 0.2445941390315237, 0.2520771345137351]\n",
      "[1, 1, 0.27945936595000503, 0.2420182034658215]\n",
      "[1, 1, 0.2789279617014929, 0.2845990230072212]\n",
      "[1, 1, 0.2574673729453185, 0.23820397112508002]\n",
      "[1, 1, 0.3270037842599148, 0.3170329723774153]\n",
      "[1, 1, 0.2432478465599495, 0.2393602000754352]\n",
      "[-1.000 -10.000]\n",
      "[1, 1, 0.2814990371943884, 0.2921676322878882]\n",
      "[1, 1, 0.3553912386302526, 0.34539327093093636]\n",
      "[1, 1, 0.31751426164081303, 0.2923589782264277]\n",
      "[1, 1, 0.34232399904045047, 0.33023484716609]\n",
      "[1, 1, 0.33515722329973946, 0.31501605046694164]\n",
      "[1, 1, 0.3311595909151623, 0.3220958102629514]\n",
      "[1, 1, 0.3680840746211719, 0.3384416594413594]\n",
      "[1, 1, 0.35466520927931916, 0.3325148518440738]\n",
      "[1, 1, 0.2787216404459065, 0.27760672249103086]\n",
      "[1, 1, 0.33998887556455964, 0.31489550269882194]\n",
      "[1, 1, 0.3735315038163725, 0.3536875924325745]\n",
      "[1, 1, 0.3779180670651709, 0.3469586973211156]\n",
      "[1, 1, 0.3119225865347124, 0.27843260271159487]\n",
      "[1, 1, 0.3028804900534788, 0.29375688015812607]\n",
      "[1, 1, 0.367868582297688, 0.3624953524471356]\n",
      "[-1.000 -20.000]\n",
      "[1, 1, 0.21732628628390332, 0.22225261027330145]\n",
      "[1, 1, 0.34909332265665804, 0.3242070284573929]\n",
      "[1, 1, 0.33350211130710755, 0.3130039613180803]\n",
      "[1, 1, 0.36648007016438205, 0.3391411416779134]\n",
      "[1, 1, 0.3351333763153949, 0.3153126446199914]\n",
      "[1, 1, 0.35017679827030623, 0.32981874409978135]\n",
      "[1, 1, 0.2790396704954812, 0.2581165517837911]\n",
      "[1, 1, 0.3273471659502391, 0.30201511961563743]\n",
      "[1, 1, 0.3389927067515624, 0.311472119811906]\n",
      "[1, 1, 0.26190450092984274, 0.25644390518533566]\n",
      "[1, 1, 0.3829831229555454, 0.34540784264730123]\n",
      "[1, 1, 0.3706570420235998, 0.3348254619068809]\n",
      "[1, 1, 0.36819479971495495, 0.35006119609714303]\n",
      "[1, 1, 0.38228440555144216, 0.3417054112705748]\n",
      "[1, 1, 0.3182348357571247, 0.2943492694149701]\n",
      "[-1.000 -50.000]\n",
      "[1, 1, 0.35055601752829163, 0.3163009014138435]\n",
      "[1, 1, 0.4051734578051684, 0.3724304987586705]\n",
      "[1, 1, 0.3316232001085009, 0.3185104405044059]\n",
      "[1, 1, 0.38387153143250774, 0.3426232989909202]\n",
      "[1, 1, 0.34187612834016823, 0.3300666902484007]\n",
      "[1, 1, 0.3202312482210975, 0.29104735819305144]\n",
      "[1, 1, 0.3845991871385463, 0.33911057550973694]\n",
      "[1, 1, 0.34212114864999243, 0.3052079508531591]\n",
      "[1, 1, 0.30905213123154596, 0.2900424345697628]\n",
      "[1, 1, 0.39525305272104916, 0.3634797350492732]\n",
      "[1, 1, 0.3644563039200135, 0.3325561353100019]\n",
      "[1, 1, 0.35545463888545425, 0.3177316824266154]\n",
      "[1, 1, 0.32055665458692706, 0.2765892007278381]\n",
      "[1, 1, 0.3818777218185627, 0.351155383595687]\n",
      "[1, 1, 0.36186675229811416, 0.33232421554320296]\n",
      "[-1.000 -100.000]\n",
      "[1, 1, 0.3600142246669893, 0.3197795919056965]\n",
      "[1, 1, 0.3701031978505634, 0.34233057350965124]\n",
      "[1, 1, 0.343898290953454, 0.32833338935091805]\n",
      "[1, 1, 0.3550919655971928, 0.3037903019490223]\n",
      "[1, 1, 0.319008185272855, 0.29565870160365]\n",
      "[1, 1, 0.3601313289752374, 0.33398103293138925]\n",
      "[1, 1, 0.39431761913186636, 0.3570465069070288]\n",
      "[1, 1, 0.3548946767515254, 0.30566933163399856]\n",
      "[1, 1, 0.3599703994158162, 0.33890159723669433]\n",
      "[1, 1, 0.41407502497398485, 0.3685165882548414]\n",
      "[1, 1, 0.33899299827441187, 0.30765208885557954]\n",
      "[1, 1, 0.37457529844221304, 0.34861417630659397]\n",
      "[1, 1, 0.37046014135797684, 0.334340892244909]\n",
      "[1, 1, 0.35856540288674543, 0.3224000828960332]\n",
      "[1, 1, 0.33552079836657583, 0.31445447043263536]\n",
      "[-2.000 -5.000]\n",
      "[0, 0, 0.49870617057484473, 0.4769477334888765]\n",
      "[0, 0, 0.46140756701838753, 0.45978182576512155]\n",
      "[0, 0, 0.4427594008116155, 0.4343266769252731]\n",
      "[1, 1, 0.3998076834930189, 0.4145021394133654]\n",
      "[1, 1, 0.47873155244257204, 0.4473137257227848]\n",
      "[0, 0, 0.438630481811016, 0.4427053099041289]\n",
      "[0, 0, 0.462394704612737, 0.4779096392609143]\n",
      "[1, 1, 0.47138263585575935, 0.4585459393306657]\n",
      "[0, 0, 0.4545610244164262, 0.4366750250754638]\n",
      "[0, 0, 0.4208567139700333, 0.4294712261620481]\n",
      "[0, 0, 0.48697273936049473, 0.4761005341782431]\n",
      "[0, 0, 0.47697936351107956, 0.4495971374241406]\n",
      "[0, 0, 0.4491903875069629, 0.4464785764983787]\n",
      "[1, 1, 0.4710673239766157, 0.45398615926201213]\n",
      "[0, 0, 0.47444190903886935, 0.4812167700406517]\n",
      "[-2.000 -10.000]\n",
      "[1, 1, 0.5028662246703213, 0.5062074869388224]\n",
      "[1, 1, 0.5199173155051205, 0.4995917644022773]\n",
      "[1, 1, 0.5228787447151817, 0.5053324378101574]\n",
      "[1, 1, 0.5348091095610145, 0.5186053763232059]\n",
      "[1, 1, 0.4478046336326753, 0.4187750362496439]\n",
      "[1, 1, 0.4792826643313248, 0.46838863813093273]\n",
      "[1, 1, 0.485329699969245, 0.4445685965915649]\n",
      "[1, 1, 0.5178580656389984, 0.5087037905554027]\n",
      "[0, 1, 0.5049726057391255, 0.4739194102701078]\n",
      "[1, 1, 0.5255365928253635, 0.5010348627152497]\n",
      "[1, 1, 0.5146066779389268, 0.4850573947870176]\n",
      "[1, 1, 0.4997720845000786, 0.46719895975908005]\n",
      "[1, 1, 0.5134156777950676, 0.4773545780241838]\n",
      "[1, 1, 0.4672867666634172, 0.4454890179153507]\n",
      "[1, 1, 0.49122016636862686, 0.47713140085817785]\n",
      "[-2.000 -20.000]\n",
      "[1, 1, 0.5633232423255645, 0.5369448398776537]\n",
      "[1, 1, 0.5379344893933548, 0.4929250491219083]\n",
      "[1, 1, 0.5623909314396465, 0.5253567650274137]\n",
      "[1, 1, 0.6311303496796129, 0.5624065934409216]\n",
      "[1, 1, 0.5450343653098217, 0.49161957106436377]\n",
      "[1, 1, 0.5373170304777046, 0.48658213001803446]\n",
      "[1, 1, 0.5430560264170169, 0.505922354458016]\n",
      "[1, 1, 0.5831977102448554, 0.5314995375343997]\n",
      "[1, 1, 0.5382769852066844, 0.49708166737713605]\n",
      "[1, 1, 0.50466530230211, 0.4603513491811003]\n",
      "[1, 1, 0.5563024985504933, 0.5059218001631598]\n",
      "[1, 1, 0.5241568291044769, 0.47503219109392625]\n",
      "[1, 1, 0.615145604952821, 0.5446922383993814]\n",
      "[1, 1, 0.4933940048691775, 0.4645315788544789]\n",
      "[1, 1, 0.461227405020862, 0.44480177852206615]\n",
      "[-2.000 -50.000]\n",
      "[1, 1, 0.5314835378489066, 0.5051825739714806]\n",
      "[1, 1, 0.581373573817214, 0.509344351363087]\n",
      "[1, 1, 0.5502416569094686, 0.504602288088646]\n",
      "[1, 1, 0.5355194584619503, 0.48510925500325663]\n",
      "[1, 1, 0.4907260041099232, 0.4683606358687421]\n",
      "[1, 1, 0.5570991700182587, 0.5264597827509808]\n",
      "[1, 1, 0.5658563090512724, 0.5281872630655073]\n",
      "[1, 1, 0.5642714231407618, 0.5149194169829439]\n",
      "[1, 1, 0.5470558851129106, 0.5027000862593611]\n",
      "[1, 1, 0.5474877176869329, 0.5072219628529415]\n",
      "[1, 1, 0.5134721383259611, 0.47198913704372536]\n",
      "[1, 1, 0.5341244372307355, 0.4798890005472995]\n",
      "[1, 1, 0.6241215631886098, 0.5793740494201947]\n",
      "[1, 1, 0.5625723585676359, 0.4995376479095167]\n",
      "[1, 1, 0.5533205399284423, 0.5132066267960836]\n",
      "[-2.000 -100.000]\n",
      "[1, 1, 0.5876080418855145, 0.528837990386134]\n",
      "[1, 1, 0.6312067183732917, 0.5314430028286821]\n",
      "[1, 1, 0.5234589708677416, 0.46900631155878436]\n",
      "[1, 1, 0.5529014233956003, 0.5125507116259191]\n",
      "[1, 1, 0.6116589898919469, 0.5512112492113342]\n",
      "[1, 1, 0.59002719839251, 0.5112879820901487]\n",
      "[1, 1, 0.5528302648932895, 0.4996292155548689]\n",
      "[1, 1, 0.6164364341139391, 0.5623266293845547]\n",
      "[1, 1, 0.5584738939926331, 0.4977389104161577]\n",
      "[1, 1, 0.5985810408899283, 0.5497946587906817]\n",
      "[1, 1, 0.5376040853250599, 0.49093073201197945]\n",
      "[1, 1, 0.5472808439486176, 0.4946609099777227]\n",
      "[1, 1, 0.5408622391374005, 0.51275301302093]\n",
      "[1, 1, 0.5366597932172522, 0.49872585474651276]\n",
      "[1, 1, 0.5507313777981394, 0.5079571007071283]\n",
      "[-5.000 -10.000]\n",
      "[0, 0, 0.8931049043947488, 0.868271362312244]\n",
      "[0, 0, 0.7820799589193145, 0.7864803426116542]\n",
      "[0, 0, 0.824291240659686, 0.8145000838579834]\n",
      "[0, 1, 0.7950217136870082, 0.7954799666652527]\n",
      "[0, 0, 0.8494805589298529, 0.8420196339578727]\n",
      "[0, 0, 0.8756936813626591, 0.8542589504344809]\n",
      "[0, 1, 0.8611828264204596, 0.8388652007800406]\n",
      "[0, 0, 0.812027710786469, 0.7870959193106354]\n",
      "[0, 0, 0.7646194564004425, 0.7832515443850093]\n",
      "[0, 0, 0.8103214855739701, 0.8219130501739788]\n",
      "[0, 0, 0.7915548640233279, 0.7710745434209151]\n",
      "[0, 0, 0.8360634679894943, 0.8155365416394119]\n",
      "[0, 1, 0.8359225384383374, 0.8145611014126608]\n",
      "[0, 1, 0.7850209671653526, 0.7456870982889335]\n",
      "[1, 1, 0.8502053983483007, 0.8204334315167545]\n",
      "[-5.000 -20.000]\n",
      "[1, 1, 0.8640783150502809, 0.8457936565659195]\n",
      "[1, 1, 0.8676195162494417, 0.8220811312066162]\n",
      "[0, 1, 0.8426058760397307, 0.8316809919915132]\n",
      "[1, 1, 0.8876629837995798, 0.876160049660286]\n",
      "[1, 1, 0.9000940840828462, 0.8830758044504344]\n",
      "[1, 0, 0.8256332861703274, 0.8317173465300405]\n",
      "[0, 0, 0.8739368095714067, 0.8516891055580227]\n",
      "[1, 1, 0.9052717828399689, 0.8465189231550171]\n",
      "[1, 1, 0.8670211888800015, 0.8602493209292588]\n",
      "[1, 1, 0.8850965482212678, 0.8629760044787751]\n",
      "[1, 1, 0.8859350233150869, 0.8494216058373276]\n",
      "[1, 1, 0.8795273416008685, 0.8398351345072727]\n",
      "[1, 1, 0.8669519089738564, 0.8361113292749422]\n",
      "[1, 1, 0.8623340312403917, 0.8696044453648654]\n",
      "[1, 1, 0.9002332235389526, 0.8482831903626172]\n",
      "[-5.000 -50.000]\n",
      "[1, 1, 0.924332981789766, 0.8517231432636388]\n",
      "[1, 1, 0.9289992031914741, 0.8681571659901735]\n",
      "[1, 1, 0.8684240594626776, 0.8200709730331187]\n",
      "[1, 1, 0.906741417637464, 0.8541196794298447]\n",
      "[1, 1, 0.8971051765736204, 0.879854198133785]\n",
      "[1, 1, 0.9997172093413499, 0.918671085809499]\n",
      "[1, 1, 0.9530614327275431, 0.8708908777909095]\n",
      "[1, 1, 0.9288808482981185, 0.8534527560085194]\n",
      "[1, 1, 0.8981629246471676, 0.8431157094776499]\n",
      "[1, 1, 0.9466118554045038, 0.8817315402443278]\n",
      "[1, 1, 0.9508734984291417, 0.9001713807533602]\n",
      "[1, 1, 0.9118069378221663, 0.8344826661604428]\n",
      "[1, 1, 0.9247066560184518, 0.835938961348044]\n",
      "[1, 1, 0.9407257950146274, 0.8481927262037275]\n",
      "[1, 1, 0.9404039883111588, 0.8696244069950816]\n",
      "[-5.000 -100.000]\n",
      "[1, 1, 0.9459785283253548, 0.8843807581897445]\n",
      "[1, 1, 0.9894692533280713, 0.9089357849640702]\n",
      "[1, 1, 1.0124951284752788, 0.9134380514710767]\n",
      "[1, 1, 0.8937475432683354, 0.8501894427199704]\n",
      "[1, 1, 0.9690898370491741, 0.8557675521644403]\n",
      "[1, 1, 0.9368744595088533, 0.8646106140241809]\n",
      "[1, 1, 0.9622517983931478, 0.8991401620711875]\n",
      "[1, 1, 0.9358992618504958, 0.8726870567001309]\n",
      "[1, 1, 0.9308995131323763, 0.8704253295165945]\n",
      "[1, 1, 0.9332525657523969, 0.8669183543660494]\n",
      "[1, 1, 0.9402818044704524, 0.8407827378478051]\n",
      "[1, 1, 0.9032085215324935, 0.8583948431568875]\n",
      "[1, 1, 0.9615821675029774, 0.8707029205506628]\n",
      "[1, 1, 0.9372397703686132, 0.9007501078963664]\n",
      "[1, 1, 0.9764474713513244, 0.9000240090046887]\n",
      "[-10.000 -20.000]\n",
      "[0, 0, 1.1064531214045643, 1.1150965489590048]\n",
      "[0, 0, 1.0828253145687887, 1.1032085692623181]\n",
      "[0, 0, 1.1718002121699727, 1.1926120410979688]\n",
      "[0, 0, 1.123012221228601, 1.1346122052136935]\n",
      "[0, 0, 1.0905731260063147, 1.1018295058875398]\n",
      "[0, 1, 1.1289704220418457, 1.1311762287422622]\n",
      "[0, 1, 1.1141640342155934, 1.100518284468771]\n",
      "[1, 1, 1.123023898204466, 1.1213350317648731]\n",
      "[0, 0, 1.0895141977683693, 1.0975482421047513]\n",
      "[0, 0, 1.126976509309889, 1.118417324118393]\n",
      "[0, 0, 1.0781238177592067, 1.0679197741934818]\n",
      "[0, 0, 1.1287258995054434, 1.1124055842868117]\n",
      "[0, 0, 1.1412877760703402, 1.1389986402168286]\n",
      "[0, 0, 1.1420736065751462, 1.1396765878193649]\n",
      "[1, 1, 1.1165315838636531, 1.112026132030619]\n",
      "[-10.000 -50.000]\n",
      "[1, 1, 1.1935319953845807, 1.171662001258437]\n",
      "[1, 1, 1.1621100902104893, 1.1257793917805663]\n",
      "[1, 1, 1.2299521833075397, 1.1920438396338375]\n",
      "[0, 1, 1.1932788671804309, 1.1591941945289923]\n",
      "[1, 1, 1.2454738388860258, 1.1739180233580202]\n",
      "[1, 1, 1.2288346895283089, 1.199295783784072]\n",
      "[0, 1, 1.2543275191058953, 1.232586439687454]\n",
      "[1, 1, 1.2237217660119915, 1.1369247693942632]\n",
      "[1, 1, 1.1599138741950608, 1.1227825845339954]\n",
      "[1, 1, 1.2484684516261113, 1.2126409477177684]\n",
      "[1, 1, 1.1596360201130516, 1.1491914954348115]\n",
      "[1, 1, 1.124365872158732, 1.1167797285519558]\n",
      "[1, 1, 1.2191966699814305, 1.1561321747005862]\n",
      "[1, 1, 1.1977496977273658, 1.1575544320985722]\n",
      "[1, 1, 1.1489189611879997, 1.1472325590517696]\n",
      "[-10.000 -100.000]\n",
      "[1, 1, 1.163410268557648, 1.1220065678056181]\n",
      "[1, 1, 1.276101646834291, 1.2136430031293552]\n",
      "[1, 1, 1.3201403214516925, 1.2745164685763772]\n",
      "[1, 1, 1.2727520775910794, 1.234424908195862]\n",
      "[1, 1, 1.2137940742469235, 1.1827393721801207]\n",
      "[1, 1, 1.2885942029456376, 1.2115507150552183]\n",
      "[1, 1, 1.2843857562960805, 1.2241916780186124]\n",
      "[1, 1, 1.2682891639689537, 1.2042137136372737]\n",
      "[1, 1, 1.2730555536719543, 1.2301789803403154]\n",
      "[1, 1, 1.233252359786671, 1.198996131312985]\n",
      "[1, 1, 1.2891355697479392, 1.20601339570378]\n",
      "[1, 1, 1.2163818222191576, 1.1482906517353457]\n",
      "[1, 1, 1.2499447619852588, 1.1436772007569718]\n",
      "[1, 1, 1.2639808570619173, 1.2157954334721475]\n",
      "[1, 1, 1.2856323136263768, 1.193445864949609]\n",
      "[-20.000 -50.000]\n",
      "[0, 1, 1.4220445252634613, 1.4144375519525658]\n",
      "[0, 1, 1.5127756395994836, 1.4428522677131224]\n",
      "[0, 0, 1.4327496267445134, 1.4554021537229955]\n",
      "[0, 0, 1.397113818727027, 1.4045392236433576]\n",
      "[1, 1, 1.4544057466175175, 1.3944734656233129]\n",
      "[1, 1, 1.4749458044493833, 1.4703886715275971]\n",
      "[0, 0, 1.4244653848084703, 1.3868252642769767]\n",
      "[0, 1, 1.4364800815190097, 1.4153364144718177]\n",
      "[0, 0, 1.4216177443722455, 1.3999530461061644]\n",
      "[1, 1, 1.4500829190883597, 1.4308340939509652]\n",
      "[0, 0, 1.44042424634804, 1.3954459717747074]\n",
      "[1, 1, 1.418071701573301, 1.4179566892264206]\n",
      "[0, 0, 1.505601579256202, 1.5079265880106223]\n",
      "[1, 1, 1.4382536206285994, 1.4128105200782706]\n",
      "[0, 0, 1.4382402506672383, 1.4447647766982121]\n",
      "[-20.000 -100.000]\n",
      "[1, 1, 1.567857172865274, 1.5164749325805311]\n",
      "[1, 1, 1.5129491797715047, 1.4763570261172771]\n",
      "[1, 1, 1.5835253870551906, 1.5092246539372691]\n",
      "[1, 1, 1.566648207233321, 1.499066594400863]\n",
      "[1, 1, 1.5284552354114698, 1.5065446513216023]\n",
      "[0, 1, 1.4437309612261076, 1.4182123460811378]\n",
      "[1, 1, 1.488852409297222, 1.4384102065043156]\n",
      "[1, 1, 1.4828607389251787, 1.453236645308995]\n",
      "[1, 1, 1.4865589075162853, 1.4250580329649565]\n",
      "[1, 1, 1.5193403377202475, 1.4872053832008165]\n",
      "[1, 1, 1.49443663762556, 1.48173145248201]\n",
      "[0, 1, 1.5618230088986913, 1.483874601582204]\n",
      "[0, 1, 1.5689466408034207, 1.4874746683143238]\n",
      "[1, 1, 1.557799287578437, 1.4860906621144065]\n",
      "[0, 1, 1.5845989703265067, 1.4759473595119221]\n",
      "[-50.000 -100.000]\n",
      "[0, 0, 1.8630256145903072, 1.8206430023114413]\n",
      "[0, 0, 1.86957160735172, 1.8643046006561907]\n",
      "[0, 1, 1.8007414720668218, 1.7920056099772077]\n",
      "[0, 1, 1.8269238802714578, 1.7845758172595234]\n",
      "[0, 0, 1.9072396079148504, 1.8667864835844052]\n",
      "[0, 0, 1.8252618192325634, 1.8120013149622098]\n",
      "[0, 0, 1.7595630911441575, 1.8040152736343325]\n",
      "[0, 0, 1.7547156657766951, 1.750271945990517]\n",
      "[0, 1, 1.8643843778499078, 1.819856152721618]\n",
      "[0, 0, 1.7319788434273227, 1.7374324098320983]\n",
      "[0, 0, 1.8938521357216456, 1.8717785955586816]\n",
      "[0, 0, 1.7591730372139973, 1.7866371428742853]\n",
      "[0, 1, 1.8584156759966821, 1.7989234852043885]\n",
      "[0, 0, 1.8185995809986215, 1.8144872463654962]\n",
      "[0, 0, 1.8229024202947341, 1.8123830115169102]\n"
     ]
    }
   ],
   "source": [
    "nsims = 15\n",
    "gamma = [-1.,-2.,-5.,-10.,-20.,-50.,-100.]\n",
    "diffgamma = np.reshape(list(it.combinations(gamma, 2)), (-1,2)) # np.reshape([(-1., x) for x in gamma[:-1][::2]], (-1,2)) #\n",
    "diffprobsf = np.zeros((len(diffgamma),nsims))\n",
    "diffprobsa = np.zeros((len(diffgamma),nsims))\n",
    "sinpredsf = np.zeros((len(diffgamma),nsims))\n",
    "sinpredsa = np.zeros((len(diffgamma),nsims))\n",
    "for ig, g in enumerate(diffgamma):\n",
    "    print(g)\n",
    "    for sim in range(nsims):\n",
    "        with open('simfiles/SelPoint.txt', 'r') as file:\n",
    "            data = file.readlines()\n",
    "\n",
    "        data[0] = '{:d} 0.5\\n'.format(int(-g[1]))\n",
    "        data[1] = '{:d} 1.0\\n'.format(int(-g[0]))\n",
    "\n",
    "        with open('simfiles/SelPoint.txt', 'w') as file:\n",
    "            file.writelines(data)\n",
    "\n",
    "        with open('simfiles/ParameterFilesPoint.txt', 'r') as file:\n",
    "            data = file.readlines()\n",
    "        \n",
    "        data[8] = 'FilePrefix: outfiles/Point_g{}_g{}_sim{}'.format(-g[0],-g[1],sim)\n",
    "\n",
    "        with open('simfiles/ParameterFilesPoint.txt', 'w') as file:\n",
    "            file.writelines(data)\n",
    "        \n",
    "        os.system(\"GSL_RNG_SEED={} GSL_RNG_TYPE=mrg ../../PReFerSim/PReFerSim simfiles/ParameterFilesPoint.txt 3 > /dev/null 2>&1 \".format(rng.integers(100496)))\n",
    "\n",
    "        dft = pd.read_csv('outfiles/Point_g{}_g{}_sim{}.3.full_out.txt'.format(-g[0],-g[1],sim),sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "        res = resample_calculateprob_freqcont(dft, g, t=200)\n",
    "        diffprobsf[ig,sim] = res[0]; diffprobsa[ig,sim] = res[1]; sinpredsf[ig,sim] = 10**res[2]; sinpredsa[ig,sim] = 10**res[3]\n",
    "        print(res)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "metadata": {},
   "outputs": [],
   "source": [
    "# diffprobsf, diffprobsa, sinpredsf, sinpredsa\n",
    "np.savetxt(X=np.vstack((diffprobsf,diffprobsa)),fname=\"outfiles/diffprobt400.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Input \u001b[0;32mIn [74]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      8\u001b[0m newdat \u001b[38;5;241m=\u001b[39m newdf1\u001b[38;5;241m.\u001b[39mto_numpy()\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m## continuous pred doesn't do great, worse than using grid! \u001b[39;00m\n\u001b[0;32m---> 10\u001b[0m diffprobs[ig,\u001b[38;5;241m0\u001b[39m], sinpreds[ig,\u001b[38;5;241m0\u001b[39m], dubpreds[ig,:\u001b[38;5;241m2\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43mresample_calculateprob_freqcont\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnewdat\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgamma\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_sims\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_samps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m100\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcutoff\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Input \u001b[0;32mIn [66]\u001b[0m, in \u001b[0;36mresample_calculateprob_freqcont\u001b[0;34m(newdat, gamma, num_sims, num_samps, thresh, cutoff)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m n \u001b[38;5;129;01min\u001b[39;00m np\u001b[38;5;241m.\u001b[39marange(num_sims):\n\u001b[1;32m      7\u001b[0m     newnewdat \u001b[38;5;241m=\u001b[39m newdat[np\u001b[38;5;241m.\u001b[39mrandom\u001b[38;5;241m.\u001b[39mchoice(newdat\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], num_samps, replace\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m),:]\n\u001b[0;32m----> 8\u001b[0m     ressin \u001b[38;5;241m=\u001b[39m \u001b[43msp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mminimize_scalar\u001b[49m\u001b[43m(\u001b[49m\u001b[43mget_ll_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mnewnewdat\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mxtol\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m.05\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m     resdub \u001b[38;5;241m=\u001b[39m sp\u001b[38;5;241m.\u001b[39moptimize\u001b[38;5;241m.\u001b[39mminimize(get_ll_freq2, x0\u001b[38;5;241m=\u001b[39m[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m10\u001b[39m], method\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mL-BFGS-B\u001b[39m\u001b[38;5;124m'\u001b[39m, args\u001b[38;5;241m=\u001b[39m(newnewdat[:,\u001b[38;5;241m1\u001b[39m]), options\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmaxiter\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m50\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mftol\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;241m1e-2\u001b[39m,}, bounds\u001b[38;5;241m=\u001b[39m[(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2\u001b[39m),(\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m200\u001b[39m,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m0.2\u001b[39m)])\n\u001b[1;32m     11\u001b[0m     estgonlyfreq \u001b[38;5;241m=\u001b[39m ressin\u001b[38;5;241m.\u001b[39mx\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/scipy/optimize/_minimize.py:886\u001b[0m, in \u001b[0;36mminimize_scalar\u001b[0;34m(fun, bracket, bounds, args, method, tol, options)\u001b[0m\n\u001b[1;32m    884\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m method(fun, args\u001b[38;5;241m=\u001b[39margs, bracket\u001b[38;5;241m=\u001b[39mbracket, bounds\u001b[38;5;241m=\u001b[39mbounds, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39moptions)\n\u001b[1;32m    885\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbrent\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 886\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_minimize_scalar_brent\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfun\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbracket\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    887\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m meth \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mbounded\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[1;32m    888\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m bounds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2498\u001b[0m, in \u001b[0;36m_minimize_scalar_brent\u001b[0;34m(func, brack, args, xtol, maxiter, disp, **unknown_options)\u001b[0m\n\u001b[1;32m   2495\u001b[0m brent \u001b[38;5;241m=\u001b[39m Brent(func\u001b[38;5;241m=\u001b[39mfunc, args\u001b[38;5;241m=\u001b[39margs, tol\u001b[38;5;241m=\u001b[39mtol,\n\u001b[1;32m   2496\u001b[0m               full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, maxiter\u001b[38;5;241m=\u001b[39mmaxiter, disp\u001b[38;5;241m=\u001b[39mdisp)\n\u001b[1;32m   2497\u001b[0m brent\u001b[38;5;241m.\u001b[39mset_bracket(brack)\n\u001b[0;32m-> 2498\u001b[0m \u001b[43mbrent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimize\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2499\u001b[0m x, fval, nit, nfev \u001b[38;5;241m=\u001b[39m brent\u001b[38;5;241m.\u001b[39mget_result(full_output\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m   2501\u001b[0m success \u001b[38;5;241m=\u001b[39m nit \u001b[38;5;241m<\u001b[39m maxiter \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (np\u001b[38;5;241m.\u001b[39misnan(x) \u001b[38;5;129;01mor\u001b[39;00m np\u001b[38;5;241m.\u001b[39misnan(fval))\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2268\u001b[0m, in \u001b[0;36mBrent.optimize\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2265\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21moptimize\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[1;32m   2266\u001b[0m     \u001b[38;5;66;03m# set up for optimization\u001b[39;00m\n\u001b[1;32m   2267\u001b[0m     func \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[0;32m-> 2268\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget_bracket_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2269\u001b[0m     _mintol \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mintol\n\u001b[1;32m   2270\u001b[0m     _cg \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_cg\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2242\u001b[0m, in \u001b[0;36mBrent.get_bracket_info\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   2239\u001b[0m \u001b[38;5;66;03m### BEGIN core bracket_info code ###\u001b[39;00m\n\u001b[1;32m   2240\u001b[0m \u001b[38;5;66;03m### carefully DOCUMENT any CHANGES in core ##\u001b[39;00m\n\u001b[1;32m   2241\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m brack \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m-> 2242\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[38;5;241m=\u001b[39m \u001b[43mbracket\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2243\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(brack) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m2\u001b[39m:\n\u001b[1;32m   2244\u001b[0m     xa, xb, xc, fa, fb, fc, funcalls \u001b[38;5;241m=\u001b[39m bracket(func, xa\u001b[38;5;241m=\u001b[39mbrack[\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m   2245\u001b[0m                                                xb\u001b[38;5;241m=\u001b[39mbrack[\u001b[38;5;241m1\u001b[39m], args\u001b[38;5;241m=\u001b[39margs)\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/scipy/optimize/_optimize.py:2752\u001b[0m, in \u001b[0;36mbracket\u001b[0;34m(func, xa, xb, args, grow_limit, maxiter)\u001b[0m\n\u001b[1;32m   2750\u001b[0m _gold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1.618034\u001b[39m  \u001b[38;5;66;03m# golden ratio: (1.0+sqrt(5.0))/2.0\u001b[39;00m\n\u001b[1;32m   2751\u001b[0m _verysmall_num \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-21\u001b[39m\n\u001b[0;32m-> 2752\u001b[0m fa \u001b[38;5;241m=\u001b[39m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mxa\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43margs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2753\u001b[0m fb \u001b[38;5;241m=\u001b[39m func(\u001b[38;5;241m*\u001b[39m(xb,) \u001b[38;5;241m+\u001b[39m args)\n\u001b[1;32m   2754\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (fa \u001b[38;5;241m<\u001b[39m fb):                      \u001b[38;5;66;03m# Switch so fa > fb\u001b[39;00m\n",
      "Input \u001b[0;32mIn [64]\u001b[0m, in \u001b[0;36mget_ll_freq\u001b[0;34m(g, sXlred, n, cutoff)\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[38;5;66;03m# just performing a search in a look-up table\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m idx, i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(np\u001b[38;5;241m.\u001b[39mwhere((sXlred\u001b[38;5;241m>\u001b[39mcutoff) \u001b[38;5;241m&\u001b[39m (sXlred\u001b[38;5;241m<\u001b[39mn\u001b[38;5;241m-\u001b[39mcutoff\u001b[38;5;241m+\u001b[39m\u001b[38;5;241m1\u001b[39m))[\u001b[38;5;241m0\u001b[39m]):\n\u001b[0;32m---> 11\u001b[0m     res[idx] \u001b[38;5;241m=\u001b[39m \u001b[43mpxs\u001b[49m\u001b[43m[\u001b[49m\u001b[43msXlred\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;241m-\u001b[39mnp\u001b[38;5;241m.\u001b[39msum(np\u001b[38;5;241m.\u001b[39mlog(res))\n",
      "File \u001b[0;32m~/mambaforge/envs/cvae/lib/python3.10/site-packages/numpy/ma/core.py:3222\u001b[0m, in \u001b[0;36mMaskedArray.__getitem__\u001b[0;34m(self, indx)\u001b[0m\n\u001b[1;32m   3212\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3213\u001b[0m \u001b[38;5;124;03mx.__getitem__(y) <==> x[y]\u001b[39;00m\n\u001b[1;32m   3214\u001b[0m \n\u001b[1;32m   3215\u001b[0m \u001b[38;5;124;03mReturn the item described by i, as a masked array.\u001b[39;00m\n\u001b[1;32m   3216\u001b[0m \n\u001b[1;32m   3217\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m   3218\u001b[0m \u001b[38;5;66;03m# We could directly use ndarray.__getitem__ on self.\u001b[39;00m\n\u001b[1;32m   3219\u001b[0m \u001b[38;5;66;03m# But then we would have to modify __array_finalize__ to prevent the\u001b[39;00m\n\u001b[1;32m   3220\u001b[0m \u001b[38;5;66;03m# mask of being reshaped if it hasn't been set up properly yet\u001b[39;00m\n\u001b[1;32m   3221\u001b[0m \u001b[38;5;66;03m# So it's easier to stick to the current version\u001b[39;00m\n\u001b[0;32m-> 3222\u001b[0m dout \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata\u001b[49m\u001b[43m[\u001b[49m\u001b[43mindx\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m   3223\u001b[0m _mask \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_mask\n\u001b[1;32m   3225\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_is_scalar\u001b[39m(m):\n",
      "\u001b[0;31mIndexError\u001b[0m: only integers, slices (`:`), ellipsis (`...`), numpy.newaxis (`None`) and integer or boolean arrays are valid indices"
     ]
    }
   ],
   "source": [
    "diffgamma = np.reshape(list(it.combinations(gamma, 2)), (-1,2)) # np.reshape([(-1., x) for x in gamma[:-1][::2]], (-1,2)) #\n",
    "diffprobs = np.zeros((len(diffgamma),2))\n",
    "sinpreds = np.zeros((len(diffgamma),2))\n",
    "dubpreds = np.zeros((len(diffgamma),4))\n",
    "for ig, g in enumerate(diffgamma):\n",
    "    newdf1 = df2.iloc[np.ravel(np.where(dat2[:,0]==g[0])),:].append(df2.iloc[np.ravel(np.where(dat2[:,0]==g[1])),:])\n",
    "    # newdf1 = newdf1.sample(frac=1)\n",
    "    newdat = newdf1.to_numpy()\n",
    "    ## continuous pred doesn't do great, worse than using grid! \n",
    "    diffprobs[ig,0], sinpreds[ig,0], dubpreds[ig,:2] = resample_calculateprob_freqcont(newdat, gamma, num_sims=5, num_samps=100, cutoff=0)\n",
    "    # diffprobs[ig,1], sinpreds[ig,1], dubpreds[ig,-2:] = resample_calculateprob_age(newdat, gamma2, num_sims=20, num_samps=1000, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dft = pd.read_csv('outfiles/Point.3.full_out.txt',sep='\\t',header=None,names=['','Xl','s','al','id'])\n",
    "# dft['empty'] = ''\n",
    "# dft['sXl'] = (dft['Xl']*200).astype('int')\n",
    "# dft['al'] = 80000+1 - dft['al']\n",
    "# dft['al'] = dft['al'].astype('int')\n",
    "# dft = dft.iloc[:,1:]\n",
    "# datt = dft.to_numpy()\n",
    "# sfs = moments.Spectrum(np.histogram(datt[:,5],bins=range(0,202))[0])\n",
    "# SMS = np.zeros((80000,200+1),dtype='int16')\n",
    "# mask = np.zeros_like(SMS); mask[0,:] = 1; mask[:,0] = 1; mask[:,-1] = 1;\n",
    "# for i in range(len(datt)):\n",
    "#     SMS[datt[i,2],datt[i,5]] += 1\n",
    "# SMSmask = np.ma.array(SMS,mask=mask)\n",
    "\n",
    "## with -100 & -1 (~15:85 split), -2.3 & -2.07 estimated with ll = -419 & -4536 respectively\n",
    "# sp.optimize.minimize_scalar(get_ll_freqconstant,args=({'sfs':sfs,'theta':2,'p_misid':0},200)), sp.optimize.minimize_scalar(get_ll_freqageconstant,args=({'sms':SMSmask,'theta':2,'N':10000,'p_misid':0,'gens':80000},200))\n",
    "# what if we said there were two gammas in the set? \n",
    "# from mom_functions import *\n",
    "## (-1, -65) & (-1,-90) estimated with ll = -349 & -4449 respectively (age takes ~4 mins)\n",
    "# sp.optimize.minimize(get_ll_freqconstant_twogam, x0=np.log10([5,50]), method='Nelder-Mead', args=({'sfs':sfs,'theta':200},400), bounds=[(-1,2.5),(-1,2.5)])\n",
    "# sp.optimize.minimize(get_ll_freqageconstant_twogam, x0=np.log10([1,50]), method='Powell', args=({'sms':SMSmask,'theta':200,'N':10000,'gens':80000},400), bounds=[(-1,2.5),(-1,2.5)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10.275835831072095, 40.862785)"
      ]
     },
     "execution_count": 159,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_ll_freqconstant_twogam(np.log10([5,50]),{'sfs':sfs,'theta':2,'p_misid':0},200), get_ll_freqageconstant_twogam(np.log10([5,50]),{'sms':SMSmask,'theta':2,'N':10000,'gens':80000},200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Need a way to plot what the predictions are too..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dubpredsfsame, dubpredsasame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(range(1,len(diffgamma)+1),diffgamma[:,0],marker='+',color='k',alpha=0.5); plt.scatter(range(1,len(diffgamma)+1),diffgamma[:,1],marker='+',color='k',label='True values'); #plt.yscale('symlog')\n",
    "plt.scatter(range(1,len(diffgamma)+1),sinpreds[:,0],color='deepskyblue',alpha=0.6,label='Predicted value (freq only)'); \n",
    "plt.scatter(range(1,len(diffgamma)+1),sinpreds[:,1],color='coral',alpha=0.6,label='Predicted value (freq & age)'); \n",
    "plt.plot([range(1,len(diffgamma)+1),range(1,len(diffgamma)+1)],[diffgamma[:,0],diffgamma[:,1]],color='k',alpha=0.4,linewidth=3); \n",
    "plt.legend(); plt.xlabel('replicate data set'); plt.ylabel(r'$\\gamma_{1,2}$'); plt.grid(); plt.xticks(ticks=range(1,22))\n",
    "# plt.savefig(\"../figs/twoparam1pred.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plt.hist(newdf1['al'].iloc[:1500],np.logspace(0,3)); plt.hist(newdf1['al'].iloc[1500:],np.logspace(0,3),alpha=0.5)\n",
    "# np.reshape(list(it.combinations(gamma[1::3], 2)), (-1,2))\n",
    "plt.scatter(diffgamma[:,0], diffgamma[:,1], marker='+', color='k', alpha=0.8, label='True values'); plt.yscale('symlog'); plt.xscale('symlog'); plt.grid()\n",
    "plt.scatter(np.unique(diffgamma), np.unique(diffgamma), marker='+', color='k', alpha=0.8); \n",
    "frmse = np.sqrt(np.mean(np.sum((dubpreds[:,0]-diffgamma[:,0])**2+(dubpreds[:,1]-diffgamma[:,1])**2)))#+np.mean(np.sum((dubpredsfsame[:,0]-np.unique(diffgamma))**2+(dubpredsfsame[:,1]-np.unique(diffgamma))**2)))\n",
    "plt.scatter(dubpreds[:,0], dubpreds[:,1], color='deepskyblue', alpha=0.4, label='Predicted values (freq only), RMSE: {:.0f}'.format(frmse)); \n",
    "# plt.scatter(dubpredsfsame[:,0], dubpredsfsame[:,1], color='deepskyblue', alpha=0.4); plt.scatter(dubpredsasame[:,0], dubpredsasame[:,1], color='coral', alpha=0.4);\n",
    "# armse = np.sqrt(np.mean(np.sum((dubpreds[:,2]-diffgamma[:,0])**2+(dubpreds[:,3]-diffgamma[:,1])**2))+np.mean(np.sum((dubpredsasame[:,0]-np.unique(diffgamma))**2+(dubpredsasame[:,1]-np.unique(diffgamma))**2)))\n",
    "# plt.scatter(dubpreds[:,2], dubpreds[:,3], color='coral', alpha=0.4, label='Predicted values (freq & age), RMSE: {:.0f}'.format(armse))\n",
    "plt.plot([diffgamma[:,0],dubpreds[:,0]],[diffgamma[:,1],dubpreds[:,1]],color='deepskyblue',alpha=0.4); plt.xlabel(r'$\\gamma_1$'); plt.ylabel(r'$\\gamma_2$')\n",
    "# plt.plot([diffgamma[:,0],dubpreds[:,2]],[diffgamma[:,1],dubpreds[:,3]],color='coral',alpha=0.4); plt.legend()\n",
    "# plt.plot([np.unique(diffgamma),dubpredsfsame[:,0]],[np.unique(diffgamma),dubpredsfsame[:,1]],color='deepskyblue',alpha=0.4)\n",
    "# plt.plot([np.unique(diffgamma),dubpredsasame[:,0]],[np.unique(diffgamma),dubpredsasame[:,1]],color='coral',alpha=0.4)\n",
    "plt.savefig(\"../figs/twoparampreds.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==s[5])),:].append(df1.iloc[np.ravel(np.where(dat[:,1]==s[4])),:])\n",
    "# newdat = newdf1.to_numpy()\n",
    "# print(resample_calculateprob_freq(newdat, gamma2, num_sims=16, num_samps=1200, cutoff=2))\n",
    "# print(resample_calculateprob_age(newdat, gamma2, num_sims=16, num_samps=1200, cutoff=2))\n",
    "newnewdat = newdat[np.random.choice(newdat.shape[0], 1200, replace=False),:]\n",
    "for ig, g in enumerate(gamma2):\n",
    "    # sum log prob for each locus\n",
    "    sin_onlyage[ig] = np.sum(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff))\n",
    "    for ig2, g2 in enumerate(gamma2[0:(ig+1)]):\n",
    "        dub_onlyage[ig, ig2] = np.sum(np.log(0.5*np.exp(get_lp_alxl(g, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff)) + 0.5*np.exp(get_lp_alxl(g2, newnewdat[:,5], newnewdat[:,2], cutoff=cutoff))))\n",
    "\n",
    "print(gamma[np.argmax(sin_onlyage)])\n",
    "print(np.take(gamma, np.unravel_index(np.argmax(np.ma.masked_array(dub_onlyage, mask)),dub_onlyage.shape)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "diffgamma = np.reshape(list(it.combinations(s, 2)), (-1,2)) # np.reshape([(-1., x) for x in gamma[:-1][::2]], (-1,2)) #\n",
    "diffprobs = np.zeros((len(diffgamma),2))\n",
    "sinpreds = np.zeros((len(diffgamma),2))\n",
    "dubpreds = np.zeros((len(diffgamma),4))\n",
    "for ig, g in enumerate(diffgamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g[0])),:].append(df1.iloc[np.ravel(np.where(dat[:,1]==g[1])),:])\n",
    "    # newdf1 = newdf1.sample(frac=1)\n",
    "    newdat = newdf1.to_numpy()\n",
    "    diffprobs[ig,0], sinpreds[ig,0], dubpreds[ig,:2] = resample_calculateprob_freq(newdat, gamma2, num_sims=20, num_samps=5000, cutoff=2)\n",
    "    diffprobs[ig,1], sinpreds[ig,1], dubpreds[ig,-2:] = resample_calculateprob_age(newdat, gamma2, num_sims=20, num_samps=5000, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "       [0.000, 0.000, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "       [0.733, 0.333, 0.000, 0.000, 0.000, 0.000, 0.000],\n",
       "       [1.000, 0.867, 0.133, 0.000, 0.000, 0.000, 0.000],\n",
       "       [1.000, 1.000, 0.867, 0.067, 0.000, 0.000, 0.000],\n",
       "       [1.000, 1.000, 1.000, 0.933, 0.267, 0.000, 0.000],\n",
       "       [1.000, 1.000, 1.000, 1.000, 0.733, 0.000, 0.000]])"
      ]
     },
     "execution_count": 207,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sinpredsfsame = np.zeros(len(np.unique(diffgamma)))\n",
    "sinpredsasame = np.zeros(len(np.unique(diffgamma)))\n",
    "dubpredsfsame = np.zeros((len(np.unique(diffgamma)),2))\n",
    "dubpredsasame = np.zeros((len(np.unique(diffgamma)),2))\n",
    "for ig, g in enumerate(np.unique(diffgamma)):\n",
    "    newdf1 = df2.iloc[np.ravel(np.where(dat2[:,1]==g)),:]\n",
    "    # newdf1 = newdf1.sample(frac=1)\n",
    "    newdat = newdf1.to_numpy()\n",
    "    powermat_freq[ig,ig], sinpredsfsame[ig], dubpredsfsame[ig,:2] = resample_calculateprob_freq(newdat, gamma2, num_sims=20, num_samps=1000, cutoff=2)\n",
    "    powermat_age[ig,ig], sinpredsasame[ig], dubpredsasame[ig,-2:] = resample_calculateprob_age(newdat, gamma2, num_sims=20, num_samps=1000, cutoff=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==np.unique(diffgamma)[2])),:]\n",
    "newdat = newdf1.to_numpy()\n",
    "print(resample_calculateprob_age(newdat, gamma, num_samps=800, cutoff=10))\n",
    "resample_calculateprob_freq(newdat, gamma, num_samps=800, cutoff=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==gamma[6])),:].append(df1.iloc[np.ravel(np.where(dat[:,1]==gamma[-1])),:])\n",
    "# newdat = newdf1.to_numpy()\n",
    "# print(resample_calculateprob_freq(newdat, gamma, num_sims=10, num_samps=1000, cutoff=50))\n",
    "# print(resample_calculateprob_age(newdat, gamma, num_sims=10, num_samps=1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([-np.mean(g) for g in diffgamma], -sinpreds[:,0], color='deepskyblue', marker='+', label='only freq')\n",
    "plt.scatter([-np.mean(g) for g in diffgamma], -sinpreds[:,1], color='coral', marker='*', label='freq & age',)\n",
    "plt.xlabel('mean of true γ'); plt.ylabel('predicted γ'); plt.loglog(); plt.legend() \n",
    "plt.axline((1,1),(100,100),color='grey',ls='--')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter([np.abs(g[1]-g[0]) for g in diffgamma], diffprobs[:,0], color='deepskyblue', alpha=0.7, label='only freq') #s=truenumlocifreq[:-1]/(truenumlocifreq[:-1]+truenumlocifreq[-1])*70.)\n",
    "plt.scatter([np.abs(g[1]-g[0]) for g in diffgamma], diffprobs[:,1], color='coral', alpha=0.7, label='freq & age')\n",
    "ginterp = np.logspace(0,4.5,base=np.exp(1),num=25)\n",
    "fit = sp.interpolate.interp1d([np.abs(g[1]-g[0]) for g in diffgamma], diffprobs[:,0], kind='linear')\n",
    "plt.plot(ginterp, fit(ginterp), '--', color='deepskyblue', alpha=0.7)\n",
    "fit = sp.interpolate.interp1d([np.abs(g[1]-g[0]) for g in diffgamma], diffprobs[:,1], kind='linear')\n",
    "plt.plot(ginterp, fit(ginterp), '--', color='coral', alpha=0.7)\n",
    "plt.ylim((-0.1,1.1)); plt.xscale('log'); plt.xlabel('log(|γ1-γ2|)'); plt.ylabel('prob of choosing complex model'); plt.legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [],
   "source": [
    "## alternative plotting mechanism to highlight the power in discriminating between gamma values\n",
    "powermat_freq = np.zeros((len(np.unique(diffgamma)),len(np.unique(diffgamma))))\n",
    "powermat_age = np.zeros((len(np.unique(diffgamma)),len(np.unique(diffgamma))))\n",
    "\n",
    "mask_pow = np.full(powermat_freq.shape,False)\n",
    "mask_pow[np.tril_indices_from(powermat_freq,k=-1)] = True\n",
    "\n",
    "for ig, g in enumerate(diffgamma[:,]):\n",
    "    powermat_freq[np.argmax(g[0]==np.unique(diffgamma)), np.argmax(g[1]==np.unique(diffgamma))] = np.sum(diffprobsf[ig, :])/15\n",
    "    powermat_age[np.argmax(g[0]==np.unique(diffgamma)), np.argmax(g[1]==np.unique(diffgamma))] = np.sum(diffprobsa[ig, :])/15"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.colorbar.Colorbar at 0x28d0ed480>"
      ]
     },
     "execution_count": 239,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "text/plain": [
       "<Figure size 1500x1050 with 0 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 550x385 with 4 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# np.hstack((diffgamma, dubpreds))\n",
    "# np.argmax(diffgamma[0][1]==np.unique(diffgamma))\n",
    "plt.figure(dpi=300)\n",
    "fig, (ax1, ax2, ax3) = plt.subplots(1,3)\n",
    "seaborn.heatmap(powermat_freq.T, mask=mask_pow, xticklabels=[-100,-50,-25,-10,-5,-2,-1], yticklabels=[-100,-50,-25,-10,-5,-2,-1], cmap='GnBu', ax=ax1, cbar=False, linewidths=0.05, square=True,alpha=0.8,vmin=0,); #ax1.set_ylabel(r'$\\gamma_1$'); \n",
    "ax1.set_title('freq only'); ax2.set_title('freq & age'); ax3.set_title('increase in power with age',fontsize=8)\n",
    "im = seaborn.heatmap(powermat_age.T, mask=mask_pow, xticklabels=[-100,-50,-25,-10,-5,-2,-1], yticklabels=[], cmap='GnBu', square=True, ax=ax2, linewidths=0.05, vmin=0, cbar=False,alpha=0.8)\n",
    "seaborn.heatmap(powermat_age.T-powermat_freq.T, mask=mask_pow, xticklabels=[-100,-50,-25,-10,-5,-2,-1], yticklabels=[], cmap='GnBu', vmax=0.8, square=True, ax=ax3, linewidths=0.05, vmin=-0, cbar=False,alpha=0.8)\n",
    "plt.colorbar(im.get_children()[0], ax = [ax1,ax2,ax3],orientation = 'horizontal',shrink=0.55,label='prob. of choosing two parameter model',)\n",
    "# plt.savefig('../figs/twoparamdiff.pdf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "truenumloci = np.zeros(len(gamma))\n",
    "for ig, g in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),:]\n",
    "    sXlred = newdf1['sXl']\n",
    "    truenumloci[ig] = np.sum((sXlred>10) & (sXlred<n-10+1))\n",
    "\n",
    "truenumlocifreq = np.zeros(len(gamma))\n",
    "for ig, g in enumerate(gamma):\n",
    "    newdf1 = df1.iloc[np.ravel(np.where(dat[:,1]==g)),0:3]\n",
    "    truenumlocifreq[ig] = newdf1.to_numpy().shape[0]\n",
    "\n",
    "truenumloci"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Automating workflow for simulating point DFE from PReFerSim (instead of using the R approach from before)\n",
    "\n",
    "Here, I will write a python function to run the program with appropriate parameters and read the input into a dataframe after."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/Users/vivaswatshastry/selCoefEst/PReFerSims\")\n",
    "## creating a small set of gamma for simulating data (testing framework) \n",
    "## gamma = 4Ns (if it has to coincide with the moments framework)\n",
    "# gamma = -np.round(np.logspace(0,2,20),2) \n",
    "# s = -np.array([1.,5.,10.,50.,100.,500.])\n",
    "# for ig, g in enumerate(gamma[1:]):\n",
    "#     with open('simfiles/ParameterFilesConstant.txt',\"r\") as file:\n",
    "#         data = file.readlines()\n",
    "\n",
    "#     data[2] = 'DFEPointSelectionCoefficient: {:f}\\n'.format(-0.25*g/10000)\n",
    "#     data[7] = 'FilePrefix: outfiles/ConstantSize{}\\n'.format(-g)\n",
    "\n",
    "#     with open('simfiles/ParameterFilesConstant.txt', 'w') as file:\n",
    "#         file.writelines(data)\n",
    "        \n",
    "#     os.system(\"GSL_RNG_SEED={} GSL_RNG_TYPE=mrg ../../PReFerSim/PReFerSim simfiles/ParameterFilesConstant.txt 2\".format(rng.integers(100496)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## reading in the data and storing in a data frame\n",
    "nsites = 2000\n",
    "# gamma = np.array([0, -0.01, -.1, -1, -10, -100])\n",
    "df1 = pd.DataFrame(index=range(nsites*len(gamma)),columns=['','Xl','s','al','id'])\n",
    "for ig, g in enumerate(gamma):\n",
    "    # if(g==-100.):\n",
    "    #     df1.iloc[(ig*nsites):(ig+1)*nsites] = pd.read_csv('outfiles/ConstantSize50.0.1.full_out.txt'.format(-g),sep='\\t',header=None).sample(n=nsites)\n",
    "    # elif(g==-1.):\n",
    "    #     df1.iloc[(ig*nsites):(ig+1)*nsites] = pd.read_csv('outfiles/ConstantSize2.0.1.full_out.txt'.format(-g),sep='\\t',header=None).sample(n=nsites)\n",
    "    # else:\n",
    "    if g!=0:\n",
    "        df1.iloc[(ig*nsites):(ig+1)*nsites] = pd.read_csv('outfiles/ConstantSize{}.2.full_out.txt'.format(-g),sep='\\t',header=None).sample(n=nsites)\n",
    "    else:\n",
    "        df1.iloc[(ig*nsites):(ig+1)*nsites] = pd.read_csv('outfiles/ConstantSize{}.2.full_out.txt'.format(g),sep='\\t',header=None).sample(n=nsites)\n",
    "    df1['s'].iloc[(ig*nsites):(ig+1)*nsites] = np.repeat(g,nsites)\n",
    "df1['empty'] = ''\n",
    "df1['sXl'] = (df1['Xl']*2000).astype('int')\n",
    "df1['al'] = 80000+1 - df1['al']\n",
    "df1['al'] = df1['al'].astype('int')\n",
    "df1 = df1.iloc[:,1:]\n",
    "dat = df1.to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(df1)):\n",
    "    if(df1['al'][i]<0):\n",
    "        df1.iloc[i,2] = df1.iloc[i,2] + 20000\n",
    "df1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# [0.5,1,2,5,10,20,50,100,200,500]\n",
    "# np.concatenate((-np.arange(1,5),-np.round(np.logspace(-1,10,25,base=2,),1)))\n",
    "# gamma = -np.logspace(-0.2,3,25,base=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MutationRate: 1000\n",
    "# DFEType: point\n",
    "# DFEPointSelectionCoefficient: 0.005\n",
    "# DemographicHistory: simfiles/ConstantSize.txt \n",
    "# n: 2000\n",
    "# PrintSegSiteInfo: 1\n",
    "# LastGenerationAFSamplingValue: 1\n",
    "# FilePrefix: outfiles/ConstantSize"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "37dbdfb015eb2911072604397bc3ab5127f1ef4d866242904832becb363c8f9b"
  },
  "kernelspec": {
   "display_name": "Python 3.9.7 64-bit ('cvae': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
