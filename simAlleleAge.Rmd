---
title: "Simulate Allele Age"
date: "7/26/2021"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

## Imports

```{r}
library(Rcpp)
library(expint)
```

*All calculations below are per-site/locus, $l$. Will port this into a global meta-function for ease of use later.* 

## Picking $\gamma$

Here, I pick the population scaled selection coefficient $\gamma = 2Ns \in [2, 200]$ to then use for simulating allele frequency $X$. 

```{r}
N<-2500 # inds
# initial: need a total of 5000 training data sets: 50 selection values on either side + 0 with 100 instances of allele frequencies
L<-200 

# just pick a grid of values here, say, ~50
gamma<-c(-exp(log(10)*seq(2, -2, length.out=25)),exp(log(10)*seq(-2, 2, length.out=25)))
```

## Simulating $X_l$

Below, I will use the above $\gamma_l$ value to simulate a starting allele frequency (present-day, $X_0$), and then let the population evolve (to either extinction or fixation). Formula 7.61 of Durrett 2008: $$f(X_l | \gamma_l) = \frac{1}{X_l(1-X_l)}\frac{1-e^{-2\gamma_l(1-X_l)}}{1-e^{-2\gamma_l}}$$

We need to normalize this function by dividing by $\int_{1/2N}^{1-1/2N} f(X_l | \gamma_l) dX_l$ to convert it to a PDF $P(X_l | \gamma_l)$. 

Using this likelihood, I can get the value of $X_l$ by normalizing and doing inverse transform sampling. From WolframAlpha, the integral (also CDF) solves out to be $$F_{X_l}(y)=\frac{1}{1-e^{-\gamma}}\times[\text{Ei}(\gamma_l(y-1)) - e^{-\gamma}\text{Ei}(\gamma_l y) - \log y-1 + \log y]$$

The following code chunk needs to be repeated for every value of $\gamma$. 

```{r}
Xl<-(2:(2*N-2))/(2*N)
estimXl<-function(Xl, gamma, ndraws){
    finalXl<-rep(0,length(gamma)*ndraws)
    for(n in 1:length(gamma)){
        lbscal<-expint_Ei(gamma[n]*(Xl[1]-1)) - exp(-gamma[n])*expint_Ei(gamma[n]*Xl[1]) - log(1-Xl[1]) + log(Xl[1])
        scal.fact<-(expint_Ei(gamma[n]*(Xl[length(Xl)]-1)) - exp(-gamma[n])*expint_Ei(gamma[n]*Xl[length(Xl)]) - log(1-Xl[length(Xl)]) + log(Xl[length(Xl)])) - lbscal
        
        pXl<-(expint_Ei(gamma[n]*(Xl-1)) - exp(-gamma[n])*expint_Ei(gamma[n]*Xl) - log(1-Xl) + log(Xl) - lbscal)/scal.fact
        
        u<-runif(ndraws, 0, 1)
        finalXl[((n-1)*ndraws+1):(n*ndraws)]<-Xl[sapply(u,function(x){which.min(abs(pXl-x))})]
    }
    return(finalXl)
}

system.time(finalXl<-estimXl(Xl,gamma,ndraws=1000))
```

Now, I have to add an extra column indicating the $\gamma$ value for each row (i.e., frequency). 

```{r}
finalXl<-cbind(finalXl, rep(gamma,1000))
colnames(finalXl)<-c("Xl","gamma")
```

### Miscellaneous

Testing bed for R function: 

```{r}
# need a scal.fact for each gamma value (removing 1/(1-exp(-gamma)) term since it cancels)
scal.fact<-(expint_Ei(gamma*(Xl[length(Xl)]-1)) - exp(-gamma)*expint_Ei(gamma*Xl[length(Xl)]) - log(1-Xl[length(Xl)]) + log(Xl[length(Xl)])) -
    (expint_Ei(gamma*(Xl[1]-1)) - exp(-gamma)*expint_Ei(gamma*Xl[1]) - log(1-Xl[1]) + log(Xl[1]))

# compute CDF 
pXl<-(expint_Ei(gamma[2]*(Xl-1)) - exp(-gamma[2])*expint_Ei(gamma[2]*Xl) - log(1-Xl) + log(Xl)) -
    (expint_Ei(gamma[2]*(Xl[1]-1)) - exp(-gamma[2])*expint_Ei(gamma[2]*Xl[1]) - log(1-Xl[1]) + log(Xl[1]))
# normalize to 0-1 scale
pXl<-pXl/scal.fact

# generate a set of random numbers between 0 and 1 for inverse transform sampling
u<-runif(2000,0,1)
# find closest pXl value and map back to corresponding Xl
Xl.dist<-Xl[which.min(abs(pXl-u))]
```

The following code is ~6x slower than the vectorized R code *cry*

```{Rcpp}
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
NumericVector estimXlcpp(NumericVector Xl, NumericVector gamma, int ndraws){
    int lenXl = Xl.size();
    int nGamma = gamma.size();
    
    NumericVector eXl(nGamma);
    
    NumericVector pXl(lenXl);
    NumericVector u(ndraws);
    
    NumericVector finalXl(nGamma*ndraws);
    
    Function e("expint_Ei");
    
    double scalFact = 1.0;
    double lbscal;
    
    for(int n=0; n<nGamma; n++){
        lbscal = Rcpp::as<double>(e(gamma[n]*(Xl[0]-1))) - std::exp(-gamma[n])*Rcpp::as<double>(e(gamma[n]*Xl[0])) - std::log(1-Xl[0]) + std::log(Xl[0]);
        scalFact = Rcpp::as<double>(e(gamma[n]*Xl[lenXl-1])) - std::exp(-gamma[n])*Rcpp::as<double>(e(gamma[n]*Xl[lenXl-1])) - std::log(1-Xl[lenXl-1]) + std::log(Xl[lenXl-1]) - lbscal;
    
        for(int i=0; i<lenXl; i++){
            pXl[i] = (Rcpp::as<double>(e(gamma[n]*(Xl[i]-1))) - std::exp(-gamma[n])*Rcpp::as<double>(e(gamma[n]*Xl[i])) - std::log(1-Xl[i]) + std::log(Xl[i]) - lbscal)/scalFact;
        }
        u = Rcpp::runif(ndraws, 0, 1);
        
        for(int m=0; m<ndraws; m++){
            finalXl[m+n*ndraws] = Xl[which_min(abs(pXl-u[m]))];
        }
    }
    
    return finalXl;
}
```

## Obtaining $a_l$

Here, I will use the $X_0$ as the starting frequency and run WF sims until it reaches a frequency of $<1/2N$ -- record this generation as the allele age. This formula is similar to equations found in Ewens 2007 for conditional processes in diffusion theory conditional on fixation (here, we condition on loss). 

$$
X_{t+1} | X_t, \gamma \sim N(\mu_s, V_s) \\
\mu_s = X_t - \frac{\gamma X_t (1-X_t)}{2 \tanh (\frac{\gamma}{2}(1-X_t))} \\
V_s = X_t(1-X_t)
$$

Prototpye R function below: 

```{r}
alleleAge<-function(X0, gamma, N){
    gen<-0
    Xt<-X0
    # quit loop and record allele age if it dips below 1/2N
    while(Xt>0.5/N){
        gen<-gen+1
        
        mu<-Xt-0.25*gamma*Xt*(1-Xt)/tanh(0.5*gamma*(1-Xt))/N
        
        Xt<-rnorm(1, mean=mu, sd=sqrt(Xt*(1-Xt))*0.5/N)
    }
    return(gen)
}
```

I will run the below function for each of our training data points (~100k) to get allele age given $\gamma$ and $X_l$. Thankfully, this Rcpp function runs ~30x faster than the regular R function. 

```{Rcpp}
#include <Rcpp.h>
using namespace Rcpp;

// [[Rcpp::export]]
int alleleAgecpp(float X0, float gamma, int N){
    int gen = 0;
    double Xt = X0;
    double mu = 0.0;
    
    while(Xt > 0.5/N){
        gen++;
        
        mu = Xt - 0.25*gamma*Xt*(1-Xt)/tanh(0.5*gamma*(1-Xt))/N;
        Xt = R::rnorm(mu, sqrt(Xt*(1-Xt))*0.5/N);
    }
    return gen;
}
```

Time to farm out the above function to each row in the previous data frame:

```{r}
all.age<-apply(finalXl, 1, function(x) alleleAgecpp(x[1], x[2], N))
finalXl<-cbind(finalXl, all.age)
colnames(finalXl)[3]<-"al"
```

Writing into a file as training data:

```{r}
library(MASS)
write.matrix(finalXl,file=paste0("traindata/trip-",Sys.Date(),".csv"),sep=",")
```

## Comparison between theory and empirical draws

Below, I will compare the expectation for allele age from diffusion theory for $h=1/2$ from Ewens 2008 (Eqn 5.54) for eventual loss of an allele, starting at initial frequency of $p$. 

$$
t^{**}(x;p) = 2\{e^{\gamma x}-1 \} \{e^{\gamma (1-x)}-1\}[\gamma x(1-x) (e^\gamma-1)]^{-1}
$$

Need to take the expectation of the above function between $1/2N$ and $p=X_l$, to find the actual expected allele age. (log in to midway2 and run mathematica module - no need to install on here for right now...)

$$
\bar t^{**}(x;p) = \int_{1/2N}^{p} x \times 2\{e^{\gamma x}-1 \} \{e^{\gamma (1-x)}-1\}[\gamma x(1-x) (e^\gamma-1)]^{-1} dx
$$

```{r}
exp.al<-function(xl, gamma){
    2*(expm1(gamma*xl))*(expm1(gamma*(1-xl)))/(gamma*xl*(1-xl)*expm1(gamma))
}

finalXl$exp.al<-rep(NA,nrow(finalXl))

finalXl$exp.al<-apply(finalXl, 1, function(x){exp.al(x[1], x[2])})
```